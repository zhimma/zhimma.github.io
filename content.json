{"meta":{"title":"zhimma","subtitle":null,"description":"zhimma's 技术blog","author":"zhimma","url":"http://yoursite.com"},"pages":[{"title":"categories","date":"2019-01-24T02:03:44.000Z","updated":"2019-01-24T02:03:44.547Z","comments":true,"path":"categories/index.html","permalink":"http://yoursite.com/categories/index.html","excerpt":"","text":""},{"title":"about","date":"2019-01-24T02:03:56.000Z","updated":"2019-01-24T02:03:56.157Z","comments":true,"path":"about/index.html","permalink":"http://yoursite.com/about/index.html","excerpt":"","text":""},{"title":"tags","date":"2019-01-24T02:03:50.000Z","updated":"2019-01-24T02:03:50.917Z","comments":true,"path":"tags/index.html","permalink":"http://yoursite.com/tags/index.html","excerpt":"","text":""}],"posts":[{"title":"","slug":"Nginx","date":"2018-12-21T08:11:29.593Z","updated":"2018-12-21T09:08:11.361Z","comments":true,"path":"2018/12/21/Nginx/","link":"","permalink":"http://yoursite.com/2018/12/21/Nginx/","excerpt":"","text":"安装版本说明Mainline version 开发版本 Stable version 稳定版本 Legacy versions 历史版本 安装源To set up the yum repository for RHEL/CentOS, create the file named /etc/yum.repos.d/nginx.repo with the following contents: 12345678&gt; [nginx]&gt; name=nginx repo&gt; baseurl=http://nginx.org/packages/OS/OSRELEASE/$basearch/&gt; gpgcheck=0&gt; enabled=1&gt; &gt; baseurl=http://nginx.org/packages/centos/7/$basearch/&gt; Replace “OS” with “rhel” or “centos”, depending on the distribution used, and “OSRELEASE” with “6” or “7”, for 6.x or 7.x versions, respectively. 查看nginx安装包yum list | grep nginx 安装nginxyum install nginx -y 查看版本信息12345678[root@host ~]# nginx -vnginx version: nginx/1.14.2[root@host ~]# nginx -Vnginx version: nginx/1.14.2built by gcc 4.8.5 20150623 (Red Hat 4.8.5-28) (GCC)built with OpenSSL 1.0.2k-fips 26 Jan 2017TLS SNI support enabledconfigure arguments: --prefix=/etc/nginx --sbin-path=/usr/sbin/nginx --modules-path=/usr/lib64/nginx/modules --conf-path=/etc/nginx/nginx.conf --error-log-path=/var/log/nginx/error.log --http-log-path=/var/log/nginx/access.log --pid-path=/var/run/nginx.pid --lock-path=/var/run/nginx.lock --http-client-body-temp-path=/var/cache/nginx/client_temp --http-proxy-temp-path=/var/cache/nginx/proxy_temp --http-fastcgi-temp-path=/var/cache/nginx/fastcgi_temp --http-uwsgi-temp-path=/var/cache/nginx/uwsgi_temp --http-scgi-temp-path=/var/cache/nginx/scgi_temp --user=nginx --group=nginx --with-compat --with-file-aio --with-threads --with-http_addition_module --with-http_auth_request_module --with-http_dav_module --with-http_flv_module --with-http_gunzip_module --with-http_gzip_static_module --with-http_mp4_module --with-http_random_index_module --with-http_realip_module --with-http_secure_link_module --with-http_slice_module --with-http_ssl_module --with-http_stub_status_module --with-http_sub_module --with-http_v2_module --with-mail --with-mail_ssl_module --with-stream --with-stream_realip_module --with-stream_ssl_module --with-stream_ssl_preread_module --with-cc-opt='-O2 -g -pipe -Wall -Wp,-D_FORTIFY_SOURCE=2 -fexceptions -fstack-protector-strong --param=ssp-buffer-size=4 -grecord-gcc-switches -m64 -mtune=generic -fPIC' --with-ld-opt='-Wl,-z,relro -Wl,-z,now -pie' nginx 配置解析 user 设置nginx服务的系统使用用户 worker_processes 工作进程数 error_log nginx的错误日志 pid nginx服务 12345678user www www;worker_processes auto;worker_cpu_affinity auto;error_log /home/wwwlogs/nginx_error.log error;# pid /usr/local/nginx/logs/nginx.pid;pid /run/nginx.pid;#Specifies the value for maximum file descriptors that can be opened by this process.worker_rlimit_nofile 65535; events worker_connections 每个工作进程运行的最大链接数 use 工作进程模式 1234events &#123; use epoll; worker_connections 65535;&#125; nginx 模块stub_status123location /nginx &#123; stub_status;&#125; 1234Active connections: 20 server accepts handled requests 274 274 784 Reading: 0 Writing: 1 Waiting: 19","categories":[],"tags":[]},{"title":"","slug":"CLI&Swoole Model","date":"2018-12-04T07:56:03.655Z","updated":"2018-12-05T09:42:25.229Z","comments":true,"path":"2018/12/04/CLI&Swoole Model/","link":"","permalink":"http://yoursite.com/2018/12/04/CLI&Swoole Model/","excerpt":"","text":"[TOC] CLI执行php index.php FEE3D9650A692CB93FF43DE7267BDBD0/Customer/Api/Pay/Address/index/id/1/name/222 获取参数$_SERVER[&#39;PARAMS&#39;] Swooletrunk/ThinkPHP/Library/Think/App.class.php line:98 1234567if (strtolower($_SERVER['CY_REQUEST_URI']) == 'swoole/server/swooleserver') &#123; $class = ''; $array = explode('/', $_SERVER['CY_REQUEST_URI']); foreach ($array as $name) &#123; $class .= '\\\\'.parse_name($name, 1); &#125;&#125; 执行启动swoole 服务:php index.php Swoole/Server/SwooleServer 投递异步任务 1234(new SwooleClient())-&gt;handle([ 'class' =&gt; 'Swoole\\Process\\Customer\\Export', 'params' =&gt; ['id' =&gt; 1, 'name' =&gt; 'zhimma'],]);","categories":[],"tags":[]},{"title":"","slug":"PhpStorm中使用PSR2编码规范phpcbf脚本自动修正代码格式","date":"2018-11-14T02:30:42.123Z","updated":"2018-11-14T03:52:20.017Z","comments":true,"path":"2018/11/14/PhpStorm中使用PSR2编码规范phpcbf脚本自动修正代码格式/","link":"","permalink":"http://yoursite.com/2018/11/14/PhpStorm中使用PSR2编码规范phpcbf脚本自动修正代码格式/","excerpt":"","text":"[TOC] 安装CodeSniffer安装CodeSniffer1brew install php-code-sniffer 安装完成后的路径:/usr/local/Cellar/php-code-sniffer 123456&gt; ☁ bin pwd&gt; /usr/local/Cellar/php-code-sniffer/3.3.1/bin&gt; ☁ bin ls&gt; phpcbf phpcs&gt; &gt; 配置phpcbf12./phpcs --config-set default_standard PSR2./phpcbf --config-set default_standard PSR2 123&gt;☁ bin ls&gt;CodeSniffer.conf phpcbf phpcs&gt; 配置PhpStorm基本配置 打开PhpStorm的设置页（File-&gt;Setting或者Command+,），到Editor/Code Style页PHP中选择风格为 PSR1/2 设置Code Sniffer 选择之前phpcs的路径，填写后可以点击Validate按钮验证 现在使用PhpStorm的格式化，将会自动格式化成psr-2的风格 参考地址","categories":[],"tags":[]},{"title":"","slug":"go-note","date":"2018-10-21T12:50:43.775Z","updated":"2018-12-27T03:36:29.446Z","comments":true,"path":"2018/10/21/go-note/","link":"","permalink":"http://yoursite.com/2018/10/21/go-note/","excerpt":"","text":"[TOC] map声明m:map名称 [int]:key类型 string:value类型 方式1123var m map[int]stringm = map[int]string&#123;&#125;fmt.Println(m) // map[] 方式2123var m map[int]stringm = make(map[int]string)fmt.Println(m) // map[] var m map[int]string = make(map[int]string) 方式312m := make(map[int]string)fmt.Println(m) // map[] 使用赋值123456func main() &#123; m := make(map[int]string) m[1] = \"map value\" key1 := m[1] fmt.Println(key1) // map value&#125; 删除元素123456789func main() &#123; m := make(map[int]string) m[1] = \"map value\" key1 := m[1] fmt.Println(m) // map[1:map value] fmt.Println(key1) // map value delete(m, 1) fmt.Println(m) // map[]&#125; 嵌套map初始化12345m := make(map[int]map[int]string)m[0] = make(map[int]string)m[0][1] = \"map=&gt;0=&gt;1\"a := m[0][1]fmt.Println(a) map迭代","categories":[],"tags":[]},{"title":"","slug":"Mac环境ELK搭建","date":"2018-10-03T14:01:12.430Z","updated":"2018-10-05T15:05:32.701Z","comments":true,"path":"2018/10/03/Mac环境ELK搭建/","link":"","permalink":"http://yoursite.com/2018/10/03/Mac环境ELK搭建/","excerpt":"","text":"[TOC] 安装Java略。。。 这里我使用brew install java命令安装 1234☁ ~ java -versionjava version &quot;11&quot; 2018-09-25Java(TM) SE Runtime Environment 18.9 (build 11+28)Java HotSpot(TM) 64-Bit Server VM 18.9 (build 11+28, mixed mode) 不要使用上述方式安装，有坑 下载这个文件安装java:https://edelivery.oracle.com/otn-pub/java/jdk/8u181-b13/96a7b8442fe848ef90c96a2fad6ed6d1/jdk-8u181-macosx-x64.dmg Elasticsearch安装配置安装官网下载对应平台的安装包 放到合适的位置，我放置后解压的目录是/Users/zhimma/Soft/elasticsearch-6.4.1 配置配置 Elasticsearch下面是我的配置文件内容： 123456789☁ config pwd/Users/zhimma/Soft/elasticsearch-6.4.1/config☁ config grep &apos;^[a-z]&apos; elasticsearch.ymlcluster.name: elk-stackpath.data: /Users/zhimma/Data/elk_stack/datapath.logs: /Users/zhimma/Data/elk_stack/logsbootstrap.memory_lock: falsenetwork.host: 0.0.0.0http.port: 9200 配置 Elasticsearch 内存占用配置 jvm 最大堆和最小堆，一般为服务器物理内存的一半，最大不超过 32g 123456☁ config pwd/Users/zhimma/Soft/elasticsearch-6.4.1/config☁ config vi jvm.options -Xms8g-Xmx8g 启动进入bin目录启动Elasticsearch 123☁ bin pwd/Users/zhimma/Soft/elasticsearch-6.4.1/bin☁ bin ./elasticsearch kibana安装配置安装官网下载对应平台的安装包 放到合适的位置，我放置后解压的目录是/Users/zhimma/Soft/kibana-6.4.1-darwin-x86_64 配置凭感觉配置了一些，如下所示： 12345☁ config grep &apos;^[a-z]&apos; kibana.ymlserver.port: 5601server.host: &quot;0.0.0.0&quot;elasticsearch.url: &quot;http://0.0.0.0:9200&quot;kibana.index: &quot;.kibana&quot; 启动进入bin目录启动Kibana 123☁ bin pwd/Users/zhimma/Soft/kibana-6.4.1-darwin-x86_64/bin☁ bin ./kibana Logstash安装配置安装官网下载对应平台的安装包 放到合适的位置，我放置后解压的目录是/Users/zhimma/Soft/logstash-6.4.1 配置配置 Logstash不是很了解，暂时使用默认配置 配置 Logstash 内存占用配置 jvm 最大堆和最小堆，一般为服务器物理内存的一半，最大不超过 32g 123456☁ config pwd/Users/zhimma/Soft/logstash-6.4.1/config☁ config vi jvm.options -Xms8g-Xmx8g 添加项目或自定义配置文件Logstash收集日志时候，可以对日志进行一定的操作和过滤，这里需要自定义不同的配置文件来实现，针对我们目前的项目，我简单的创建了下面的配置文件 在/Users/zhimma/Soft/logstash-6.4.1/config目录下创建conf.d文件夹，这个文件夹下存放我们所有的自定义配置文件: 12345678910111213141516171819202122232425262728293031323334353637383940414243444546input &#123; file &#123; path =&gt; [ &quot;/data/www/XX_project/trunk/Common/Runtime/Apps/Api/*.log&quot; ] start_position =&gt; &quot;beginning&quot; ignore_older =&gt; 0 sincedb_path =&gt; &quot;/dev/null&quot; type =&gt; &quot;Api&quot; codec =&gt; multiline &#123; pattern =&gt; &quot;^\\[&quot; negate =&gt; true what =&gt; &quot;previous&quot; &#125; &#125;, file &#123; path =&gt; [ &quot;/data/www/XX_project/trunk/Common/Runtime/Apps/SDK/*.log&quot; ] start_position =&gt; &quot;beginning&quot; ignore_older =&gt; 0 sincedb_path =&gt; &quot;/dev/null&quot; type =&gt; &quot;SDK&quot; codec =&gt; multiline &#123; pattern =&gt; &quot;^\\[&quot; negate =&gt; true what =&gt; &quot;previous&quot; &#125; &#125;&#125;filter &#123;&#125;output &#123; if [type] == &quot;Api&quot; &#123; elasticsearch &#123; hosts =&gt; [ &quot;127.0.0.1:9200&quot; ] index =&gt; &quot;api&quot; &#125; &#125;, if [type] == &quot;SDK&quot; &#123; elasticsearch &#123; hosts =&gt; [ &quot;127.0.0.1:9200&quot; ] index =&gt; &quot;sdk&quot; &#125; &#125; stdout &#123; codec =&gt; rubydebug &#125;&#125; 启动进入bin目录启动Llogstash` 123☁ bin pwd/Users/zhimma/Soft/logstash-6.4.1/bin☁ bin ./logstash -f /Users/zhimma/Soft/logstash-6.4.1/config/conf.d/default.conf ## 访问浏览器访问0.0.0.0:5601即可","categories":[],"tags":[]},{"title":"","slug":"搬瓦工Cenots7 实现BBR加速以及SS安装","date":"2018-09-30T07:23:52.587Z","updated":"2018-12-18T10:05:31.466Z","comments":true,"path":"2018/09/30/搬瓦工Cenots7 实现BBR加速以及SS安装/","link":"","permalink":"http://yoursite.com/2018/09/30/搬瓦工Cenots7 实现BBR加速以及SS安装/","excerpt":"","text":"[TOC] 准备环境: centos7 64位1、一键安装Shadowsock 下载脚本 wget --no-check-certificate https://raw.githubusercontent.com/teddysun/shadowsocks_install/master/shadowsocks-libev.sh 增加执行权限 chmod +x shadowsocks-libev.sh 运行 ./shadowsocks-libev.sh 2&gt;&amp;1 | tee shadowsocks-libev.log 安装过程中会提示配置端口、密码、加密方式。 卸载: ./shadowsocks-libev.sh uninstall ss控制 1234启动：/etc/init.d/shadowsocks start 停止：/etc/init.d/shadowsocks stop 重启：/etc/init.d/shadowsocks restart 查看状态：/etc/init.d/shadowsocks status 2、安装BBR加速 目前支持的Linux系统包括：Ubuntu 14.04 x64、Ubuntu 16.04 x64、CentOS 6 x64、CentOS 7 x64 只支持 64 位系统，要求 glibc 版本 2.14 以上。 关闭防火墙 121、systemctl disable firewalld2、systemctl stop firewalld BBR安装脚本 1231、wget https://raw.githubusercontent.com/kuoruan/shell-scripts/master/ovz-bbr/ovz-bbr-installer.sh2、chmod +x ovz-bbr-installer.sh3、./ovz-bbr-installer.sh 安装过程中，会提示加速端口(可以更改) 判断BBR是否正常工作 ping 10.0.0.2 如果能通，则代表启动成功 控制bbr 1systemctl &#123;start|stop|restart|status&#125; haproxy-lkl 配置bbr加速端口 1vi /usr/local/haproxy-lkl/etc/port-rules 一行一个端口，可写范围 ​ 卸载BBR ​ 作者：我是你的nobita 链接：https://www.jianshu.com/p/9f27d4cabd40 來源：简书 简书著作权归作者所有，任何形式的转载都请联系作者获得授权并注明出处。","categories":[],"tags":[]},{"title":"","slug":"mac安装swoole扩展问题记录","date":"2018-09-30T06:09:46.412Z","updated":"2018-09-30T07:16:29.480Z","comments":true,"path":"2018/09/30/mac安装swoole扩展问题记录/","link":"","permalink":"http://yoursite.com/2018/09/30/mac安装swoole扩展问题记录/","excerpt":"","text":"[TOC] openssl/ssl.h&#39; file not found/private/tmp/pear/temp/swoole/include/swoole.h:438:10: fatal error: &#39;openssl/ssl.h&#39; file not found 原因：openssl 未安装或 openssl 库不在标准位置中解决方案： 确认是否安装了 opensslbrew search openssl若未安装则执行命令brew install openssl进行安装 确认 openssl 库是否在标准位置中 12☁ ~ ls /usr/local/include/openssl☁ ~ No such file or directory 这就是问题所在了，找到 openssl/include/openssl 目录，并 cp 到 /usr/local/include 目录中。 ☁ ~ ln -s /usr/local/Cellar/openssl/1.0.2p/include/openssl/ /usr/local/include/ 一般情况下就可以解决该问题了。 但是，也可能会遇到很诡异的状况，上步没有解决问题，依然找不到 openssl/ssl.h 等文件复制 openssl 源文件到 swoole 的源码目录中，编译就可以了。 cp -R /usr/local/Cellar/openssl/1.0.2p/include/openssl swoole-src-2.1.3/include 这个肯定能解决问题了 Enable openssl support, require openssl library./private/tmp/pear/temp/swoole/php_swoole.h:137:2: error: &quot;Enable openssl support, require openssl library.&quot; 上面的问题解决了，再次pecl install swoole时候报了这个错，找了很久都么有找到解决方案，偶然看到pecl 安装的过程： 123456789enable debug/trace log support? [no] : yesenable sockets supports? [no] : yesenable openssl support? [no] : yesenable http2 support? [no] : yesenable async-redis support? [no] : yesenable mysqlnd support? [no] : yesenable postgresql coroutine client support? [no] : nobuilding in /private/tmp/pear/temp/pear-build-zhimmaSwGIQ1/swoole-4.2.1running: /private/tmp/pear/temp/swoole/configure --with-php-config=/usr/local/opt/php@7.1/bin/php-config --enable-debug-log=yes --enable-sockets=yes --enable-openssl=yes --enable-http2=yes --enable-async-redis=yes --enable-mysqlnd=yes --enable-coroutine-postgresql=no ，于是猜想如果指定openssl的目录，是否可以解决，先看看openssl目录： 12☁ ~ which openssl/usr/local/opt/openssl/bin/openssl 于是安装过程就变成下面： 123456789enable debug/trace log support? [no] : yesenable sockets supports? [no] : yesenable openssl support? [no] : yes --with-openssl-dir=/usr/local/opt/openssl/bin/opensslenable http2 support? [no] : yesenable async-redis support? [no] : yesenable mysqlnd support? [no] : yesenable postgresql coroutine client support? [no] : nobuilding in /private/tmp/pear/temp/pear-build-zhimmaN9CyFV/swoole-4.2.1running: /private/tmp/pear/temp/swoole/configure --with-php-config=/usr/local/opt/php@7.1/bin/php-config --enable-debug-log=yes --enable-sockets=yes --enable-openssl=yes --with-openssl-dir=/usr/local/opt/openssl/bin/openssl --enable-http2=yes --enable-async-redis=yes --enable-mysqlnd=yes --enable-coroutine-postgresql=no 错误解决 Enable http2 support, require nghttp2 library./private/tmp/pear/temp/swoole/php_swoole.h:148:2: error: &quot;Enable http2 support, require nghttp2 library. 解决方案： brew install nghttp2 未能解决 hiredis/hiredis.h&#39; file not found/private/tmp/pear/temp/swoole/swoole_redis.c:20:10: fatal error: hiredis/hiredis.h&#39; file not found 解决方案： brew install hiredis 编译参数12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455--disable-option-checking ignore unrecognized --enable/--with options --disable-FEATURE do not include FEATURE (same as --enable-FEATURE=no) --enable-FEATURE[=ARG] include FEATURE [ARG=yes] --with-PACKAGE[=ARG] use PACKAGE [ARG=yes] --without-PACKAGE do not use PACKAGE (same as --with-PACKAGE=no) --with-libdir=NAME Look for libraries in .../NAME rather than .../lib --with-php-config=PATH Path to php-config php-config --enable-swoole-debug Enable swoole debug 启用swoole的调试日志。不要在生产环境中启用此配置。 --enable-trace-log Enable swoole trace log --enable-sockets Do you have sockets extension? 启用对 sockets 的支持。依赖 sockets --enable-async-redis Do you have hiredis? 启用对异步Redis客户端的支持。依赖 hiredis --enable-coroutine-postgresql Do you install postgresql? 启用协程 Postgresql 客户端，依赖 libpq --enable-openssl Use openssl? 启用openssl支持。依赖 libssl.so --enable-http2 Use http2.0? 启用HTTP2的支持。依赖 nghttp2 --enable-thread Experimental: Use thread? 启用线程支持 //实验性功能。请勿在生产环境中使用此功能 --enable-hugepage Experimental: Use hugepage? 启用 hugepage //使用大内存页优化性能，具体鸟哥在他的博客中讲到。 如果已经开启了 jemalloc，再开启hugepage 印象性能 https://blog.digitalocean.com/transparent-huge-pages-and-alternative-memory-allocators/ 实验性功能。请勿在生产环境中使用此功能 --enable-swoole Enable swoole support --enable-swoole-static Enable swoole static compile support --with-swoole With swoole support --with-libpq-dir=DIR Include libpq support (requires libpq &gt;= 9.5) --with-openssl-dir=DIR Include OpenSSL support (requires OpenSSL &gt;= 0.9.6) 设置openssl库的路径，例如：--with-openssl-dir=/opt/openssl/. --with-jemalloc-dir=DIR Include jemalloc support 使用 jemalloc 进行内存优化支持 --enable-mysqlnd Do you have mysqlnd? 启用对 mysqlnd 的支持，依赖 mysqlnd --enable-coroutine Enable coroutine (requires PHP &gt;= 5.5) 启用协程 --enable-asan Enable asan 启用 Address-Sanitizier 内存检测工具 //只有开启debug才有效 --enable-picohttpparser Experimental: Do you have picohttpparser? 启用 picohttpparser 支持 //这是一个超高性能的http解析器，实验性功能。请勿在生产环境中使用此功能 --enable-timewheel Experimental: Enable timewheel heartbeat? 启用时间轮算法并优化心跳算法 //实验性功能。请勿在生产环境中使用此功能 --enable-debug, compile with debug symbols 编译时加入符号表 //使用gdb调试时有用 --enable-shared=PKGS Build shared libraries default=yes --enable-static=PKGS Build static libraries default=yes --enable-fast-install=PKGS Optimize for fast installation default=yes --with-gnu-ld Assume the C compiler uses GNU ld default=no --disable-libtool-lock Avoid locking (might break parallel builds) --with-pic Try to use only PIC/non-PIC objects default=use both --with-tags=TAGS Include additional configurations automatic","categories":[],"tags":[]},{"title":"","slug":"面向对象的特性","date":"2018-09-29T11:08:49.334Z","updated":"2018-09-29T11:08:49.334Z","comments":true,"path":"2018/09/29/面向对象的特性/","link":"","permalink":"http://yoursite.com/2018/09/29/面向对象的特性/","excerpt":"","text":"来自这里https://www.cnblogs.com/zhyunfe/p/6398581.html、 [TOC] 面向对象的特性封装对事物的封装是指，将事物进行抽象后，提供抽象概念的实现的具体方法。 PHP也只是三种封装概念：Private，Protected，Public。 私有/Private私有的概念是，仅仅对象内部可见，外部不可见 保护/Protected 保护的概念是，仅仅是自身类和继承类可见，这个关键字的用途主要是防止滥用类的派生，另外三方库编写的时候会用到，防止误用。 继承继承性就是派生类(子类)自动继承一个或多个基类(父类)中的属性与方法，并可以重写或添加新的属性和方法。继承这个特性简化了对象和类的创建，增加了代码的可重性。继承分单继承和多继承，PHP所支持的是单继承，也就是说，一个子类有且只有一个父类。 多态多态是指在面向对象中能够根据使用类的上下文来重新定义或改变类的性质和行为同一个类的不同对象，使用同一个方法可以获得不同的结果。多态性增强了软件的灵活性和重用性。 五大基本原则单一职责原则SRP(Single Responsibility Principle)是指一个类的功能要单一，不能包罗万象。如同一个人一样，分配的工作不能太多，否则一天到晚虽然忙忙碌碌的，但效率却高不起来。 开放封闭原则OCP(Open－Close Principle)一个模块在扩展性方面应该是开放的而在更改性方面应该是封闭的。比如：一个网络模块，原来只服务端功能，而现在要加入客户端功能，那么应当在不用修改服务端功能代码的前提下，就能够增加客户端功能的实现代码，这要求在设计之初，就应当将服务端和客户端分开，公共部分抽象出来。 替换原则(the Liskov Substitution Principle LSP)子类应当可以替换父类并出现在父类能够出现的任何地方。比如：公司搞年度晚会，所有员工可以参加抽奖，那么不管是老员工还是新员工，也不管是总部员工还是外派员工，都应当可以参加抽奖，否则这公司就不和谐了。 依赖原则(the Dependency Inversion Principle DIP) 具体依赖抽象，上层依赖下层。假设B是较A低的模块，但B需要使用到A的功能，这个时候，B不应当直接使用A中的具体类： 而应当由B定义一抽象接口，并由A来实现这个抽象接口，B只使用这个抽象接口：这样就达到了依赖倒置的目的，B也解除了对A的依赖，反过来是A依赖于B定义的抽象接口。通过上层模块难以避免依赖下层模块，假如B也直接依赖A的实现，那么就可能造成循环依赖。一个常见的问题就是编译A模块时需要直接包含到B模块的cpp文件，而编译B时同样要直接包含到A的cpp文件。 接口分离原则(the Interface Segregation Principle ISP)模块间要通过抽象接口隔离开，而不是通过具体的类强耦合起来","categories":[],"tags":[]},{"title":"","slug":"负载均衡实践","date":"2018-09-29T11:08:49.333Z","updated":"2018-09-29T11:08:49.333Z","comments":true,"path":"2018/09/29/负载均衡实践/","link":"","permalink":"http://yoursite.com/2018/09/29/负载均衡实践/","excerpt":"","text":"引用参考：https://juejin.im/post/5821c24e570c350060bef4c3 环境说明：windows 下4台服务器，真实机IP：192.168.2.107，其中 服务器 IP 说明 nginx1 172.17.0.3 nginx服务器1 nginx2 172.17.0.4 nginx服务器2 server1 172.17.0.5 服务器1 server2 172.17.0.6 服务器2 server3 172.17.0.7 服务器3 1234567C:\\Users\\mma&gt;docker psCONTAINER ID PORTS NAMES73e6f2096612 6379/tcp, 0.0.0.0:201-&gt;22/tcp, 0.0.0.0:881-&gt;80/tcp, 0.0.0.0:3361-&gt;3306/tcp, 0.0.0.0:9004-&gt;9001/tcp nginx1805ef8d42fa6 6379/tcp, 0.0.0.0:202-&gt;22/tcp, 0.0.0.0:882-&gt;80/tcp, 0.0.0.0:3362-&gt;3306/tcp, 0.0.0.0:9005-&gt;9001/tcp nginx2e91b4a662023 6379/tcp, 0.0.0.0:203-&gt;22/tcp, 0.0.0.0:883-&gt;80/tcp, 0.0.0.0:3363-&gt;3306/tcp, 0.0.0.0:9006-&gt;9001/tcp server101bb4850cc8c 6379/tcp, 0.0.0.0:204-&gt;22/tcp, 0.0.0.0:884-&gt;80/tcp, 0.0.0.0:3364-&gt;3306/tcp, 0.0.0.0:9007-&gt;9001/tcp server2e500cbd1efad 6379/tcp, 0.0.0.0:205-&gt;22/tcp, 0.0.0.0:885-&gt;80/tcp, 0.0.0.0:3365-&gt;3306/tcp, 0.0.0.0:9008-&gt;9001/tcp server3 主要需要暴露http服务端口 负载均衡概念负载均衡，英文名称为Load Balance，其意思就是分摊到多个操作单元上进行执行，例如Web服务器、FTP服务器、企业关键应用服务器和其它关键任务服务器等，从而共同完成工作任务。 我们知道单台服务器的性能是有上限的，当流量很大时，就需要使用多台服务器来共同提供服务，这就是所谓的集群。 负载均衡服务器，就是用来把经过它的流量，按照某种方法，分配到集群中的各台服务器上。这样一来不仅可以承担更大的流量、降低服务的延迟，还可以避免单点故障造成服务不可用。一般的反向代理服务器，都具备负载均衡的功能。 负载均衡功能可以由硬件来提供，比如以前的F5设备。也可以由软件来提供，LVS可以提供四层的负载均衡(利用IP和端口)， 架构图 负载均衡策略加权轮询指定轮询几率，weight和访问比率成正比，用于后端服务器性能不均的情况。 图中有两点需要注意，第一，如果可以把加权轮询算法分为先深搜索和先广搜索，那么nginx采用的是先深搜索算法，即将首先将请求都分给高权重的机器，直到该机器的权值降到了比其他机器低，才开始将请求分给下一个高权重的机器；第二，当所有后端机器都down掉时，nginx会立即将所有机器的标志位清成初始状态，以避免造成所有的机器都处在timeout的状态，从而导致整个前端被夯住。 1234567891011121314151617http &#123; upstream zhimma &#123; server 192.168.2.107:883 weight=5; server 192.168.2.107:884 weight=6; server 192.168.2.107:885 weight=7; &#125; server&#123; listen 80; server_name zhimma.ma; location / &#123; proxy_pass http://zhimma; proxy_set_header Host $host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; &#125; &#125;&#125; 除了 weight 之外，还有别的配置项 1234upstream phpServers &#123; server 192.168.2.107:883 weight=5 max_fails=1 fail_timeout=20 max_conns=100; server 192.168.2.107:883 weight=6 backup down&#125; max_fails 默认为1。某台Server允许请求失败的次数，超过最大次数后，在failtimeout时间内，新的请求将不会分配给这台机器。如果设置为0，Nginx会将这台Server置为永久无效状态，然后将请求发给定义了proxynextupstream, fastcginextupstream, uwsginextupstream, scginextupstream, and memcachednext_upstream指令来处理这次错误的请求。 fail_timeout 默认为10秒。某台Server达到maxfails次失败请求后，在failtimeout期间内，nginx会认为这台Server暂时不可用，不会将请求分配给它 backup 备份机，所有服务器挂了之后才会生效 down 标识某一台server不可用 max_conns 限制分配给某台Server处理的最大连接数量，超过这个数量，将不会分配新的连接给它。默认为0，表示不限制。注意：1.5.9之后的版本才有这个配置 表示最多给100这台Server分配1000个请求，如果这台Server正在处理1000个请求，nginx将不会分配新的请求给到它。假如有一个请求处理完了，还剩下999个请求在处理，这时nginx也会将新的请求分配给它。 3.IP HASHip_hash(ip绑定)每个请求按访问ip的hash结果分配，这样每个访客固定访问一个后端服务器，可以解决session的问题。 ip hash算法的核心实现如下： 12345for(i = 0;i &lt; 3;i++)&#123; hash = (hash * 113 + iphp-&gt;addr[i]) % 6271; &#125;p = hash % iphp-&gt;rrp.peers-&gt;number; 从代码中可以看出，hash值既与ip有关又与后端机器的数量有关。经过测试，上述算法可以连续产生1045个互异的value，这是该算法的硬限制。对此nginx使用了保护机制，当经过20次hash仍然找不到可用的机器时，算法退化成轮询。因此，从本质上说，ip hash算法是一种变相的轮询算法，如果两个ip的初始hash值恰好相同，那么来自这两个ip的请求将永远落在同一台服务器上，这为均衡性埋下了很深的隐患。 12345678910111213141516171819http &#123; upstream zhimma &#123; ip_hash; server 192.168.2.107:883; server 192.168.2.107:884; server 192.168.2.107:885; &#125; server&#123; listen 80; server_name zhimma.ma; location / &#123; proxy_pass http://zhimma; #如果服务器要获取客户端真实IP，可以用下三句设置主机头和客户端真实地址 proxy_set_header Host $host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; &#125; &#125;&#125; fair通用hash、一致性hashsession_sticky配置详情负载均衡服务器1234567891011121314151617181920212223242526272829303132333435363738user nginx;worker_processes 1;error_log /var/log/nginx/error.log warn;pid /var/run/nginx.pid;events &#123; worker_connections 1024;&#125;http &#123; include /etc/nginx/mime.types; default_type application/octet-stream; log_format main '$remote_addr - $remote_user [$time_local] \"$request\" ' '$status $body_bytes_sent \"$http_referer\" ' '\"$http_user_agent\" \"$http_x_forwarded_for\"'; access_log /var/log/nginx/access.log main; sendfile on; #tcp_nopush on; keepalive_timeout 65; #gzip on; upstream zhimma &#123; server 192.168.2.107:883 weight=3; server 192.168.2.107:884 weight=4; server 192.168.2.107:885 weight=5; &#125; server&#123; listen 80; server_name zhimma.ma; root /home/www/tourism/laravel_store/public; index index.html index.htm; location / &#123; proxy_pass http://zhimma; proxy_set_header Host $host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; &#125; &#125;# include /etc/nginx/conf.d/*.conf;&#125; 业务服务器1234567891011121314151617181920212223242526272829303132333435363738[root@e91b4a662023 conf.d]# pwd /etc/nginx/conf.d[root@e91b4a662023 conf.d]# lszhimma.ma.confroot@e91b4a662023 conf.d]# cat zhimma.ma.conf server &#123; listen 80; server_name zhimma.ma; ## Root and index files. # 这里的路径对应自己项目路径，因为我是做了目录挂载，所以剩下2台服务器nginx的配置做了区分 # 分别是/home/www/zhimma/server2和/home/www/zhimma/server3 root /home/www/zhimma/server1; index index.php index.html index.htm; #error_page 404 /404.html; # redirect server error pages to the static page /50x.html # error_page 500 502 503 504 /50x.html; location = /50x.html &#123; root html; &#125; location / &#123; # pass the PHP scripts to FastCGI server listening on 127.0.0.1:9000 # location ~ \\.php$ &#123; fastcgi_pass 127.0.0.1:9000; fastcgi_index index.php; fastcgi_param SCRIPT_FILENAME $document_root$fastcgi_script_name; include fastcgi_params; &#125; try_files $uri $uri/ /index.php$is_args$args; &#125; &#125; 重启nginx ，配置hosts,访问zhimma.ma:881,就能看的切换的效果了 ###","categories":[],"tags":[]},{"title":"","slug":"正向代理和反向代理","date":"2018-09-29T11:08:49.332Z","updated":"2018-09-29T11:08:49.332Z","comments":true,"path":"2018/09/29/正向代理和反向代理/","link":"","permalink":"http://yoursite.com/2018/09/29/正向代理和反向代理/","excerpt":"","text":"概念正向代理正向代理是一个位于客户端和目标服务器之间的代理服务器（中间服务器）。为了从原始服务器取得内容，客户端向代理服务器发送一个请求，并且指定目标服务器，之后代理向目标服务器转交并且将获得的内容返回给客户端。正向代理的情况下客户端必须要进行一些特别的设置才能使用。 反向代理反向代理正好相反。对于客户端来说，反向代理就好像目标服务器。并且客户端不需要进行任何设置。客户端向反向代理发送请求，接着反向代理判断请求走向何处，并将请求转交给客户端，使得这些内容就好似他自己一样，一次客户端并不会感知到反向代理后面的服务，也因此不需要客户端做任何设置，只需要把反向代理服务器当成真正的服务器就好了。 区别访问形式区分：正向代理需要你主动设置代理服务器ip或者域名进行访问，由设置的服务器ip或者域名去获取访问内容并返回；正向代理是代理客户端，为客户端收发请求，使真实客户端对服务器不可见；反向代理不需要你做任何设置，直接访问服务器真实ip或者域名，但是服务器内部会自动根据访问内容进行跳转及内容返回，你不知道它最终访问的是哪些机器。反向代理是代理服务器端，为服务器收发请求，使真实服务器对客户端不可见。从上面的描述也能看得出来正向代理和反向代理最关键的两点区别： 是否指定目标服务器 客户端是否要做设置正向代理中，proxy和client同属一个LAN，对server透明； 反向代理中，proxy和server同属一个LAN，对client透明。 实际上proxy在两种代理中做的事都是代为收发请求和响应，不过从结构上来看正好左右互换了下，所以把前者那种代理方式叫做正向代理，后者叫做反向代理。用途上来区分：正向代理：正向代理用途是为了在防火墙内的局域网提供访问internet的途径。另外还可以使用缓冲特性减少网络使用率反向代理：反向代理的用途是将防火墙后面的服务器提供给internet用户访问。同时还可以完成诸如负载均衡等功能从安全性来讲：正向代理：正向代理允许客户端通过它访问任意网站并且隐蔽客户端自身，因此你必须采取安全措施来确保仅为经过授权的客户端提供服务反向代理：对外是透明的，访问者并不知道自己访问的是代理。对访问者而言，他以为访问的就是原始服务器使用场景正向代理从上面的介绍也就可以猜出来正向代理的至少一个功能（俗称翻墙），也即： 用户A无法访问facebook，但是能访问服务器B，而服务器B可以访问facebook。于是用户A访问服务器B，通过服务器B去访问facebook，，服务器B收到请求后，去访问facebook，facebook把响应信息返回给服务器B，服务器B再把响应信息返回给A。这样，通过代理服务器B，就实现了翻墙。 反向代理从上面的介绍也可以猜出来反向代理的至少一个功能（比如负载均衡），也即： 假设用户A访问 http://www.somesite.com/something.html，但www.somesite.com上并不存在something.html页面，于是接收用户请求的该服务器就偷偷从另外一台服务器上取回来，然后返回给用户，而用户并不知道something.html页面究竟位于哪台机器上。 反向代理的作用就比较多了，这里简单列举一下： 保护和隐藏原始资源服务器 加密和SSL加速 负载均衡 缓存静态内容 压缩 减速上传 安全 外网发布 下面做两个简单介绍 保护和隐藏原始资源服务器用户A始终认为它访问的是原始服务器B而不是代理服务器Z，但实用际上反向代理服务器接受用户A的应答，从原始资源服务器B中取得用户A的需求资源，然后发送给用户A。由于防火墙的作用，只允许代理服务器Z访问原始资源服务器B。尽管在这个虚拟的环境下，防火墙和反向代理的共同作用保护了原始资源服务器B，但用户A并不知情。 负载均衡当反向代理服务器不止一个的时候，我们甚至可以把它们做成集群，当更多的用户访问资源服务器B的时候，让不同的代理服务器Z（x）去应答不同的用户，然后发送不同用户需要的资源。 透明代理透明代理比较类似正向代理的功能，差别在于客户端根本不知道代理的存在，它改编你的request，并会传送真实IP（使用场景就是公司限制网络的访问）。 比如为了工作效率或者安全，A公司屏蔽了QQ软件的使用。A公司的员工接上了网络，但发现无法使用qq。这就是透明代理捣的鬼。公司在内网和外网的中间插入一个透明代理，这个代理会根据规则抓取请求内容，遇到qq的请求我就把这个请求给屏蔽掉，这样就完成了透明屏蔽。当然了，如果你明白原理，就可以自己搞个正向代理来绕过公司的屏蔽。","categories":[],"tags":[]},{"title":"","slug":"计算机基础","date":"2018-09-29T11:08:49.332Z","updated":"2018-09-29T11:08:49.332Z","comments":true,"path":"2018/09/29/计算机基础/","link":"","permalink":"http://yoursite.com/2018/09/29/计算机基础/","excerpt":"","text":"计算机基础title: 计算机基础date: 2018-03-18 23:20:16 进程与线程进程和线程都是一个时间段的描述，是CPU工作时间段的描述 一个最最基础的事实：CPU太快，太快，太快了，寄存器仅仅能够追的上他的脚步，RAM和别的挂在各总线上的设备完全是望其项背。那当多个任务要执行的时候怎么办呢？轮流着来?或者谁优先级高谁来？不管怎么样的策略，一句话就是在CPU看来就是轮流着来。一个必须知道的事实：执行一段程序代码，实现一个功能的过程介绍 ，当得到CPU的时候，相关的资源必须也已经就位，就是显卡啊，GPS啊什么的必须就位，然后CPU开始执行。这里除了CPU以外所有的就构成了这个程序的执行环境，也就是我们所定义的程序上下文。当这个程序执行完了，或者分配给他的CPU执行时间用完了，那它就要被切换出去，等待下一次CPU的临幸。在被切换出去的最后一步工作就是保存程序上下文，因为这个是下次他被CPU临幸的运行环境，必须保存。串联起来的事实：前面讲过在CPU看来所有的任务都是一个一个的轮流执行的，具体的轮流方法就是：先加载程序A的上下文，然后开始执行A，保存程序A的上下文，调入下一个要执行的程序B的程序上下文，然后开始执行B,保存程序B的上下文。。。 进程就是包换上下文切换的程序执行时间总和 = CPU加载上下文+CPU执行+CPU保存上下文进程的颗粒度太大，每次都要有上下的调入，保存，调出。如果我们把进程比喻为一个运行在电脑上的软件，那么一个软件的执行不可能是一条逻辑执行的，必定有多个分支和多个程序段，就好比要实现程序A，实际分成 a，b，c等多个块组合而成。那么这里具体的执行就可能变成： 程序A得到CPU =&gt; CPU加载上下文，开始执行程序A的a小段，然后执行A的b小段，然后再执行A的c小段，最后CPU保存A的上下文。 这里a，b，c的执行是共享了A的上下文，CPU在执行的时候没有进行上下文切换的。这里的a，b，c就是线程，也就是说线程是共享了进程的上下文环境，的更为细小的CPU时间段。 开个QQ，开了一个进程；开了迅雷，开了一个进程。在QQ的这个进程里，传输文字开一个线程、传输语音开了一个线程、弹出对话框又开了一个线程。所以运行某个软件，相当于开了一个进程。在这个软件运行的过程里（在这个进程里），多个工作支撑的完成QQ的运行，那么这“多个工作”分别有一个线程。所以一个进程管着多个线程。通俗的讲：“进程是爹妈，管着众多的线程儿子”… 一个进程可以包括多个线程 每个线程可以使用进程的共享内存（互斥锁） 操作系统的设计，因此可以归结为三点： 以多进程形式，允许多个任务同时运行； 以多线程形式，允许单个任务分成不同的部分运行； 提供协调机制，一方面防止进程之间和线程之间产生冲突，另一方面允许进程之间和线程之间共享资源。 异步，非阻塞和 IO 复用https://segmentfault.com/a/1190000007614502 同步与异步同步与异步的重点在消息通知的方式上，也就是调用结果通知的方式。 同步: 当一个同步调用发出去后，调用者要一直等待调用结果的通知后，才能进行后续的执行。异步：当一个异步调用发出去后，调用者不能立即得到调用结果的返回。异步调用，要想获得结果，一般有两种方式 主动轮询异步调用的结果; 被调用方通过callback来通知调用方调用结果。 demo：同步买奶茶：小明点单交钱，然后等着拿奶茶；异步买奶茶：小明点单交钱，店员给小明一个小票，等小明奶茶做好了，再来取。 异步买奶茶: 小明要想知道奶茶是否做好了，有两种方式： 小明主动去问店员，一会就去问一下：“奶茶做好了吗？”…直到奶茶做好。这叫轮训。 等奶茶做好了，店员喊一声：“小明，奶茶好了！”，然后小明去取奶茶。这叫回调。 阻塞与非阻塞阻塞与非阻塞的重点在于进/线程等待消息时候的行为，也就是在等待消息的时候，当前进/线程是挂起状态，还是非挂起状态。 阻塞调用在发出去后，在消息返回之前，当前进/线程会被挂起，直到有消息返回，当前进/线程才会被激活.非阻塞调用在发出去后，不会阻塞当前进/线程，而会立即返回。 demo：阻塞买奶茶：小明点单交钱，干等着拿奶茶，什么事都不做；非阻塞买奶茶：小明点单交钱，等着拿奶茶，等的过程中，时不时刷刷微博、朋友圈。 总结： 同步与异步，重点在于消息通知的方式; 阻塞与非阻塞，重点在于等消息时候的行为。 demo 同步阻塞：小明在柜台干等着拿奶茶； 同步非阻塞：小明在柜台边刷微博边等着拿奶茶； 异步阻塞：小明拿着小票啥都不干，一直等着店员通知他拿奶茶； 异步非阻塞：小明拿着小票，刷着微博，等着店员通知他拿奶茶。 IO复用在一个进程处理所有的并发I/O呢?答案是有的，这就是I/O复用技术。 最初级的I/O复用所谓的I/O复用，就是多个I/O可以复用一个进程。当一个连接过来时，我们不阻塞住，这样一个进程可以同时处理多个连接了。比如一个进程接受了10000个连接，这个进程每次从头到尾的问一遍这10000个连接：“有I/O事件没？有的话就交给我处理，没有的话我一会再来问一遍。”然后进程就一直从头到尾问这10000个连接，如果这1000个连接都没有I/O事件，就会造成CPU的空转，并且效率也很低 升级版的I/O复用上面虽然实现了基础版的I/O复用，但是效率太低了。于是伟大的程序猿们日思夜想的去解决这个问题…终于！我们能不能引入一个代理，这个代理可以同时观察许多I/O流事件呢？当没有I/O事件的时候，这个进程处于阻塞状态；当有I/O事件的时候，这个代理就去通知进程醒来？于是，早期的程序猿们发明了两个代理—select、poll。select、poll代理的原理是这样的： 当连接有I/O流事件产生的时候，就会去唤醒进程去处理。 但是进程并不知道是哪个连接产生的I/O流事件，于是进程就挨个去问：“请问是你有事要处理吗？”……问了99999遍，哦，原来是第100000个进程有事要处理。那么，前面这99999次就白问了，白白浪费宝贵的CPU时间片了 注:select与poll原理是一样的，只不过select只能观察1024个连接，poll可以观察无限个连接。 上面看了，select、poll因为不知道哪个连接有I/O流事件要处理，性能也挺不好的。 那么，如果发明一个代理，每次能够知道哪个连接有了I/O流事件，不就可以避免无意义的空转了吗？ 于是，超级无敌、闪闪发光的epoll被伟大的程序员发明出来了。 epoll代理的原理是这样的： 当连接有I/O流事件产生的时候，epoll就会去告诉进程哪个连接有I/O流事件产生，然后进程就去处理这个进程。 如此，多高效！","categories":[],"tags":[]},{"title":"","slug":"抽象类和接口","date":"2018-09-29T11:08:49.331Z","updated":"2018-09-29T11:08:49.331Z","comments":true,"path":"2018/09/29/抽象类和接口/","link":"","permalink":"http://yoursite.com/2018/09/29/抽象类和接口/","excerpt":"","text":"来自这里https://blog.csdn.net/sunlylorn/article/details/6124319 [TOC] 抽象类和接口抽象类 一个类中如果有一个方法是抽象方法，那么这个类必须定义为抽象类 抽象类是指在 class 前加了 abstract 关键字且存在抽象方法（在类方法 function 关键字前加了 abstract 关键字）的类。 抽象类不能直接实例化，抽象类中只定义（或部分实现）子类需要的方法。子类可以通过继承抽象类并通过实现抽象类中的所有抽象方法，使抽象类具体化。 如果子类需要实例化，前提是它实现了抽象类中的所有抽象方法。如果子类没有全部实现抽象类中的所有抽象方法，那么该子类也是一个抽象类，必须在 class 前面加上 abstract 关键字，并且不能被实例化。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647abstract class Service&#123; /** 抽象类中可以定义变量 */ protected $value1 = 0; private $value2 = 1; public $value3 = 2; /** * 大多数情况下，抽象类至少含有一个抽象方法。抽象方法用abstract关键字声明，其中不能有具体内容。 * 可以像声明普通类方法那样声明抽象方法，但是要以分号而不是方法体结束。也就是说抽象方法在抽象类中不能被实现，也就是没有函数体“&#123;some codes&#125;”。 */ abstract public function say(); abstract public function talk(); /** 也可以定义非抽象方法 */ public function run() &#123; echo \"run function\" .PHP_EOL; &#125;&#125;abstract class A extends Service&#123; public function say() &#123; echo \"say function\" .PHP_EOL; &#125; public function jump() &#123; $this-&gt;run(); &#125;&#125;class MiniA extends A&#123; public function talk() &#123; echo \"talk function \".PHP_EOL; &#125; public function other() &#123; $this-&gt;jump(); $this-&gt;say(); &#125;&#125;$class = new MiniA();$class-&gt;talk();$class-&gt;other(); ​ 接口类PHP接口类interface就是一个类的领导者，指明方向，子类必须完成它指定方法 抽象类提供了具体实现的标准，而接口则是纯粹的模版。接口只定义功能，而不包含实现的内容。接口用关键字 interface 来声明。 interface 是完全抽象的，只能声明方法，而且只能声明 public 的方法，不能声明 private 及 protected 的方法，不能定义方法体，也不能声明实例变量 。然而， interface 却可以声明常量变量 。但将常量变量放在 interface 中违背了其作为接口的作用而存在的宗旨，也混淆了 interface 与类的不同价值。如果的确需要，可以将其放在相应的 abstract class 或 Class 中。 1234567interface Bar&#123; const NAME = 'zhimma'; public function say(); public function talk(); &#125; echo Bar:: NAME; ​ 任何实现接口的类都要实现接口中所定义的所有方法,否则该类必须声明为 abstract 。 1234567891011121314class A implements Bar&#123; public function say() &#123; // TODO: Implement say() method. &#125; public function talk() &#123; // TODO: Implement talk() method. &#125;&#125;abstract class X implements Bar&#123;&#125; ​ 一个类可以在声明中使用 implements 关键字来实现某个接口。这么做之后，实现接口的具体过程和继承一个仅包含抽象方法的抽象类是一样的。一个类可以同时继承一个父类和实现任意多个接口。 extends 子句应该在 implements 子句之前。 PHP 只支持继承自一个父类，因此 extends 关键字后只能跟一个类名。 12345678910111213class Foo&#123;&#125;;class B extends Foo implements Bar&#123; public function say() &#123; // TODO: Implement say() method. &#125; public function talk() &#123; // TODO: Implement talk() method. &#125;&#125; ​ 接口不可以实现另一个接口，但可以继承多个 ​ ​ 抽象类对比接口相同点 两者都是抽象类，都不能实例化。 interface 实现类及 abstract class 的子类都必须要实现已经声明的抽象方法。 不同点 interface 需要实现，要用 implements ，而 abstract class 需要继承，要用 extends 。 一个类可以实现多个 interface ，但一个类只能继承一个 abstract class interface 强调特定功能的实现，而 abstract class 强调所属关系。 尽管 interface 实现类及 abstract class 的子类都必须要实现相应的抽象方法，但实现的形式不同。 interface 中的每一个方法都是抽象方法，都只是声明的 (declaration, 没有方法体 ) ，实现类必须要实现。而 abstract class 的子类可以有选择地实现。 abstract class 中并非所有的方法都是抽象的，只有那些冠有 abstract 的方法才是抽象的，子类必须实现。那些没有 abstract 的方法，在 abstract class 中必须定义方法体 abstract class 的子类在继承它时，对非抽象方法既可以直接继承，也可以覆盖；而对抽象方法，可以选择实现，也可以留给其子类来实现，但此类必须也声明为抽象类。既是抽象类，当然也不能实例化。 abstract class 是 interface 与 class 的中介。 abstract class 在 interface 及 class 中起到了承上启下的作用。一方面， abstract class 是抽象的，可以声明抽象方法，以规范子类必须实现的功能；另一方面，它又可以定义缺省的方法体，供子类直接使用或覆盖。另外，它还可以定义自己的实例变量，以供子类通过继承来使用。 接口中的抽象方法前不用也不能加 abstract 关键字，默认隐式就是抽象方法，也不能加 final关键字来防止抽象方法的继承。而抽象类中抽象方法前则必须加上 abstract 表示显示声明为抽象方法。 接口中的抽象方法默认是 public 的，也只能是 public 的，不能用 private ， protected 修饰符修饰。而抽象类中的抽象方法则可以用 public ， protected 来修饰，但不能用 private 应用场合interface 的应用场合 类与类之间需要特定的接口进行协调，而不在乎其如何实现 作为能够实现特定功能的标识存在，也可以是什么接口方法都没有的纯粹标识。 需要将一组类视为单一的类，而调用者只通过接口来与这组类发生联系。 需要实现特定的多项功能，而这些功能之间可能完全没有任何联系。 abstract 的应用场合在既需要统一的接口，又需要实例变量或缺省的方法的情况下，就可以使用它 定义了一组接口，但又不想强迫每个实现类都必须实现所有的接口。可以用 abstract class 定义一组方法体，甚至可以是空方法体，然后由子类选择自己所感兴趣的方法来覆盖 某些场合下，只靠纯粹的接口不能满足类与类之间的协调，还必需类中表示状态的变量来区别不同的关系。 abstract 的中介作用可以很好地满足这一点。 规范了一组相互协调的方法，其中一些方法是共同的，与状态无关的，可以共享的，无需子类分别实现；而另一些方法却需要各个子类根据自己特定的状态来实现特 定的功能 。","categories":[],"tags":[]},{"title":"","slug":"搞懂JWT","date":"2018-09-29T11:08:49.331Z","updated":"2018-09-29T11:08:49.331Z","comments":true,"path":"2018/09/29/搞懂JWT/","link":"","permalink":"http://yoursite.com/2018/09/29/搞懂JWT/","excerpt":"","text":"搞懂JWT本文基本一字不差的转载至这里 JSON Web Token（JWT）是一个非常轻巧的规范。这个规范允许我们使用JWT在用户和服务器之间传递安全可靠的信息 让我们来假想一下一个场景。在A用户关注了B用户的时候，系统发邮件给B用户，并且附有一个链接“点此关注A用户”。链接的地址可以是这样的https://your.awesome-app.com/make-friend/?from_user=B&amp;target_user=A上面的URL主要通过URL来描述这个当然这样做有一个弊端，那就是要求用户B用户是一定要先登录的。可不可以简化这个流程，让B用户不用登录就可以完成这个操作。JWT就允许我们做到这点。 JWT的组成一个JWT实际上就是一个字符串，它由三部分组成，头部、载荷与签名 载荷（Payload）我们先将上面的添加好友的操作描述成一个JSON对象。其中添加了一些其他的信息，帮助今后收到这个JWT的服务器理解这个JWT。1234567891011121314151617&#123; \"iss\": \"John Wu JWT\", \"iat\": 1441593502, \"exp\": 1441594722, \"aud\": \"www.example.com\", \"sub\": \"jrocket@example.com\", \"from_user\": \"B\", \"target_user\": \"A\"&#125; 这里面的前五个字段都是由JWT的标准所定义的。 iss: 该JWT的签发者 sub: 该JWT所面向的用户 aud: 接收该JWT的一方 exp(expires): 什么时候过期，这里是一个Unix时间戳 iat(issued at): 在什么时候签发的 这些定义都可以在标准中找到。将上面的JSON对象进行[base64编码]可以得到下面的字符串。这个字符串我们将它称作JWT的Payload（载荷）。 eyJpc3MiOiJKb2huIFd1IEpXVCIsImlhdCI6MTQ0MTU5MzUwMiwiZXhwIjoxNDQxNTk0NzIyLCJhdWQiOiJ3d3cuZXhhbXBsZS5jb20iLCJzdWIiOiJqcm9ja2V0QGV4YW1wbGUuY29tIiwiZnJvbV91c2VyIjoiQiIsInRhcmdldF91c2VyIjoiQSJ9 如果你使用Node.js，可以用Node.js的包base64url来得到这个字符串1234567var base64url = require('base64url')var header = &#123; \"from_user\": \"B\", \"target_user\": \"A\"&#125;console.log(base64url(JSON.stringify(header)))// 输出：eyJpc3MiOiJKb2huIFd1IEpXVCIsImlhdCI6MTQ0MTU5MzUwMiwiZXhwIjoxNDQxNTk0NzIyLCJhdWQiOiJ3d3cuZXhhbXBsZS5jb20iLCJzdWIiOiJqcm9ja2V0QGV4YW1wbGUuY29tIiwiZnJvbV91c2VyIjoiQiIsInRhcmdldF91c2VyIjoiQSJ9 小知识：Base64是一种编码，也就是说，它是可以被翻译回原来的样子来的。它并不是一种加密过程。 头部（Header）JWT还需要一个头部，头部用于描述关于该JWT的最基本的信息，例如其类型以及签名所用的算法等。这也可以被表示成一个JSON对象。1234567&#123; \"typ\": \"JWT\", \"alg\": \"HS256\"&#125; 在这里，我们说明了这是一个JWT，并且我们所用的签名算法（后面会提到）是HS256算法。对它也要进行Base64编码，之后的字符串就成了JWT的Header（头部）。eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9 签名（签名）将上面的两个编码后的字符串都用句号.连接在一起（头部在前），就形成了yJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJmcm9tX3VzZXIiOiJCIiwidGFyZ2V0X3VzZXIiOiJBIn0这一部分的过程在node-jws的源码中有体现 最后，我们将上面拼接完的字符串用HS256算法进行加密。在加密的时候，我们还需要提供一个密钥（secret）。如果我们用mystar作为密钥的话，那么就可以得到我们加密后的内容rSWamyAYwuHCo7IFAgd1oRpSP7nzL7BF5t7ItqpKViM这一部分又叫做签名。 最后将这一部分签名也拼接在被签名的字符串后面，我们就得到了完整的JWTeyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJmcm9tX3VzZXIiOiJCIiwidGFyZ2V0X3VzZXIiOiJBIn0.rSWamyAYwuHCo7IFAgd1oRpSP7nzL7BF5t7ItqpKViM 于是，我们就可以将邮件中的URL改成https://your.awesome-app.com/make-friend/?jwt=eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJmcm9tX3VzZXIiOiJCIiwidGFyZ2V0X3VzZXIiOiJBIn0.rSWamyAYwuHCo7IFAgd1oRpSP7nzL7BF5t7ItqpKViM这样就可以安全地完成添加好友的操作了！且慢，我们一定会有一些问题： 签名的目的是什么？ Base64是一种编码，是可逆的，那么我的信息不就被暴露了吗？让我逐一为你说明。 签名的目的最后一步签名的过程，实际上是对头部以及载荷内容进行签名。一般而言，加密算法对于不同的输入产生的输出总是不一样的。对于两个不同的输入，产生同样的输出的概率极其地小（有可能比我成世界首富的概率还小）。所以，我们就把“不一样的输入产生不一样的输出”当做必然事件来看待吧。 所以，如果有人对头部以及载荷的内容解码之后进行修改，再进行编码的话，那么新的头部和载荷的签名和之前的签名就将是不一样的。而且，如果不知道服务器加密的时候用的密钥的话，得出来的签名也一定会是不一样的。 服务器应用在接受到JWT后，会首先对头部和载荷的内容用同一算法再次签名。那么服务器应用是怎么知道我们用的是哪一种算法呢？别忘了，我们在JWT的头部中已经用alg字段指明了我们的加密算法了。 如果服务器应用对头部和载荷再次以同样方法签名之后发现，自己计算出来的签名和接受到的签名不一样，那么就说明这个Token的内容被别人动过的，我们应该拒绝这个Token，返回一个HTTP 401 Unauthorized响应。 信息会暴露？是的。 所以，在JWT中，不应该在载荷里面加入任何敏感的数据。在上面的例子中，我们传输的是用户的User ID。这个值实际上不是什么敏感内容，一般情况下被知道也是安全的。 但是像密码这样的内容就不能被放在JWT中了。如果将用户的密码放在了JWT中，那么怀有恶意的第三方通过Base64解码就能很快地知道你的密码了。 JWT的适用场景我们可以看到，JWT适合用于向Web应用传递一些非敏感信息。例如在上面提到的完成加好友的操作，还有诸如下订单的操作等等。 其实JWT还经常用于设计用户认证和授权系统，甚至实现Web应用的单点登录。","categories":[],"tags":[]},{"title":"","slug":"基于Docker容器的MySQL主从配置","date":"2018-09-29T11:08:49.330Z","updated":"2018-09-29T11:08:49.330Z","comments":true,"path":"2018/09/29/基于Docker容器的MySQL主从配置/","link":"","permalink":"http://yoursite.com/2018/09/29/基于Docker容器的MySQL主从配置/","excerpt":"","text":"[TOC] 基于Docker容器的MySQL主从配置我本机的镜像 1234docker imagesREPOSITORY TAG IMAGE ID ssh_network_vim_lnmp_redis_swoole_supervisor latest 6da5efb40932 环境搭建及MySQL安装步骤省略，根据已有的镜像创建容器 master数据库 docker run -it -d --privileged=true --name master -p 33060:3306 -p 220:22 -p 8080:80 -p 1024:1024 -p 16379:6379 -p 9001:9001 -v E:\\www\\:/home/www ssh_network_vim_lnmp_redis_swoole_supervisor /usr/sbin/init slave1数据库 docker run -it -d --privileged=true --name slave1 -p 33061:3306 -p 221:22 -p 8081:80 -p 2024:1024 -p 26379:6379 -p 9002:9001 -v E:\\www\\:/home/www ssh_network_vim_lnmp_redis_swoole_supervisor /usr/sbin/init slave2数据库 docker run -it -d --privileged=true --name slave2 -p 33062:3306 -p 222:22 -p 8082:80 -p 3024:1024 -p 36379:6379 -p 9003:9001 -v E:\\www\\:/home/www ssh_network_vim_lnmp_redis_swoole_supervisor /usr/sbin/init ​ …… slaveN binlog方式master数据库真实机IP：192.168.2.107 容器IP:172.17.0.2 修改MySQL配置文件(my.cnf)12log-bin=mysql-bin #启动二进制文件 server_id=1 #服务器ID 附一份全一点的配置,指定需要同步的数据库和不需要同步的数据库 12345678910[mysqld]server-id=1log-bin=mysql-binlog-bin-index=master-bin.indexbinlog_format=mixed // binlog 日志文件格式sync-binlog=1 //binlog-ignore-db=mysqlbinlog-ignore-db=productbinlog-do-db=testbinlog-do-db=local 重启MySQL； 创建复制用户12345671. CREATE USER 'zhimma'@'%' IDENTIFIED BY '123456'; GRANT REPLICATION SLAVE ON . TO 'zhimma'@'%'; 或者2. grant replication slave on *.* to 'zhimma'@'%' identified by '123456';SHOW MASTER STATUS; 查看MySQLmaster status```123456789```mysqlmysql&gt; show master status;+------------------+----------+--------------+------------------+-------------------+| File | Position | Binlog_Do_DB | Binlog_Ignore_DB | Executed_Gtid_Set |+------------------+----------+--------------+------------------+-------------------+| mysql-bin.000001 | 998 | | | |+------------------+----------+--------------+------------------+-------------------+1 row in set (0.00 sec) 如果是项目中途使用主从复制，可以使用下面方法迁移数据 锁定所有表 12mysql&gt; FLUSH TABLES WITH READ LOCK;Query OK, 0 rows affected (2.59 sec) 备份表 1[root@b04f945297ac ~]# mysqldump -uroot -p123456 --all-databases -l -F &gt;/tmp/all_db.sql 解锁 12mysql&gt; UNLOCK TABLES; Query OK, 0 rows affected (0.00 sec) 传输数据到从库 1scp -P 221/222 /tmp/all_db.sql root@192.168.2.107:/tmp slave数据库修改server-uuid将/var/lib/mysql/auto.conf 12[auto]server-uuid=f781e2b4-28e1-11e8-a1c0-0242ac110001 修改MySQL配置文件(my.cnf)12log-bin=mysql-bin #启动二进制文件 server_id=101 #服务器ID 重启MySQL； 导入主备份文件1[root@9ae039d46474 tmp]# mysql -uroot -p123456 &lt; /tmp/all_db.sql 开启slave同步1234567CHANGE MASTER TO MASTER_HOST=&apos;192.168.2.107&apos;,MASTER_PORT=33060, MASTER_USER=&apos;zhimma&apos;, MASTER_PASSWORD=&apos;123456&apos;, MASTER_LOG_FILE=&apos;mysql-bin.000001&apos;, MASTER_LOG_POS=998;或者CHANGE MASTER TO MASTER_HOST=&apos;172.17.0.2&apos;, MASTER_USER=&apos;zhimma&apos;, MASTER_PASSWORD=&apos;123456&apos;, MASTER_LOG_FILE=&apos;mysql-bin.000001&apos;, MASTER_LOG_POS=998;start slave 查看是否同步成功slave连接master成功12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364mysql&gt; start slave;Query OK, 0 rows affected (0.43 sec)mysql&gt; show slave status\\G;*************************** 1. row *************************** Slave_IO_State: Queueing master event to the relay log Master_Host: 192.168.2.107 Master_User: zhimma Master_Port: 33060 Connect_Retry: 60 Master_Log_File: mysql-bin.000003 Read_Master_Log_Pos: 4 Relay_Log_File: 06e5a050e74b-relay-bin.000001 Relay_Log_Pos: 4 Relay_Master_Log_File: mysql-bin.000001 Slave_IO_Running: Yes Slave_SQL_Running: Yes Replicate_Do_DB: Replicate_Ignore_DB: Replicate_Do_Table: Replicate_Ignore_Table: Replicate_Wild_Do_Table: Replicate_Wild_Ignore_Table: Last_Errno: 0 Last_Error: Skip_Counter: 0 Exec_Master_Log_Pos: 998 Relay_Log_Space: 1483 Until_Condition: None Until_Log_File: Until_Log_Pos: 0 Master_SSL_Allowed: No Master_SSL_CA_File: Master_SSL_CA_Path: Master_SSL_Cert: Master_SSL_Cipher: Master_SSL_Key: Seconds_Behind_Master: 0Master_SSL_Verify_Server_Cert: No Last_IO_Errno: 0 Last_IO_Error: Last_SQL_Errno: 0 Last_SQL_Error: Replicate_Ignore_Server_Ids: Master_Server_Id: 1 Master_UUID: f781e2b4-28e1-11e8-a1c0-0242ac110002 Master_Info_File: /var/lib/mysql/master.info SQL_Delay: 0 SQL_Remaining_Delay: NULL Slave_SQL_Running_State: Slave has read all relay log; waiting for more updates Master_Retry_Count: 86400 Master_Bind: Last_IO_Error_Timestamp: Last_SQL_Error_Timestamp: Master_SSL_Crl: Master_SSL_Crlpath: Retrieved_Gtid_Set: Executed_Gtid_Set: Auto_Position: 0 Replicate_Rewrite_DB: Channel_Name: Master_TLS_Version: 1 row in set (0.20 sec) 12Slave_IO_Running: YesSlave_SQL_Running: Yes 同步成功 http://www.cnblogs.com/clsn/p/8150036.html","categories":[],"tags":[]},{"title":"","slug":"php-fpm如何合理设置max_chindren和pm模式，包括开启status监听","date":"2018-09-29T11:08:49.329Z","updated":"2018-09-29T11:08:49.329Z","comments":true,"path":"2018/09/29/php-fpm如何合理设置max_chindren和pm模式，包括开启status监听/","link":"","permalink":"http://yoursite.com/2018/09/29/php-fpm如何合理设置max_chindren和pm模式，包括开启status监听/","excerpt":"","text":"[TOC] php-fpm如何合理设置max_chindren和pm模式，包括开启status监听开启status获得执行状态启用php-fpm状态功能123vi /etc/php-fpm.d/www.conf修改：pm.status_path = /status nginx配置1234567891011server &#123; . . . location ~ ^/status$ &#123; include fastcgi_params; fastcgi_pass 127.0.0.1:9000; fastcgi_param SCRIPT_FILENAME $fastcgi_script_name; &#125;&#125; 重启nginx和php-fpm打开status页面123456789101112131415[root@b04f945297ac ~]# curl http://visit.ma/statuspool: wwwprocess manager: dynamicstart time: 23/Jul/2018:15:32:09 +0800start since: 1055accepted conn: 9listen queue: 0max listen queue: 0listen queue len: 128idle processes: 5active processes: 1total processes: 6max active processes: 1max children reached: 0slow requests: 0 参数详解pool – fpm池子名称，大多数为wwwprocess manager – 进程管理方式,值：static, dynamic or ondemand. dynamicstart time – 启动日期,如果reload了php-fpm，时间会更新start since – 运行时长accepted conn – 当前池子接受的请求数listen queue – 请求等待队列，如果这个值不为0，那么要增加FPM的进程数量max listen queue – 请求等待队列最高的数量listen queue len – socket等待队列长度idle processes – 空闲进程数量active processes – 活跃进程数量total processes – 总进程数量max active processes – 最大的活跃进程数量（FPM启动开始算）max children reached - 大道进程最大数量限制的次数，如果这个数量不为0，那说明你的最大进程数量太小了，请改大一点。slow requests – 启用了php-fpm slow-log，缓慢请求的数量 php-fpm其他参数php-fpm状态页比较个性化的一个地方是它可以带参数，可以带参数json、xml、html并且前面三个参数可以分别和full做一个组合 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849curl http://visit.ma/status?jsoncurl http://visit.ma/status?xmlcurl http://visit.ma/status?htmlcurl http://visit.ma/status?full[root@b04f945297ac ~]# curl http://visit.ma/status?fullpool: wwwprocess manager: dynamicstart time: 23/Jul/2018:15:32:09 +0800start since: 1240accepted conn: 10listen queue: 0max listen queue: 0listen queue len: 128idle processes: 5active processes: 1total processes: 6max active processes: 1max children reached: 0slow requests: 0************************pid: 5466state: Idlestart time: 23/Jul/2018:15:32:09 +0800start since: 1240requests: 2request duration: 99request method: GETrequest URI: /statuscontent length: 0user: -script: -last request cpu: 0.00last request memory: 2097152************************pid: 5467state: Idlestart time: 23/Jul/2018:15:32:09 +0800start since: 1240requests: 2request duration: 184request method: GETrequest URI: /status?fullcontent length: 0user: -script: -last request cpu: 0.00last request memory: 2097152 这里重点说下full参数详解 pid – 进程PID，可以单独kill这个进程. You can use this PID to kill a long running process.state – 当前进程的状态 (Idle, Running, …)start time – 进程启动的日期start since – 当前进程运行时长requests – 当前进程处理了多少个请求request duration – 请求时长（微妙）request method – 请求方法 (GET, POST, …)request URI – 请求URIcontent length – 请求内容长度 (仅用于 POST)user – 用户 (PHP_AUTH_USER) (or ‘-’ 如果没设置)script – PHP脚本 (or ‘-’ if not set)last request cpu – 最后一个请求CPU使用率last request memorythe - 上一个请求使用的内存 合理设置max_chindren和pm模式 使用htop命令查看单个php-fpm所申请的VIRT大小，我32G服务器是400左右（实际要除以8=M，就是：50M左右），如果按照每个进程消耗50M*1.5倍=75M左右，如果你的服务器内存是32G，我们假设可用于php-fpm的内存为60%=20G，则：20*1024/75=273，所以，一般我们建议max_chindren最大为273，最好还是设置为：8的倍数，所以我设置为256. 然后我们可以根据域名/status的结果来合理设置其他参数（pm.start_servers和pm.min_spare_servers和pm.max_spare_servers） 在php.ini中，我们可以看到memory_limit有一句这样的原文，Maximum amount of memory a script may consume (128MB)，就是说单个进程使用的最大内存大小，这个参数吧，当然不能低于刚刚计算的75M了，一般我们可以设置为3倍，则75*3=225M左右（建议：128，256，512，1024…） 这里假如有攻击的话，max_chindren=256，memory_limit=256，256*256=64G，很明显会导致内存爆满，所以如果想又保持性能，又能一定程度上防止内存爆满，可以将max_chindren设置的低一点，memory_limit可以设置为每个进程消耗的值（一般不建议低于128M吧，如果是独立服务器的话）。 PHP-FPM 子进程数量，是不是越多越好？当然不是，pm.max_chindren，进程多了，增加进程管理的开销以及上下文切换的开销。 更核心的是，能并发执行的 php-fpm 进程不会超过 cpu 个数。 如何设置，取决于你的代码 如果代码是 CPU 计算密集型的，pm.max_chindren 不能超过 CPU 的内核数。 如果不是，那么将 pm.max_chindren 的值大于 CPU 的内核数，是非常明智的。国外技术大拿给出这么个公式： 在 N + 20% 和 M/m 之间。 N 是 CPU 内核数量。M 是 PHP 能利用的内存数量。m 是每个 PHP 进程平均使用的内存数量。适用于 dynamic 方式。 static方式：M/(m * 1.2) 当然，还有一种保险的方式，来配置 max_children。适用于 static 方式。 先把 max_childnren 设置成一个比较大的值。稳定运行一段时间后，观察 php-fpm 的 status 里的 maxactive processes 是多少然后把 max_children 配置比它大一些就可以了。pm.max_requests：指的是每个子进程在处理了多少个请求数量之后就重启。 这个参数，理论上可以随便设置，但是为了预防内存泄漏的风险，还是设置一个合理的数比较好 所以，我的服务器32G内存设置为： 123456memory_limit = 256Mpm = dynamicpm.max_children = 256pm.start_servers = 32pm.min_spare_servers = 16pm.max_spare_servers = 32 pm.max_children：静态方式下开启的php-fpm进程数量。 pm.start_servers：动态方式下的起始php-fpm进程数量。 pm.min_spare_servers：动态方式下的最小php-fpm进程数量。 pm.max_spare_servers：动态方式下的最大php-fpm进程数量。 如果dm设置为static，那么其实只有pm.max_children这个参数生效。系统会开启设置数量的php-fpm进程。 如果dm设置为static，那么其实只有pm.max_children这个参数生效。系统会开启设置数量的php-fpm进程。 http://www.zhanghongliang.com/article/1300 http://www.ttlsa.com/php/use-php-fpm-status-page-detail/","categories":[],"tags":[]},{"title":"","slug":"redis安装与配置","date":"2018-09-29T11:08:49.329Z","updated":"2018-09-29T11:08:49.329Z","comments":true,"path":"2018/09/29/redis安装与配置/","link":"","permalink":"http://yoursite.com/2018/09/29/redis安装与配置/","excerpt":"","text":"[TOC] redis安装与配置安装 redis下载地址 解压缩tar -zxf redis-4.0.2.tar.gz cd redis-4.0.2 make cd src make install ​ 到此就安装完成。但是，由于安装redis的时候，我们没有选择安装路径，故是默认位置安装。在此，我们可以将可执行文件和配置文件移动到习惯的目录。 /usr/local 123456mkdir -p /usr/local/redis/bin mkdir -p /usr/local/redis/etc cd /usr/local/redis-4.0.2 mv ./redis.conf /usr/local/redis/etc cd src mv mkreleasehdr.sh redis-benchmark redis-check-aof redis-check-dump redis-cli redis-server redis-sentinel /usr/local/redis/bin 比较重要的3个可执行文件：redis-server：Redis服务器程序redis-cli：Redis客户端程序，它是一个命令行操作工具。也可以使用telnet根据其纯文本协议操作。redis-benchmark：Redis性能测试工具，测试Redis在你的系统及配置下的读写性能 Redis的启动命令：/usr/local/redis/bin/redis-server或cd /usr/local/redis/bin./redis-server /usr/local/redis/etc/redis.conf为redis-server指定配置文件 Redis的配置下面列举了Redis中的一些常用配置项：daemonize 如果需要将Redis服务以守护进程在后台运行，则把该项的值改为yes pidfile 配置多个pid的地址，默认在/var/run/redis/pid bind 绑定ip，设置后只接受来自该ip的请求 port 监听端口，默认是6379 timeout 客户端连接超时的设定，单位是秒 loglevel 分为4级，debug、verbose、notice、warning logfile 配置log文件地址 databases 设置数据库的个数，默认使用的数据库为0 save 设置redis进行数据库镜像的频率 rdbcompression 在进行镜像备份时，是否进行压缩 Dbfilename 镜像备份文件的文件名 Dir 数据库镜像备份文件的存放路径 Slaveof 设置数据库为其他数据库的从数据库 Masterauth 主数据库连接需要的密码验证Requirepass 设置登录时，需要使用的密码Maxclients 设置同时连接的最大客户端数量Maxmemory 设置redis能够使用的最大内存Appendonly 开启append only模式Appendfsync 设置对appendonly.aof文件同步的频率vm-enabled 是否开启虚拟内存支持vm-swap-file 设置虚拟内存的交换文件路径vm-max-memory 设置redis能够使用的最大虚拟内存vm-page-size 设置虚拟内存的页大小vm-pages 设置交换文件的总的page数量vm-max-threads 设置VMIO同时使用的线程数量Glueoutputbuf 把小的输出缓存存放在一起hash-max-zipmap-entries 设置hash的临界值Activerehashing 重新hash 修改redis的配置参数：vi /usr/local/redis/etc/redis.conf将daemonize no改为daemonize yes，保存退出。再来启动redis服务器cd /usr/local/redis/bin./redis-server /usr/local/redis/etc/redis.conf 启动redis并指定配置文件 ps aux | grep redis 查看redis是否启动成功 netstat -tlun 查看主机的6379端口是否在使用（监听） ./redis-cli 打开redis的客户端 quit 退出redis的客户端 pkill redis-server 关闭redis服务器 ./redis-cli shutdown 也可以通过这条命令关闭redis服务器 自启动只有两个步骤： 设置redis.conf中daemonize为yes,确保守护进程开启。 编写开机自启动脚本 基本原理为：系统开机启动时会去加载/etc/init.d/下面的脚本，通常而言每个脚本文件会自定义实现程序的启动；若想将新的程序开机自启动，只需在该目录下添加一个自定义启动程序的脚本，然后设置相应规则即可。如在这里我们在/etc/init.d/下新建一个 redis 的脚本，开机启动时会去加载执行该脚本。 1xxxxxxxxxx #!/bin/sh## Simple Redis init.d script conceived to work on Linux systems# as it does use of the /proc filesystem.REDISPORT=6379EXEC=/usr/local/redis/bin/redis-serverCLIEXEC=/usr/local/redis/bin/redis-cliPIDFILE=/var/run/redis_$&#123;REDISPORT&#125;.pidCONF=&quot;/usr/local/redis/etc/$&#123;REDISPORT&#125;.conf&quot;case &quot;$1&quot; in start) if [ -f $PIDFILE ] then echo &quot;$PIDFILE exists, process is already running or crashed&quot; else echo &quot;Starting Redis server...&quot; $EXEC $CONF fi ;; stop) ​ 设置可执行权限：chmod 755 redis 启动/etc/init.d/redis start 设置开机自启动:chkconfig redis on https://blog.csdn.net/qq_38158631/article/details/78644274 https://blog.csdn.net/baidu_30000217/article/details/51558408","categories":[],"tags":[]},{"title":"","slug":"SSH 密钥创建及密钥登录","date":"2018-09-29T11:08:49.328Z","updated":"2018-09-29T11:08:49.328Z","comments":true,"path":"2018/09/29/SSH 密钥创建及密钥登录/","link":"","permalink":"http://yoursite.com/2018/09/29/SSH 密钥创建及密钥登录/","excerpt":"","text":"SSH 密钥创建及密钥登录本文基本引自这里：https://blog.csdn.net/nahancy/article/details/79059135 在我们平时使用Linux系统时候，通常使用的Linux SSH登录方式是用户名加密码的登录方式，今天来探讨另外的一种相对安全的登录方式——密钥登录 我们知道SSH登录是用的RSA非对称加密的，所以我们在SSH登录的时候就可以使用RSA密钥登录，SSH有专门创建SSH密钥的工具ssh-keygen，下面就来一睹风采。 首先进入Linux系统的用户目录下的.ssh目录下，root用户是/root/.ssh，普通用户是/home/您的用户名/.ssh，我们以root用户为例 123[root@b04f945297ac .ssh]# cd /root/.ssh/[root@b04f945297ac .ssh]# lsknown_hosts 上面是没有创建过ssh秘钥的样子 执行ssh-keygen命令创建密钥对： 123456789101112131415161718192021[root@b04f945297ac .ssh]# ssh-keygen -t rsa -b 4096Generating public/private rsa key pair.Enter file in which to save the key (/root/.ssh/id_rsa): /root/.ssh/zhimma_id_rsaEnter passphrase (empty for no passphrase): Enter same passphrase again: Your identification has been saved in /root/.ssh/zhimma_id_rsa.Your public key has been saved in /root/.ssh/zhimma_id_rsa.pub.The key fingerprint is:SHA256:WrIN4U/dk+1KdTxv0t5zFeXCeWWpvaNtFFMxbkDY2Cw root@b04f945297acThe key&apos;s randomart image is:+---[RSA 4096]----+| Bo oo|| E +o.*|| . ..o*+|| . . . . +=*o|| + S . + o+B|| X + *+|| o o . * *|| . o Bo|| . . =|+----[SHA256]-----+ -b 参数，指定了长度，也可以不加-b参数，直接使用ssh-keygen -t rsa 这里我重新命名了下秘钥文件名 zhimma_id_rsa 密钥生成后会在当前目录下多出两个文件，zhimma_id_rsa和zhimma_id_rsa.pub，其中zhimma_id_rsa是私钥（敲黑板：这个很重要，不能外泄），zhimma_id_rsa.pub这个是公钥 123[root@b04f945297ac .ssh]# lsknown_hosts zhimma_id_rsa zhimma_id_rsa.pub[root@b04f945297ac .ssh]# 放置公钥ssh-copy-id把公钥拷贝到需要登录的远程服务器或Linux系统上，这里可以使用ssh-copy-id ssh-copy-id默认端口是22，如果要重新指定端口，则使用-p 端口号命令 12345678910[root@b04f945297ac .ssh]# ssh-copy-id -i /root/.ssh/zhimma_id_rsa.pub -p 203 root@192.168.2.107 /usr/bin/ssh-copy-id: INFO: Source of key(s) to be installed: &quot;/root/.ssh/zhimma_id_rsa.pub&quot;/usr/bin/ssh-copy-id: INFO: attempting to log in with the new key(s), to filter out any that are already installed/usr/bin/ssh-copy-id: INFO: 1 key(s) remain to be installed -- if you are prompted now it is to install the new keysroot@192.168.2.107&apos;s password: Number of key(s) added: 1Now try logging into the machine, with: &quot;ssh -p &apos;203&apos; &apos;root@192.168.2.107&apos;&quot;and check to make sure that only the key(s) you wanted were added. 这样就把公钥加的指定的服务器上了 尝试登陆下 123[root@b04f945297ac .ssh]# ssh -i /root/.ssh/zhimma_id_rsa -p 203 root@192.168.2.107Last login: Wed Jun 6 04:16:09 2018 from 172.17.0.1[root@e91b4a662023 ~]# 登陆成功！ 手动放置进入远程服务器.ssh目录，创建authorized_keys 文件，赋权限600 123456789[root@01bb4850cc8c .ssh]# touch authorized_keys[root@01bb4850cc8c .ssh]# chmod -R 600 authorized_keys [root@01bb4850cc8c .ssh]# ls -altotal 16drwx------ 1 root root 4096 Jun 6 07:02 .dr-xr-x--- 1 root root 4096 Apr 27 08:15 ..-rw------- 1 root root 0 Jun 6 07:02 authorized_keysdrwxr-xr-x 2 root root 4096 Jun 6 07:02 dd-rw-r--r-- 1 root root 824 Mar 16 08:59 known_hosts 复制zhimma_id_rsa.pub的内容进入这个文件 尝试登陆 123[root@b04f945297ac .ssh]# ssh -i /root/.ssh/zhimma_id_rsa -p 204 root@192.168.2.107Last login: Wed Jun 6 04:18:46 2018 from 172.17.0.1[root@01bb4850cc8c ~]# 登陆成功！ ssh-keygen可用的参数12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455ssh-keygen可用的参数选项有： -a trials 在使用 -T 对 DH-GEX 候选素数进行安全筛选时需要执行的基本测试数量。 -B 显示指定的公钥/私钥文件的 bubblebabble 摘要。 -b bits 指定密钥长度。对于RSA密钥，最小要求768位，默认是2048位。DSA密钥必须恰好是1024位(FIPS 186-2 标准的要求)。 -C comment 提供一个新注释 -c 要求修改私钥和公钥文件中的注释。本选项只支持 RSA1 密钥。 程序将提示输入私钥文件名、密语(如果存在)、新注释。 -D reader 下载存储在智能卡 reader 里的 RSA 公钥。 -e 读取OpenSSH的私钥或公钥文件，并以 RFC 4716 SSH 公钥文件格式在 stdout 上显示出来。 该选项能够为多种商业版本的 SSH 输出密钥。 -F hostname 在 known_hosts 文件中搜索指定的 hostname ，并列出所有的匹配项。 这个选项主要用于查找散列过的主机名/ip地址，还可以和 -H 选项联用打印找到的公钥的散列值。 -f filename 指定密钥文件名。 -G output_file 为 DH-GEX 产生候选素数。这些素数必须在使用之前使用 -T 选项进行安全筛选。 -g 在使用 -r 打印指纹资源记录的时候使用通用的 DNS 格式。 -H 对 known_hosts 文件进行散列计算。这将把文件中的所有主机名/ip地址替换为相应的散列值。 原来文件的内容将会添加一个&quot;.old&quot;后缀后保存。这些散列值只能被 ssh 和 sshd 使用。 这个选项不会修改已经经过散列的主机名/ip地址，因此可以在部分公钥已经散列过的文件上安全使用。 -i 读取未加密的SSH-2兼容的私钥/公钥文件，然后在 stdout 显示OpenSSH兼容的私钥/公钥。 该选项主要用于从多种商业版本的SSH中导入密钥。 -l 显示公钥文件的指纹数据。它也支持 RSA1 的私钥。 对于RSA和DSA密钥，将会寻找对应的公钥文件，然后显示其指纹数据。 -M memory 指定在生成 DH-GEXS 候选素数的时候最大内存用量(MB)。 -N new_passphrase 提供一个新的密语。 -P passphrase 提供(旧)密语。 -p 要求改变某私钥文件的密语而不重建私钥。程序将提示输入私钥文件名、原来的密语、以及两次输入新密语。 -q 安静模式。用于在 /etc/rc 中创建新密钥的时候。 -R hostname 从 known_hosts 文件中删除所有属于 hostname 的密钥。 这个选项主要用于删除经过散列的主机(参见 -H 选项)的密钥。 -r hostname 打印名为 hostname 的公钥文件的 SSHFP 指纹资源记录。 -S start 指定在生成 DH-GEX 候选模数时的起始点(16进制)。 -T output_file 测试 Diffie-Hellman group exchange 候选素数(由 -G 选项生成)的安全性。 -t type 指定要创建的密钥类型。可以使用：&quot;rsa1&quot;(SSH-1) &quot;rsa&quot;(SSH-2) &quot;dsa&quot;(SSH-2) -U reader 把现存的RSA私钥上传到智能卡 reader -v 详细模式。ssh-keygen 将会输出处理过程的详细调试信息。常用于调试模数的产生过程。 重复使用多个 -v 选项将会增加信息的详细程度(最大3次)。 -W generator 指定在为 DH-GEX 测试候选模数时想要使用的 generator -y 读取OpenSSH专有格式的公钥文件，并将OpenSSH公钥显示在 stdout 上。 ###","categories":[],"tags":[]},{"title":"","slug":"elk stack实践","date":"2018-09-29T11:08:49.328Z","updated":"2018-10-05T15:16:45.081Z","comments":true,"path":"2018/09/29/elk stack实践/","link":"","permalink":"http://yoursite.com/2018/09/29/elk stack实践/","excerpt":"","text":"[TOC] 环境说明：真实机IP：192.168.1.198，其中 服务器 IP 说明 Redis-server 172.17.0.3 nginx服务器1 Project1(logstash) 172.17.0.2 nginx服务器2 Project2(logstash) 172.17.0.3 服务器1 Elk 172.17.0.6 服务器2 1234567docker run -it -d --privileged=true --name redis-master -p 63791:6379 -p 221:22 -v /Users/zhimma/Data/www/:/data/www/ 67793c412ed1 /usr/sbin/initdocker run -it -d --privileged=true --name project1 -p 50441:5044 -p 8081:80 -p 10241:1024 -p 222:22 -v /Users/zhimma/Data/www/:/data/www/ 67793c412ed1 /usr/sbin/initdocker run -it -d --privileged=true --name project2 -p 50442:5044 -p 8082:80 -p 10242:1024 -p 223:22 -v /Users/zhimma/Data/www/:/data/www/ 67793c412ed1 /usr/sbin/initdocker run -it -d --privileged=true --name elk -p 50443:5044 -p 15602:5601 -p 224:22 -p 8083:80 -p 10243:1024 -v /Users/zhimma/Data/www/:/data/www/ 67793c412ed1 /usr/sbin/init 123456789101112docker psCONTAINER ID PORTS NAMES3f139b00a661 3306/tcp, 6379/tcp, 0.0.0.0:224-&gt;22/tcp, 0.0.0.0:8083-&gt;80/tcp, 0.0.0.0:10243-&gt;1024/tcp, 0.0.0.0:50443-&gt;5044/tcp, 0.0.0.0:15602-&gt;5601/tcp elke08ca55e124d 3306/tcp, 6379/tcp, 0.0.0.0:223-&gt;22/tcp, 0.0.0.0:8082-&gt;80/tcp, 0.0.0.0:10242-&gt;1024/tcp, 0.0.0.0:50442-&gt;5044/tcp project23b670e7a9ad1 3306/tcp, 6379/tcp, 0.0.0.0:222-&gt;22/tcp, 0.0.0.0:8081-&gt;80/tcp, 0.0.0.0:10241-&gt;1024/tcp, 0.0.0.0:50441-&gt;5044/tcp project1dbefa01b3393 80/tcp, 3306/tcp, 0.0.0.0:221-&gt;22/tcp, 0.0.0.0:63791-&gt;6379/tcp redis-master 所有服务器关闭防火墙 将软件和配置文件放在宿主机目录，各个容器就可以共享使用了 redis-master安装logstash服务器安装redis,进行配置,开机启动 project服务器安装logstash安装java环境1yum install java ###下载logstash 12345mkdir /opt/downloadsmkdir /opt/softcd /opt/downloadswget https://artifacts.elastic.co/downloads/logstash/logstash-6.4.1.tar.gztar -zxvf logstash-6.4.1.tar.gz -C /opt/soft/ 配置logstash1234vi /opt/soft/logstash-6.4.0/config/jvm.options-Xms2g-Xmx2g 安装配置supervisor 参考：https://blog.csdn.net/donggege214/article/details/80264811 vi /etc/supervisord.conf 123456[unix_http_server]file=/var/run/supervisor/supervisor.sock chmod=0700chown=root:root[include]files = supervisord.d/*.conf vi /etc/supervisord/l.conf 12345678[program:elk-l]command=/opt/soft/logstash-6.4.0/bin/logstash -r -f /data/www/elk/conf/project/*.confautostart=trueautorestart=trueuser=rootredirect_stderr=truestdout_logfile=/var/log/elk/l.logpriority=10 vi /data/www/elk/conf/project/project.conf 12345678910111213141516171819202122232425262728293031input &#123; file &#123; path =&gt; [ &quot;/data/www/project-mdl/trunk/Common/Runtime/Apps/*.log&quot; ] start_position =&gt; &quot;beginning&quot; ignore_older =&gt; 0 sincedb_path =&gt; &quot;/dev/null&quot; type =&gt; &quot;Api&quot; codec =&gt; multiline &#123; pattern =&gt; &quot;^\\[&quot; negate =&gt; true what =&gt; &quot;previous&quot; &#125; &#125;&#125;filter &#123;&#125;output &#123; if [type] == &quot;Api&quot; &#123; redis &#123; host =&gt; &apos;192.168.1.198&apos; port =&gt; &apos;63791&apos; db =&gt; &apos;1&apos; data_type =&gt; &quot;list&quot; key =&gt; &quot;project&quot; &#125; &#125; stdout &#123; codec =&gt; rubydebug &#125;&#125; 重启supervisor，如果数据写入redis-master服务器，那么就代表项目日志收集成功 ELK服务器安装java环境1yum install java 安装elk123456789mkdir /opt/downloadsmkdir /opt/softcd /opt/downloadswget https://artifacts.elastic.co/downloads/elasticsearch/elasticsearch-6.4.1.tar.gzwget https://artifacts.elastic.co/downloads/kibana/kibana-6.4.1-linux-x86_64.tar.gzwget https://artifacts.elastic.co/downloads/logstash/logstash-6.4.1.tar.gztar -zxvf logstash-6.4.1.tar.gz -C /opt/soft/tar -zxvf elasticsearch-6.4.1.tar.gz -C /opt/soft/tar -zxvf kibana-6.4.1-linux-x86_64.tar.gz -C /opt/soft/ 配置elk创建elastic用户由于 Elasticsearch 不允许也不推荐使用 root 用户来运行，因此需要新建一个用户来启动 Elasticsearch。 12adduser elastic #创建elastic用户passwd elastic #修改elastic密码 创建ES数据日志文件夹12345cd /data/www/elkmkdir data #创建数据目录mkdir log #创建日志目录mkdir bak #创建备份目录chown -R elatic /data/www/elk/ #修改目录拥有者为 elastic 优化文件句柄数以及用户可用进程数新版 Elasticsearch 要求其可用的文件句柄至少为 65536，同时要求其进程数限制至少为 2048，可用按照下面的指令进行修改。 分别对应以下两个报错信息： max file descriptors [4096] for elasticsearch process is too low, increase to at least [65536]； max number of threads [1024] for user [es] is too low, increase to at least [2048]。 12345678vim /etc/security/limits.conf* soft nofile 655350* hard nofile 655350* soft nproc 4096* hard nproc 8192elastic soft memlock unlimitedelastic hard memlock unlimited 修改内核交换为了避免不必要的磁盘和内存交换，影响效率，需要将 vm.swappiness 修改为 1。 此外需要修改最大虚拟内存 vm.max_map_count 防止启动时报错：max virtual memory areas vm.max_map_count [65530] likely too low, increase to at least [262144] 123456vim /etc/sysctl.confvm.swappiness = 1vm.max_map_count = 655360sysctl -p # 立即生效 关闭swap并且重启12swapoff -areboot 配置 Elasticsearch 内存占用12345cd /opt/soft/elasticsearch-6.4.1/config/vim jvm.options -Xms2g-Xmx2g 配置 Elasticsearch配置文件12345678[root@3f139b00a661 ~]# grep -n &apos;^[a-z]&apos; /opt/soft/elasticsearch-6.4.0/config/elasticsearch.yml17:cluster.name: elk-demo33:path.data: /data/www/elk/data37:path.logs: /data/www/logs43:bootstrap.memory_lock: false55:network.host: 0.0.0.059:http.port: 9200 安装配置supervisor grep -n &#39;^[a-z]&#39; /etc/supervisord.conf 12345678910111213144:file=/var/run/supervisor/supervisor.sock ; (the path to the socket file)5:chmod=0700 ; sockef file mode (default 0700)6:chown=root:root ; socket file uid:gid owner16:logfile=/var/log/supervisor/supervisord.log ; (main log file;default $CWD/supervisord.log)17:logfile_maxbytes=50MB ; (max main logfile bytes b4 rotation;default 50MB)18:logfile_backups=10 ; (num of main logfile rotation backups;default 10)19:loglevel=info ; (log level;default info; others: debug,warn,trace)20:pidfile=/var/run/supervisord.pid ; (supervisord pidfile;default supervisord.pid)21:nodaemon=false ; (start in foreground if true;default false)22:minfds=1024 ; (min. avail startup file descriptors;default 1024)23:minprocs=200 ; (min. avail process descriptors;default 200)37:supervisor.rpcinterface_factory = supervisor.rpcinterface:make_main_rpcinterface40:serverurl=unix:///var/run/supervisor/supervisor.sock ; use a unix:// URL for a unix socket129:files = /etc/supervisord.d/elk.conf grep &#39;^[a-z]&#39; /etc/supervisord.d/elk.conf 123456789101112131415161718192021command=/opt/soft/elasticsearch-6.4.0/bin/elasticsearchautostart=trueautorestart=trueuser=elasticredirect_stderr=truestdout_logfile=/var/log/elk/e.logpriority=1command=/opt/soft/logstash-6.4.0/bin/logstash -r -f /data/www/elk/conf/elk/*.confautostart=trueautorestart=trueuser=elasticredirect_stderr=truestdout_logfile=/var/log/elk/l.logpriority=10command=/opt/soft/kibana-6.4.0-linux-x86_64/bin/kibanaautostart=trueautorestart=trueuser=elasticredirect_stderr=truestdout_logfile=/var/log/elk/k.logpriority=20 cat /data/www/elk/conf/elk/elk.conf 123456789101112131415161718192021222324252627input &#123; redis &#123; host =&gt; &apos;192.168.1.198&apos; port =&gt; 63791 db =&gt; 1 data_type =&gt; &quot;list&quot; key =&gt; &quot;project&quot; &#125; stdin &#123; codec =&gt; multiline &#123; pattern =&gt; &quot;^\\[&quot; negate =&gt; true what =&gt; &quot;previous&quot; &#125; &#125;&#125;filter &#123;&#125;output &#123; elasticsearch &#123; hosts =&gt; [ &quot;127.0.0.1:9200&quot; ] index =&gt; &quot;project&quot; &#125; stdout &#123; codec =&gt; rubydebug &#125;&#125;","categories":[],"tags":[]},{"title":"","slug":"Nginx配置整理","date":"2018-09-29T11:08:49.327Z","updated":"2018-09-29T11:08:49.327Z","comments":true,"path":"2018/09/29/Nginx配置整理/","link":"","permalink":"http://yoursite.com/2018/09/29/Nginx配置整理/","excerpt":"","text":"Nginx配置整理https://www.zybuluo.com/phper/note/89391 nginx.conf配置概览1234567891011121314151617181920212223242526272829mainevents &#123; ...&#125;http &#123; ... upstram myObject &#123; ... &#125; server1 &#123; ... location &#123; ... &#125; &#125; ... serverN &#123; ... location &#123; ... &#125; &#125;&#125; nginx配置文件主要分为六个区域： main(全局设置)、event(nginx工作模式)、http(http设置)、upstream(负载均衡服务器设置)、server(主机设置)、location(URL匹配)。 main模块1234567891011121314// 来指定Nginx Worker进程运行的用户及用户组，默认由nobody账号运行。user nobody nobody;// 来指定Nginx要快起的子进程数。每个Nginx进程平均耗费10M~12M内存。根据经验一般指定一个进程就足够了，如果是多核CPU，建议数量和CPU数量保持一样即可。worker_processes 1;// 用来定义全局错误日志文件。日志输出级别有debug、info、notice、warn、error、crit可供选择，其中，debug输出日志最为最详细，而crit输出日志最少。#error_log logs/error.log;#error_log logs/error.log notice;#error_log logs/error.log info;// 用来指定进程id的存储文件位置#pid logs/nginx.pid;// 用于指定一个nginx进程最多可以打开的最多文件描述符数目worker_rlimit_nofile 1024; events模块1234events &#123; use kqueue; #mac平台 worker_connections 1024;&#125; use用来指定Nginx的工作模式。Nginx支持的工作模式有select、poll、kqueue、epoll、rtsig和/dev/poll。其中select和poll都是标准的工作模式，kqueue和epoll是高效的工作模式，不同的是epoll用在Linux平台上，而kqueue用在BSD系统中，因为Mac基于BSD,所以Mac也得用这个模式，对于Linux系统，epoll工作模式是首选。 worker_connections用于定义Nginx每个进程的最大连接数，即接收前端的最大请求数，默认是1024。最大客户端连接数由worker_processes和worker_connections决定，即Max_clients=worker_processes*worker_connections，在作为反向代理时，Max_clients变为：Max_clients = worker_processes * worker_connections/4。进程的最大连接数受Linux系统进程的最大打开文件数限制，在执行操作系统命令“ulimit -n 65536”后worker_connections的设置才能生效。 http 模块Http模块是核心的模块，负责HTTP服务相关属性的配置，包含server和upstream子模块。1234567891011121314151617181920212223242526272829http &#123; // incluede 用来设定文件的mime类型，类型在配置文件目录下的mime.type文件定义，用来告诉nginx来识别文件类型 include mime.types; // 设置了默认类型为二进制流，也就是说当文件类型未定义时使用这种方式。 default_type application/octet-stream; client_max_body_size 120m; // 设置日志格式和记录那修参数 这里设置为main，刚好用于access_log来记录这种类型 log_format main &apos;$remote_addr - $remote_user [$time_local] &quot;$request&quot; &apos; &apos;$status $body_bytes_sent &quot;$http_referer&quot; &apos; &apos;&quot;$http_user_agent&quot; &quot;$http_x_forwarded_for&quot;&apos;; // 用来纪录每次的访问日志的文件地址，后面的`main`是日志的格式样式，对应于log_format的main。 access_log /var/log/nginx/access.log main; // 用于开启高效文件传输模式，将tcp_nopush和tcp_nodelay两个指令设置为on用于防止网络阻塞 sendfile on; tcp_nopush on; // 设置客户端连接保持活动的超时时间。在超过这个时间之后，服务器会关闭该连接。 #keepalive_timeout 0; keepalive_timeout 65; #gzip on; upstream myproject &#123; ... &#125; server &#123; ... &#125; server模块12345678910111213141516171819// 标志定义虚拟主机开始server &#123; // 用于指定虚拟主机的服务端口 listen 80; // 用来指定IP地址或者域名，多个域名直接用空格分个格 server_name localhost 192.168.12.10 www.yangyi.com; // 表示虚拟主机的root web目录 root /home/www; // 全局定义访问的默认首页地址，需要和locate&#123;&#125;下面定义的区分开来 index index.php index.html index.htm; // 设置网页的默认编码格式 charset utf-8; // 用来存放次虚拟主机的日志目录，最后的main用来指定访问日志的输出格式 access_log usr/local/var/log/host.access.log main; aerror_log usr/local/var/log/host.error.log error; location / &#123; &#125;&#125; location 模块location模块是nginx中用的最多的，也是最重要的模块了，什么负载均衡啊、反向代理啊、虚拟域名啊都与它相关location 根据它字面意思就知道是来定位的，定位URL，解析URL，所以，它也提供了强大的正则匹配功能，也支持条件判断匹配，用户可以通过location指令实现Nginx对动、静态网页进行过滤处理。像我们的php环境搭建就是用到了它。1234567// 匹配访问根目录location / &#123; // root指令用于指定访问根目录时，虚拟主机的web目录，这个目录可以是相对路径（相对路径是相对于nginx的安装目录）。也可以是绝对路径。 root /home/www; // index用于设定我们只输入域名后访问的默认首页地址，有个先后顺序：index.php index.html index.htm，如果没有开启目录浏览权限，又找不到这些默认首页，就会报403错误。 index index.php index.html index.htm;&#125; 下面这个例子是运用正则匹配来链接php。我们之前搭建环境也是这样做：123456789// 正则匹配.php结尾的URLlocation ~ \\.php$ &#123; root /home/www; // fast_pass链接的是php-fpm 的地址 fastcgi_pass 127.0.0.1:9000; fastcgi_index index.php; include fastcgi.conf;&#125; upstream 模块upstream 模块负债负载均衡模块，通过一个简单的调度算法来实现客户端IP到后端服务器的负载均衡。1234567upstream demo.com&#123; ip_hash; server 192.168.12.1:80; server 192.168.12.2:80 down; server 192.168.12.3:8080 max_fails=3 fail_timeout=20s; server 192.168.12.4:8080;&#125; 在上面的例子中，通过upstream指令指定了一个负载均衡器的名称demo.com。这个名称可以任意指定，在后面需要的地方直接调用即可。 里面是ip_hash这是其中的一种负载均衡调度算法。紧接着就是各种服务器了。用server关键字表识，后面接ip。 Nginx的负载均衡模块目前支持4种调度算法: weight 轮询（默认）。每个请求按时间顺序逐一分配到不同的后端服务器，如果后端某台服务器宕机，故障系统被自动剔除，使用户访问不受影响。weight。指定轮询权值，weight值越大，分配到的访问机率越高，主要用于后端每个服务器性能不均的情况下。 ip_hash。每个请求按访问IP的hash结果分配，这样来自同一个IP的访客固定访问一个后端服务器，有效解决了动态网页存在的session共享问题。 fair。比上面两个更加智能的负载均衡算法。此种算法可以依据页面大小和加载时间长短智能地进行负载均衡，也就是根据后端服务器的响应时间来分配请求，响应时间短的优先分配。Nginx本身是不支持fair的，如果需要使用这种调度算法，必须下载Nginx的upstream_fair模块。 url_hash。按访问url的hash结果来分配请求，使每个url定向到同一个后端服务器，可以进一步提高后端缓存服务器的效率。Nginx本身是不支持url_hash的，如果需要使用这种调度算法，必须安装Nginx 的hash软件包。 在HTTP Upstream模块中，可以通过server指令指定后端服务器的IP地址和端口，同时还可以设定每个后端服务器在负载均衡调度中的状态。常用的状态有： down，表示当前的server暂时不参与负载均衡。 backup，预留的备份机器。当其他所有的非backup机器出现故障或者忙的时候，才会请求backup机器，因此这台机器的压力最轻。 max_fails，允许请求失败的次数，默认为1。当超过最大次数时，返回proxy_next_upstream 模块定义的错误。 fail_timeout，在经历了max_fails次失败后，暂停服务的时间。max_fails可以和fail_timeout一起使用。 注意 当负载调度算法为ip_hash时，后端服务器在负载均衡调度中的状态不能是weight和backup。","categories":[],"tags":[]},{"title":"","slug":"PHP-FPM配置详解","date":"2018-09-29T11:08:49.327Z","updated":"2018-09-29T11:08:49.327Z","comments":true,"path":"2018/09/29/PHP-FPM配置详解/","link":"","permalink":"http://yoursite.com/2018/09/29/PHP-FPM配置详解/","excerpt":"","text":"[TOC] PHP-FPM配置文件参数解释 PHP-FPM配置详解FPM配置文件为php-fpm.conf，其语法类似 php.ini 。其php手册上也有详细的讲解：http://php.net/manual/zh/install.fpm.configuration.php php-fpm.conf全局配置段12345678# 包含其他POOL定义配置文件include=/etc/php-fpm.d/*.conf# 全局配置段，定义PID文件的位置和错误日志的位置[global]daemonize = yespid = /var/run/php-fpm/php-fpm.piderror_log = /var/log/php-fpm/error.log 一般在主配置文件php-fpm.conf全局配置段中的配置非常少，php-fpm可以配置多个pool，每个pool都是以一个独立的配置文件来运作，默认都会定义在主配置文件的include包含文件目录中。php默认会提供一个www的pool，大概配置如下。 123456789101112$ cat /etc/php-fpm.d/www.conf[www]user = apachegroup = apache listen = 127.0.0.1:9000listen.allowed_clients = 127.0.0.1pm = dynamicpm.max_children = 50pm.start_servers = 5pm.min_spare_servers = 5pm.max_spare_servers = 35 每个pool配置文件参数可以独立，也可以设置在主配置文件的全局配置段中，这样每个pool就共用一个参数。建议最好分开设置。大概常用参数如下： daemonize = yes#后台执行fpm，默认值为yes，如果为了调试可以改为no。在FPM中，可以使用不同的设置来运行多个进程池。 这些设置可以针对每个进程池单独设置。 listen = 127.0.0.1:9000#fpm监听端口，即nginx中php处理的地址，一般默认值即可。可用格式为: ‘ip:port’, ‘port’, ‘/path/to/unix/socket’，每个进程池都需要设置。如果nginx和php在不同的机器上，分布式处理，就设置ip这里就可以了。 listen.backlog = -1#backlog数，设置 listen 的半连接队列长度，-1表示无限制，由操作系统决定，此行注释掉就行。backlog含义参考：http://www.3gyou.cc/?p=41。 log_level = notice#错误级别. 上面的php-fpm.log纪录的登记。可用级别为: alert（必须立即处理）, error（错误情况）, warning（警告情况）, notice（一般重要信息）, debug（调试信息）. 默认: notice。 emergency_restart_threshold = 60emergency_restart_interval = 60s#表示在emergency_restart_interval所设值内出现SIGSEGV或者SIGBUS错误的php-cgi进程数如果超过 emergency_restart_threshold个，php-fpm就会优雅重启。这两个选项一般保持默认值。0 表示 ‘关闭该功能’. 默认值: 0 (关闭). process_control_timeout = 0#设置子进程接受主进程复用信号的超时时间. 可用单位: s(秒), m(分), h(小时), 或者 d(天) 默认单位: s(秒). 默认值: 0. listen.allowed_clients = 127.0.0.1#允许访问FastCGI进程的IP白名单，设置any为不限制IP，如果要设置其他主机的nginx也能访问这台FPM进程，listen处要设置成本地可被访问的IP。默认值是any。每个地址是用逗号分隔. 如果没有设置或者为空，则允许任何服务器请求连接。 listen.owner = wwwlisten.group = wwwlisten.mode = 0666#unix socket设置选项，如果使用tcp方式访问，这里注释即可。 user = wwwgroup = www#启动进程的用户和用户组，FPM 进程运行的Unix用户, 必须要设置。用户组，如果没有设置，则默认用户的组被使用。 pm = dynamic#php-fpm进程启动模式，pm可以设置为static和dynamic和ondemand。如果选择static，则进程数就是固定的，由pm.max_children指定固定的子进程数。如果选择dynamic，则进程数是动态变化的，由以下参数决定： pm.max_children = 50#子进程能开启的最大数。 pm.start_servers = 2#启动时的进程数，默认值为: min_spare_servers + (max_spare_servers – min_spare_servers) / 2。 pm.min_spare_servers = 1#保证空闲进程数最小值，如果空闲进程小于此值，则创建新的子进程。 pm.max_spare_servers = 3#保证空闲进程数最大值，如果空闲进程大于此值，此进行清理。 pm.max_requests = 500#设置每个子进程重生之前服务的请求数. 对于可能存在内存泄漏的第三方模块来说是非常有用的. 如果设置为 ‘0’ 则一直接受请求. 等同于 PHP_FCGI_MAX_REQUESTS 环境变量. 默认值: 0。 pm.status_path = /status#FPM状态页面的网址. 如果没有设置, 则无法访问状态页面. 默认值: none. munin监控会使用到 ping.path = /ping#FPM监控页面的ping网址. 如果没有设置, 则无法访问ping页面. 该页面用于外部检测FPM是否存活并且可以响应请求. 请注意必须以斜线开头 (/)。 ping.response = pong#用于定义ping请求的返回相应. 返回为 HTTP 200 的 text/plain 格式文本. 默认值: pong. access.log = log/$pool.access.log#每一个请求的访问日志，默认是关闭的。 access.format = “%R – %u %t \\”%m %r%Q%q\\” %s %f %{mili}d %{kilo}M %C%%”#设定访问日志的格式。 slowlog = log/$pool.log.slow#慢请求的记录日志,配合request_slowlog_timeout使用，默认关闭 request_slowlog_timeout = 10s#当一个请求该设置的超时时间后，就会将对应的PHP调用堆栈信息完整写入到慢日志中. 设置为 ‘0’ 表示 ‘Off’ request_terminate_timeout = 0#设置单个请求的超时中止时间. 该选项可能会对php.ini设置中的’max_execution_time’因为某些特殊原因没有中止运行的脚本有用. 设置为 ‘0’ 表示 ‘Off’.当经常出现502错误时可以尝试更改此选项。 rlimit_files = 1024#设置文件打开描述符的rlimit限制. 默认值: 系统定义值默认可打开句柄是1024，可使用 ulimit -n查看，ulimit -n 2048修改。 rlimit_core = 0#设置核心rlimit最大限制值. 可用值: ‘unlimited’ 、0或者正整数. 默认值: 系统定义值。 chroot = /data/app#启动时的Chroot目录. 所定义的目录需要是绝对路径. 如果没有设置, 则chroot不被使用。 chdir = /data/app#设置启动目录，启动时会自动Chdir到该目录. 所定义的目录需要是绝对路径. 默认值: 当前目录，或者/目录（chroot时）。 catch_workers_output = yes#重定向运行过程中的stdout和stderr到主要的错误日志文件中. 如果没有设置, stdout 和 stderr 将会根据FastCGI的规则被重定向到 /dev/null . 默认值: 空。 当然还有一些无关紧要的设置，用到了再说吧。 PHP-FPM重要的设置PHP-FPM重要的设置在之前的文章中就说过了。在fasgcgi模式下，php会启动多个php-fpm进程，来接收nginx发来的请求，那是不是进程越多，速度就越快呢？这可不一定！得根据我们的机器配置和业务量来决定。 我们先来看下，设定进程的配置在哪里？ pm = static | dynamic | ondemandpm可以设置成这样3种，我们用的最多的就上前面2种。 pm = static模式 pm = static 表示我们创建的php-fpm子进程数量是固定的，那么就只有pm.max_children = 50这个参数生效。你启动php-fpm的时候就会一起全部启动51(1个主＋50个子)个进程，颇为壮观。 pm = dynamic模式 pm = dynamic模式，表示启动进程是动态分配的，随着请求量动态变化的。他由pm.max_children，pm.start_servers，pm.min_spare_servers，pm.max_spare_servers 这几个参数共同决定。 上面已经讲过，这里再重申一下吧： pm.max_children ＝ 50是最大可创建的子进程的数量。必须设置。这里表示最多只能50个子进程。 pm.start_servers = 20随着php-fpm一起启动时创建的子进程数目。默认值：min_spare_servers + (max_spare_servers – min_spare_servers) / 2。这里表示，一起启动会有20个子进程。 pm.min_spare_servers = 10 设置服务器空闲时最小php-fpm进程数量。必须设置。如果空闲的时候，会检查如果少于10个，就会启动几个来补上。 pm.max_spare_servers = 30 设置服务器空闲时最大php-fpm进程数量。必须设置。如果空闲时，会检查进程数，多于30个了，就会关闭几个，达到30个的状态。到底选择static还数dynamic? 很多人恐惧症来袭，不知道选什么好？ 一般原则是：动态适合小内存机器，灵活分配进程，省内存。静态适用于大内存机器，动态创建回收进程对服务器资源也是一种消耗。 如果你的内存很大，有8-20G，按照一个php-fpm进程20M算，100个就2G内存了，那就可以开启static模式。如果你的内存很小，比如才256M，那就要小心设置了，因为你的机器里面的其他的进程也算需要占用内存的，所以设置成dynamic是最好的，比如：pm.max_chindren = 8, 占用内存160M左右，而且可以随时变化，对于一半访问量的网站足够了。 慢日志查询我们有时候会经常饱受500,504问题困扰。当nginx收到如上错误码时，可以确定后端php-fpm解析php出了某种问题，比如，执行错误，执行超时。 这个时候，我们是可以开启慢日志功能的。 slowlog = /usr/local/var/log/php-fpm.log.slowrequest_slowlog_timeout = 15s当一个请求该设置的超时时间15秒后，就会将对应的PHP调用堆栈信息完整写入到慢日志中。 php-fpm慢日志会记录下进程号，脚本名称，具体哪个文件哪行代码的哪个函数执行时间过长： [21-Nov-2013 14:30:38] [pool www] pid 11877script_filename = /usr/local/lnmp/nginx/html/www.quancha.cn/www/fyzb.php[0xb70fb88c] file_get_contents() /usr/local/lnmp/nginx/html/www.quancha.cn/www/fyzb.php:2 通过日志，我们就可以知道第2行的file_get_contents 函数有点问题，这样我们就能追踪问题了。","categories":[],"tags":[]},{"title":"","slug":"Mycat实践","date":"2018-09-29T11:08:49.326Z","updated":"2018-09-29T11:08:49.326Z","comments":true,"path":"2018/09/29/Mycat实践/","link":"","permalink":"http://yoursite.com/2018/09/29/Mycat实践/","excerpt":"","text":"接着上一篇MySql主从配置完成后，下面实战下Mycat做读写分离和分库分表 参考： https://foofish.net/mysql-for-mycat.html https://www.cnblogs.com/joylee/p/7513038.html [TOC] 环境说明：windows 下4台服务器，真实机IP：192.168.2.107，其中 服务器 IP 说明 master 172.17.0.2 物理数据库，主库 mycat 172.17.0.3 mycat服务器，连接数据库时，连接此服务器 slave1 172.17.0.4 物理数据库，从库 slave2 172.17.0.5 物理数据库，从库 123456C:\\Users\\mma&gt;docker psCONTAINER ID PORTS NAMESb04f945297ac 0.0.0.0:1024-&gt;1024/tcp, 0.0.0.0:6379-&gt;6379/tcp, 0.0.0.0:9001-&gt;9001/tcp, 0.0.0.0:220-&gt;22/tcp, 0.0.0.0:8080-&gt;80/tcp, 0.0.0.0:33060-&gt;3306/tcp masterdcccd23b6177 0.0.0.0:8066-&gt;8066/tcp, 0.0.0.0:223-&gt;22/tcp, 0.0.0.0:8083-&gt;80/tcp, 0.0.0.0:31024-&gt;1024/tcp, 0.0.0.0:33063-&gt;3306/tcp, 0.0.0.0:36379-&gt;6379/tcp, 0.0.0.0:9004-&gt;9001/tcp myCat9ae039d46474 0.0.0.0:221-&gt;22/tcp, 0.0.0.0:8081-&gt;80/tcp, 0.0.0.0:10241-&gt;1024/tcp, 0.0.0.0:33061-&gt;3306/tcp, 0.0.0.0:16379-&gt;6379/tcp, 0.0.0.0:9002-&gt;9001/tcp slave106e5a050e74b 0.0.0.0:222-&gt;22/tcp, 0.0.0.0:8082-&gt;80/tcp, 0.0.0.0:10242-&gt;1024/tcp, 0.0.0.0:33062-&gt;3306/tcp, 0.0.0.0:26379-&gt;6379/tcp, 0.0.0.0:9003-&gt;9001/tcp slave2 master:123456mysql&gt; show master status;+------------------+----------+--------------+------------------+-------------------+| File | Position | Binlog_Do_DB | Binlog_Ignore_DB | Executed_Gtid_Set |+------------------+----------+--------------+------------------+-------------------+| mysql-bin.000001 | 154 | zhimma | | |+------------------+----------+--------------+------------------+-------------------+ mycat:12[root@dcccd23b6177 mycat]# mycat statusMycat-server is running (317). slave1:123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263mysql&gt; show slave status\\G;*************************** 1. row *************************** Slave_IO_State: Waiting for master to send event Master_Host: 172.17.0.2 Master_User: zhimma Master_Port: 3306 Connect_Retry: 60 Master_Log_File: mysql-bin.000001 Read_Master_Log_Pos: 154 Relay_Log_File: 9ae039d46474-relay-bin.000003 Relay_Log_Pos: 367 Relay_Master_Log_File: mysql-bin.000001 Slave_IO_Running: Yes Slave_SQL_Running: Yes Replicate_Do_DB: Replicate_Ignore_DB: Replicate_Do_Table: Replicate_Ignore_Table: Replicate_Wild_Do_Table: Replicate_Wild_Ignore_Table: Last_Errno: 0 Last_Error: Skip_Counter: 0 Exec_Master_Log_Pos: 154 Relay_Log_Space: 581 Until_Condition: None Until_Log_File: Until_Log_Pos: 0 Master_SSL_Allowed: No Master_SSL_CA_File: Master_SSL_CA_Path: Master_SSL_Cert: Master_SSL_Cipher: Master_SSL_Key: Seconds_Behind_Master: 0Master_SSL_Verify_Server_Cert: No Last_IO_Errno: 0 Last_IO_Error: Last_SQL_Errno: 0 Last_SQL_Error: Replicate_Ignore_Server_Ids: Master_Server_Id: 1 Master_UUID: f781e2b4-28e1-11e8-a1c0-0242ac110002 Master_Info_File: /var/lib/mysql/master.info SQL_Delay: 0 SQL_Remaining_Delay: NULL Slave_SQL_Running_State: Slave has read all relay log; waiting for more updates Master_Retry_Count: 86400 Master_Bind: Last_IO_Error_Timestamp: Last_SQL_Error_Timestamp: Master_SSL_Crl: Master_SSL_Crlpath: Retrieved_Gtid_Set: Executed_Gtid_Set: Auto_Position: 0 Replicate_Rewrite_DB: Channel_Name: Master_TLS_Version: 1 row in set (0.00 sec)ERROR: No query specified salve2:123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263mysql&gt; show slave status \\G;*************************** 1. row *************************** Slave_IO_State: Waiting for master to send event Master_Host: 192.168.2.107 Master_User: zhimma Master_Port: 33060 Connect_Retry: 60 Master_Log_File: mysql-bin.000001 Read_Master_Log_Pos: 154 Relay_Log_File: 06e5a050e74b-relay-bin.000003 Relay_Log_Pos: 367 Relay_Master_Log_File: mysql-bin.000001 Slave_IO_Running: Yes Slave_SQL_Running: Yes Replicate_Do_DB: Replicate_Ignore_DB: Replicate_Do_Table: Replicate_Ignore_Table: Replicate_Wild_Do_Table: Replicate_Wild_Ignore_Table: Last_Errno: 0 Last_Error: Skip_Counter: 0 Exec_Master_Log_Pos: 154 Relay_Log_Space: 581 Until_Condition: None Until_Log_File: Until_Log_Pos: 0 Master_SSL_Allowed: No Master_SSL_CA_File: Master_SSL_CA_Path: Master_SSL_Cert: Master_SSL_Cipher: Master_SSL_Key: Seconds_Behind_Master: 0Master_SSL_Verify_Server_Cert: No Last_IO_Errno: 0 Last_IO_Error: Last_SQL_Errno: 0 Last_SQL_Error: Replicate_Ignore_Server_Ids: Master_Server_Id: 1 Master_UUID: f781e2b4-28e1-11e8-a1c0-0242ac110002 Master_Info_File: /var/lib/mysql/master.info SQL_Delay: 0 SQL_Remaining_Delay: NULL Slave_SQL_Running_State: Slave has read all relay log; waiting for more updates Master_Retry_Count: 86400 Master_Bind: Last_IO_Error_Timestamp: Last_SQL_Error_Timestamp: Master_SSL_Crl: Master_SSL_Crlpath: Retrieved_Gtid_Set: Executed_Gtid_Set: Auto_Position: 0 Replicate_Rewrite_DB: Channel_Name: Master_TLS_Version: 1 row in set (0.00 sec)ERROR: No query specified 安装省略 目录结构： 12345[root@dcccd23b6177 mycat]# pwd/etc/mycat[root@dcccd23b6177 mycat]# lsbin catlet conf lib logs tmlogs version.txt[root@dcccd23b6177 mycat]# 目录 说明 bin mycat命令，启动、重启、停止等 catlet catlet为Mycat的一个扩展功能 conf Mycat 配置信息,重点关注 lib Mycat引用的jar包，Mycat是java开发的 logs 日志文件，包括Mycat启动的日志和运行的日志。 配置Mycat的配置文件都在conf目录里面，这里介绍几个常用的文件： 文件 说明 server.xml Mycat的配置文件，设置账号、参数等 schema.xml Mycat对应的物理数据库和数据库表的配置 rule.xml Mycat分片（分库分表）规则 Mycat的架构Mycat的架构其实很好理解，Mycat是代理，Mycat后面就是物理数据库。和Web服务器的Nginx类似。对于使用者来说，访问的都是Mycat，不会接触到后端的数据库。 配置server.xml1234&lt;user name=\"root\" defaultAccount=\"true\"&gt; &lt;property name=\"password\"&gt;123456&lt;/property&gt; &lt;property name=\"schemas\"&gt;zhimma_mycat&lt;/property&gt;&lt;/user&gt; 重点关注下面这段，其他默认即可。 参数 说明 user 用户配置节点 –name 登录的用户名，也就是连接Mycat的用户名 –password 登录的密码，也就是连接Mycat的密码 –schemas 数据库名，这里会和schema.xml中的配置关联，多个用逗号分开，例如需要这个用户需要管理两个数据库db1,db2，则配置db1,db2 –privileges 配置用户针对表的增删改查的权限，具体见文档吧 我这里配置了一个账号root密码是123456,针对数据库zhimma_mycat,读写权限都有，没有针对表做任何特殊的权限。 schema.xml12345678910111213141516171819202122&lt;?xml version=\"1.0\"?&gt;&lt;!DOCTYPE mycat:schema SYSTEM \"schema.dtd\"&gt;&lt;mycat:schema xmlns:mycat=\"http://io.mycat/\"&gt; &lt;schema name=\"zhimma_mycat\" checkSQLschema=\"false\" sqlMaxLimit=\"100\"&gt; &lt;table name=\"users\" dataNode=\"dn1\" /&gt; &lt;table name=\"articles\" dataNode=\"dn1\" /&gt; &lt;table name=\"categories\" dataNode=\"dn1\" /&gt; &lt;/schema&gt; &lt;dataNode name=\"dn1\" dataHost=\"localhost1\" database=\"zhimma\" /&gt; &lt;dataHost name=\"localhost1\" maxCon=\"1000\" minCon=\"10\" balance=\"1\" writeType=\"0\" dbType=\"mysql\" dbDriver=\"native\" switchType=\"1\" slaveThreshold=\"100\"&gt; &lt;heartbeat&gt;select users()&lt;/heartbeat&gt; &lt;!-- can have multi write hosts --&gt; &lt;writeHost host=\"hostM1\" url=\"192.168.2.107:33060\" user=\"root\" password=\"123456\"&gt; &lt;!-- can have multi read hosts --&gt; &lt;readHost host=\"hostS1\" url=\"192.168.2.107:33061\" user=\"root\" password=\"123456\" /&gt; &lt;readHost host=\"hostS2\" url=\"192.168.2.107:33062\" user=\"root\" password=\"123456\" /&gt; &lt;/writeHost&gt; &lt;/dataHost&gt;&lt;/mycat:schema&gt; 参数 说明 schema 数据库设置，此数据库为逻辑数据库，name与server.xml中schema对应,此处为zhimma_mycat dataNode 分片信息，也就是分库相关配置 dataHost 物理数据库，真正存储数据的数据库 每个节点的属性逐一说明： schema: 属性 说明 name 逻辑数据库名，与server.xml中的schema对应 checkSQLschema 布尔值，默认和推荐都是关闭。如果开启则会拦截SQL语句，将其中的mycat相关字段删除如：select from zhimma_mycat.users;将会把SQL语句变为：select from users; sqlMaxLimit SQL返回条数，最好加上限制，防止查询量过大导致卡死 table: 属性 说明 name 表名，物理数据库中表名 dataNode 表存储到哪些节点，多个节点用逗号分隔。节点为下文dataNode设置的name primaryKey 主键字段名，自动生成主键时需要设置 autoIncrement 是否自增 rule 分片规则名，具体规则下文rule详细介绍 dataNode 属性 说明 name 节点名，与table中dataNode对应 datahost 物理数据库名，与datahost中name对应 database 物理数据库中数据库名 dataHost 属性 说明 name 物理数据库名，与dataNode中dataHost对应 balance 均衡负载的方式 writeType 写入方式 dbType 数据库类型 heartbeat 心跳检测语句，注意语句结尾的分号要加。","categories":[],"tags":[]},{"title":"","slug":"Nginx与PHP的交互机制","date":"2018-09-29T11:08:49.326Z","updated":"2018-09-29T11:08:49.326Z","comments":true,"path":"2018/09/29/Nginx与PHP的交互机制/","link":"","permalink":"http://yoursite.com/2018/09/29/Nginx与PHP的交互机制/","excerpt":"","text":"Nginx与PHP的交互机制(1)from there https://www.awaimai.com/371.html 在搭建 LAMP/LNMP 服务器时，会经常遇到 PHP-FPM、FastCGI和CGI 这几个概念。如果对它们一知半解，很难搭建出高性能的服务器。接下来我们就以图形方式，解释这些概念之间的关系。 基础在整个网站架构中，Web Server（如Apache）只是内容的分发者。举个栗子，如果客户端请求的是 index.html，那么Web Server会去文件系统中找到这个文件，发送给浏览器，这里分发的是静态数据。 如果请求的是 index.php，根据配置文件，Web Server知道这个不是静态文件，需要去找 PHP 解析器来处理，那么他会把这个请求简单处理，然后交给PHP解析器。 当Web Server收到 index.php 这个请求后，会启动对应的 CGI 程序，这里就是PHP的解析器。接下来PHP解析器会解析php.ini文件，初始化执行环境，然后处理请求，再以规定CGI规定的格式返回处理后的结果，退出进程，Web server再把结果返回给浏览器。这就是一个完整的动态PHP Web访问流程 CGICGI是 Web Server 与 Web Application 之间数据交换的一种协议。CGI全称是“公共网关接口”(Common Gateway Interface)，描述的是服务器和请求处理程序之间传输数据的一种标准（服务器与你的或其它机器上的程序进行“交谈”的一种工具）。 所以，CGI是一种协议。CGI可用于任何语言，只要该语言具有标准的输出、输入以及环境变量。如perl、php等语言。 以nginx和php为例，我们可以理解为，这是php在与nginx服务器之间交互时，对传输数据的一种约定。 CGI的原理是什么?当需要请求使用网关的资源时，服务器会请辅助应用程序来处理请求（比如nginx会请php程序来处理请求）。 服务器会将辅助应用程序的数据传送给网关。然后网关会向服务器返回一条响应或者响应数据，服务器再将响应或响应数据转发给客户端。 由此我们可以清楚两点： 服务器和网关是相互独立的应用程序 服务器是应用程序和网关之间的一座桥梁 由此，我们可知CGI有一个致命的弱点，即应用程序的每次请求，都要引发一个全新的进程。所以，服务器和网关之间的分离会造成性能的 耗费，会限制使用CGI的服务器的性能，并且会加重服务端机器资源的负担。好啦，重角要登场了。后来为了解决这个问题，出现了FastCGI，也就是快速的CGI。 接下来，我们再详细的了解下FastCGI。 FastCGI FastCGI:(Fast Common Gateway Interface),即快速通用网关接口，是一种让交互程序与Web服务器通信的协议。它是CGI的增强版本 FastCGI致力于减少网页服务器与CGI程序之间互动的开销，从而使服务器可以同时处理更多的网页请求。以上来自维基百科，我们可以由此了解到，FastCGI，同CGI一样，也是一种协议，只不过它是CGI的增强版本。那FastCGI是如何增强性能的呢？ FastCGI接口模拟了CGI，但FastCGI是作为持久守护进程运行的，消除了为每个请求建立或拆除新进程所带来的性能损耗。也就是允许，一个进程内可以处理多个请求。 也就说CGI解释器保持在内存中，并接受了FastCGI进程管理和调度，所以它可以提供更好的性能，可扩展性，故障切换等特点 FastCGI的特点: FastCGI与语言无关 FastCGI应用在进程中，独立于核心网络服务器，提供了一个比API环境更安全的环境。 APIs的代码和web服务器的应用的核心是 紧紧关联的。这也就意味着在API应用程序的错误可能会损坏其它应用程序或核心服务器。恶意API应用程序代码甚至可以窃取另一个应用程序或核心服务器密钥。 FastCGI技术目前支持PHP,C/C++, Java lanuage, Perl, Tcl, Python, SmallTalk, Ruby etc.. 它在Apache, ISS, Lighttpd和其他流行的 服务器中的相关模块都是可以使用的。FastCGI不依赖于任何服务器体系结构，所以即使服务器在技术上改变了，FastCGI还是稳定的 FastCGI的工作原理 Web Server 启动时载入FastCGI进程管理器 (IIS ISAPI 或Apache Module) FastCGI进程管理器首先初始化自己，启动一批CGI解释器进程（可见多个php-cgi），然后等待来自Web Server的连接。 当Web Server中的一个客户端请求达到时， FastCGI进程管理器会选择并连接一个CGI解释器。Web server的CGI环境变量和标准输入会被送达FastCGI进程的php-cgi。 FastCGI子进程从同一连接完成返还给Web Server的标准输出和错误信息。当请求进程完成后，FastCGI进程会关闭此连接。FastCGI会等待并出来来自FastCGI进程管理器（运行在Web Server中的）的下一个连接。 在CGI模式，php-cgi然后会退出。 如上图所示，FastCGI的下游，是CGI-APP，在我们的LNMP架构里，这个CGI-APP就是PHP程序。而FastCGI的上游是Nginx，他们之间有一个通信载体，即图中的socket。上图中的Pre-fork，则对应着我们PHP-FPM的启动，也就是在我们启动PHP-FPM时便会根据用户配置启动诸多FastCGI触发器（FastCGI Wrapper）。 FastCGI的不足 因为是多进程，所以比CGI多线程消耗更多的服务器内存，PHP-CGI解释器每进程消耗7至25兆内存，将这个数字乘以50或100就是很大的内存数。 Nginx 0.8.46+PHP 5.2.14(FastCGI)服务器在3万并发连接下，开启的10个Nginx进程消耗150M内存（15M_10=150M），开启的64个php-cgi进程消耗1280M内存（20M_64=1280M），加上系统自身消耗的内存，总共消耗不到2GB内存。 如果服务器内存较小，完全可以只开启25个php-cgi进程，这样php-cgi消耗的总内存数才500M。 上面的数据摘自Nginx 0.8.x + PHP 5.2.13(FastCGI)搭建胜过Apache十倍的Web服务器(第6版) PHP-CGIPHP-CGI：是 PHP （Web Application）对 Web Server 提供的 CGI 协议的接口程序,是PHP自带的FastCGI管理器。 PHP-CGI的不足: php-cgi变更php.ini配置后需重启php-cgi才能让新的php-ini生效，不可以平滑重启 直接杀死php-cgi进程,php就不能运行了。(PHP-FPM和Spawn-FCGI就没有这个问题,守护进程会平滑从新生成新的子进程。） PHP-FPMPHP-FPM：是 PHP（Web Application）对 Web Server 提供的 FastCGI 协议的接口程序，额外还提供了相对智能一些任务管理。PHP-FPM的全称是PHP FastCGI Process Manager。它是 PHP 针对 FastCGI 协议的具体实现，它会通过用户配置来管理一批FastCGI进程.因此它也是PHP 在多种服务器端应用编程端口（SAPI：cgi、fast-cgi、cli、isapi、apache）里使用最普遍、性能最佳的一款进程管理器。在PHP-FPM管理下的某个FastCGI进程挂了，PHP-FPM会根据用户配置来看是否要重启补全。PHP-FPM更像是管理器，负责管理PHP FastCGI，而真正衔接Nginx与PHP的则是FastCGI进程。因此，CGI是通用网关协议，FastCGI则是一种常驻进程的CGI模式程序，而PHP-FPM更像是管理器，用于管理FastCGI进程。WEB 中: Web Server 一般指Apache、Nginx、IIS、Lighttpd、Tomcat等服务器， Web Application 一般指PHP、Java、Asp.net等应用程序。 Nginx+PHP的工程模式下，两位主角分工明确，Nginx负责承载HTTP请求的响应与返回，以及超时控制记录日志等HTTP相关的功能，而PHP则负责处理具体请求要做的业务逻辑，它们俩的这种合作模式也是常见的分层架构设计中的一种，在它们各有专注面的同时，FastCGI又很好的将两块衔接，保障上下游通信交互，这种通过某种协议或规范来衔接好上下游的模式，在我们日常的PHP应用开发中也有这样的思想落地，譬如我们所开发的高性能API，具体的Client到底是PC、APP还是某个其他程序，我们不关心，而这些PC、APP、第三方程序也不关心我们的PHP代码实现，他们按照API的规范来请求做处理即可","categories":[],"tags":[]},{"title":"","slug":"MySQL数据类型","date":"2018-09-29T11:08:49.325Z","updated":"2018-09-29T11:08:49.325Z","comments":true,"path":"2018/09/29/MySQL数据类型/","link":"","permalink":"http://yoursite.com/2018/09/29/MySQL数据类型/","excerpt":"","text":"[TOC] MySQL数据类型char和varcharvarchar数据类型的变化MySQL4.1以下的版本中，varchar数据类型的最大长度限制为255，其数据范围可以是0~255或1~255（根据不同版本数据库来定） MySQL5.0以上的版本中，varchar数据类型的长度支持到了65535，也就是说可以存放65532个字节的数据，起始位和结束位占去了3个字节 Mysql5根据编码不同,存储大小也不同，具体有以下规则： 存储限制 varchar 字段是将实际内容单独存储在聚簇索引之外，内容开头用1到2个字节表示实际长度（长度超过255时需要2个字节），因此最大长度不能超过65535。 编码长度限制 字符类型若为gbk，每个字符最多占2个字节，最大长度不能超过32766; 字符类型若为utf8，每个字符最多占3个字节，最大长度不能超过21845。 若定义的时候超过上述限制，则varchar字段会被强行转为text类型，并产生warning。 行长度限制 导致实际应用中varchar长度限制的是一个行定义的长度。 MySQL要求一个行的定义长度不能超过65535。若定义的表长度超过这个值，则提示 ERROR 1118 (42000): Row size too large. The maximum row size for the used table type, not counting BLOBs, is 65535. You have to change some columns to TEXT or BLOBs。 char(M), varchar(M)不同之处char(M)定义的列的长度为固定的，M取值可以为0～255之间，当保存char值时，在它们的右边填充空格以达到指定的长度。当检索到CHAR值时，尾部的空格被删除掉。在存储或检索过程中不进行大小写转换。char存储定长数据很方便，char字段上的索引效率级高，比如定义char(10)，那么不论你存储的数据是否达到了10个字节，都要占去10个字节的空间,不足的自动用空格填充。 varchar(M)定义的列的长度为可变长字符串，M取值可以为0~65535之间，(VARCHAR的最大有效长度由最大行大小和使用的字符集确定。整体最大长度是65,532字节）。varchar值保存时只保存需要的字符数，另加一个字节来记录长度(如果列声明的长度超过255，则使用两个字节)。varchar值保存时不进行填充。当值保存和检索时尾部的空格仍保留，符合标准SQL。varchar存储变长数据，但存储效率没有char高。如果一个字段可能的值是不固定长度的，我们只知道它不可能超过10个字符，把它定义为 VARCHAR(10)是最合算的。VARCHAR类型的实际长度是它的值的实际长度+1。为什么”+1”呢？这一个字节用于保存实际使用了多大的长度。从空间上考虑，用varchar合适；从效率上考虑，用char合适，关键是根据实际情况找到权衡点。 char和varchar最大的不同就是一个是固定长度，一个是可变长度。由于是可变长度，因此实际存储的时候是实际字符串再加上一个记录字符串长度的字节(如果超过255则需要两个字节)。如果分配给char或varchar列的值超过列的最大长度，则对值进行裁剪以使其适合。如果被裁掉的字符不是空格，则会产生一条警告。如果裁剪非空格字符，则会造成错误(而不是警告)并通过使用严格SQL模式禁用值的插入。 VARCHAR和TEXT、BlOB类型的区别VARCHAR，BLOB和TEXT类型是变长类型，对于其存储需求取决于列值的实际长度(在前面的表格中用L表示)，而不是取决于类型的最大可能尺寸。例如，一个VARCHAR(10)列能保存最大长度为10个字符的一个字符串，实际的存储需要是字符串的长度 ，加上1个字节以记录字符串的长度。对于字符串’abcd’，L是4而存储要求是5个字节。 BLOB和TEXT类型需要1，2，3或4个字节来记录列值的长度，这取决于类型的最大可能长度。VARCHAR需要定义大小，有65535字节的最大限制；TEXT则不需要。如果你把一个超过列类型最大长度的值赋给一个BLOB或TEXT列，值被截断以适合它。 一个BLOB是一个能保存可变数量的数据的二进制的大对象。4个BLOB类型TINYBLOB、BLOB、MEDIUMBLOB和LONGBLOB仅仅在他们能保存值的最大长度方面有所不同。 BLOB 可以储存图片,TEXT不行，TEXT只能储存纯文本文件。4个TEXT类型TINYTEXT、TEXT、MEDIUMTEXT和LONGTEXT对应于4个BLOB类型，并且有同样的最大长度和存储需求。在BLOB和TEXT类型之间的唯一差别是对BLOB值的排序和比较以大小写敏感方式执行，而对TEXT值是大小写不敏感的。换句话说，一个TEXT是一个大小写不敏感的BLOB 总结char，varchar，text区别长度的区别，char范围是0～255，varchar最长是64k，但是注意这里的64k是整个row的长度，要考虑到其它的column，还有如果存在not null的时候也会占用一位，对不同的字符集，有效长度还不一样，比如utf8的，最多21845，还要除去别的column，但是varchar在一般情况下存储都够用了。如果遇到了大文本，考虑使用text，最大能到4G。 效率来说基本是char&gt;varchar&gt;text，但是如果使用的是Innodb引擎的话，推荐使用varchar代替char char和varchar可以有默认值，text不能指定默认值 数据库选择合适的数据类型存储还是很有必要的，对性能有一定影响。这里在零碎记录两笔，对于int类型的，如果不需要存取负值，最好加上unsigned；对于经常出现在where语句中的字段，考虑加索引，整形的尤其适合加索引。","categories":[],"tags":[]},{"title":"","slug":"MySQL添加新用户1364","date":"2018-09-29T11:08:49.325Z","updated":"2018-09-29T11:08:49.326Z","comments":true,"path":"2018/09/29/MySQL添加新用户1364/","link":"","permalink":"http://yoursite.com/2018/09/29/MySQL添加新用户1364/","excerpt":"","text":"MySQL5.7添加新用户 出现ERROR 1364 (HY000): Field &#39;ssl_cipher&#39; doesn&#39;t have a default value ## 解决方法1：insert into user (host,user,authentication_string,select_priv,insert_priv,update_priv) values (&#39;%&#39; , &#39;mma&#39; ,PASSWORD(&#39;123456&#39;),&#39;Y&#39;,&#39;Y&#39;,&#39;Y&#39;); 原因： 在我的配置文件my.cnf中有这样一条语句sql_mode=NO_ENGINE_SUBSTITUTION,STRICT_TRANS_TABLES 指定了严格模式，为了安全，严格模式禁止通过insert 这种形式直接修改MySQL库中的user表进行添加新用户 解决方法: 将配置文件中的STRICT_TRANS_TABLES删掉，即改为： sql_mode=NO_ENGINE_SUBSTITUTION 然后重启mysql即可 解决方法2(推荐)：添加用户： grant usage on *.* to &#39;mma&#39;@&#39;%&#39; identified by &#39;123456&#39; with grant option; 赋予权限 grant all privileges on *.* to &#39;mma&#39;@&#39;%&#39; identified by &#39;123456&#39;; or grant select,insert,update,delete,create,drop ON TUTORIALS.* TO &#39;mma&#39;@&#39;%&#39; IDENTIFIED BY &#39;123456&#39;; 刷新权限 flush privileges;","categories":[],"tags":[]},{"title":"","slug":"MySQL中Binlog记录","date":"2018-09-29T11:08:49.325Z","updated":"2018-09-29T11:08:49.325Z","comments":true,"path":"2018/09/29/MySQL中Binlog记录/","link":"","permalink":"http://yoursite.com/2018/09/29/MySQL中Binlog记录/","excerpt":"","text":"[TOC] MySQL中binlog文件 [DCOT] 概念MySQL Server 有四种类型的日志——Error Log、General Query Log、Binary Log 和 Slow Query Log。 Error Log：错误日志，记录 mysqld 的一些错误 General Query Log：一般查询日志，记录 mysqld 正在做的事情，比如客户端的连接和断开、来自客户端每条 Sql Statement 记录信息；如果你想准确知道客户端到底传了什么瞎 [哔哔] 玩意儿给服务端，这个日志就非常管用了，不过它非常影响性能。 Binlog：Mysql sever层维护的一种二进制日志,Binlog中包含了一些事件，这些事件描述了数据库的改动，如建表、数据改动等，也包括一些潜在改动，比如 DELETE FROM ran WHERE bing = luan，然而一条数据都没被删掉的这种情况。除非使用 Row-based logging，否则会包含所有改动数据的 SQL Statement。 Slow Query Log：慢查询日志，记录一些查询比较慢的 SQL 语句——这种日志非常常用，主要是给开发者调优用的。 用途Binlog的作用主要有： Replication（主从数据库）:在master端开启binary log后，log会记录所有数据库的改动，然后slave端获取这个Log文件内容就可以在slave端进行同样的操作。 备份（数据恢复 ）：在某个时间点a做了一次备份，然后利用binary log记录从这个时间点a后的所有数据库的改动，然后下一次还原的时候，利用时间点a的备份文件和这个binary log文件，就可以将数据还原。 我们执行SELECT等不设计数据变更的语句是不会记录Binlog的，而涉及到数据更新则会记录。要注意的是，对支持事务的引擎如InnoDB而言，必须要提交了事务才会记录Binlog。Binlog是在事务最终commit前写入的，binlog什么时候刷新到磁盘跟参数sync_binlog相关。如果设置为0，则表示MySQL不控制binlog的刷新，由文件系统去控制它缓存的刷新，而如果设置为不为0的值则表示每sync_binlog次事务，MySQL调用文件系统的刷新操作刷新binlog到磁盘中。设为1是最安全的，在系统故障时最多丢失一个事务的更新，但是会对性能有所影响，一般情况下会设置为100或者0，牺牲一定的一致性来获取更好的性能。 Binlog的用法常用命令1.开启Binlog 通过配置/etc/my.cnf配置文件的log-bin选项： 12[mysqld]log-bin=mysql-bin 修改后重启MySql服务； 可以使用SET SQL_LOG_BIN=0命令停止使用日志文件，然后可以通过SET SQL_LOG_BIN=1命令来启用。 2.查看Binlog文件 1234567891011121314151617181920212223242526272829303132333435363738394041mysql&gt; show binary logs; +------------------+-----------+| Log_name | File_size |+------------------+-----------+| mysql-bin.000001 | 1045 || mysql-bin.000002 | 201 || mysql-bin.000003 | 201 || mysql-bin.000004 | 201 || mysql-bin.000005 | 201 || mysql-bin.000006 | 201 || mysql-bin.000007 | 201 || mysql-bin.000008 | 201 || mysql-bin.000009 | 18949 || mysql-bin.000010 | 471 || mysql-bin.000011 | 1072 || mysql-bin.000012 | 177 || mysql-bin.000013 | 1171 || mysql-bin.000014 | 3548 |+------------------+-----------+14 rows in set (0.00 sec)mysql&gt; show master logs;+------------------+-----------+| Log_name | File_size |+------------------+-----------+| mysql-bin.000001 | 1045 || mysql-bin.000002 | 201 || mysql-bin.000003 | 201 || mysql-bin.000004 | 201 || mysql-bin.000005 | 201 || mysql-bin.000006 | 201 || mysql-bin.000007 | 201 || mysql-bin.000008 | 201 || mysql-bin.000009 | 18949 || mysql-bin.000010 | 471 || mysql-bin.000011 | 1072 || mysql-bin.000012 | 177 || mysql-bin.000013 | 1171 || mysql-bin.000014 | 3548 |+------------------+-----------+14 rows in set (0.00 sec) 3.查看Binlog记录时长,设置时长(过期自动删除) 123456789101112131415161718mysql&gt; show variables like &apos;expire_logs_days&apos;;+------------------+-------+| Variable_name | Value |+------------------+-------+| expire_logs_days | 7 |+------------------+-------+1 row in set (0.00 sec)mysql&gt; set global expire_logs_days=15;Query OK, 0 rows affected (0.00 sec)mysql&gt; show variables like &apos;expire_logs_days&apos;;+------------------+-------+| Variable_name | Value |+------------------+-------+| expire_logs_days | 15 |+------------------+-------+1 row in set (0.00 sec) 4.删除Binlog 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455mysql&gt; flush logs;Query OK, 0 rows affected (0.35 sec)mysql&gt; reset master;Query OK, 0 rows affected (0.35 sec)mysql&gt; show binary logs;+------------------+-----------+| Log_name | File_size |+------------------+-----------+| mysql-bin.000001 | 154 |+------------------+-----------+1 row in set (0.00 sec)mysql&gt; show master logs;+------------------+-----------+| Log_name | File_size |+------------------+-----------+| mysql-bin.000001 | 154 |+------------------+-----------+1 row in set (0.00 sec)查看Binlog文件目录[root@b04f945297ac mysql]# ls -alh. . .drwxr-x--- 1 mysql mysql 4.0K Apr 8 04:12 mysql-rw-r----- 1 mysql mysql 1.1K May 22 07:41 mysql-bin.000001-rw-r----- 1 mysql mysql 201 May 22 07:41 mysql-bin.000002-rw-r----- 1 mysql mysql 201 May 22 07:41 mysql-bin.000003-rw-r----- 1 mysql mysql 201 May 22 07:41 mysql-bin.000004-rw-r----- 1 mysql mysql 201 May 22 07:41 mysql-bin.000005-rw-r----- 1 mysql mysql 201 May 22 07:41 mysql-bin.000006-rw-r----- 1 mysql mysql 201 May 22 07:41 mysql-bin.000007-rw-r----- 1 mysql mysql 201 May 22 07:41 mysql-bin.000008-rw-r----- 1 mysql mysql 19K May 22 10:09 mysql-bin.000009-rw-r----- 1 mysql mysql 471 May 23 01:28 mysql-bin.000010-rw-r----- 1 mysql mysql 1.1K May 24 02:28 mysql-bin.000011-rw-r----- 1 mysql mysql 177 May 24 02:28 mysql-bin.000012-rw-r----- 1 mysql mysql 1.2K May 25 02:15 mysql-bin.000013-rw-r----- 1 mysql mysql 2.0K May 25 06:36 mysql-bin.000014-rw-r----- 1 mysql mysql 266 May 25 02:15 mysql-bin.indexsrwxrwxrwx 1 mysql mysql 0 May 25 02:15 mysql.sock-rw------- 1 mysql mysql 3 May 25 02:15 mysql.sock.lock. . .删除之后的目录[root@b04f945297ac mysql]# ls -alhtotal 313M. . .drwxr-x--- 1 mysql mysql 4.0K Apr 8 12:12 mysql-rw-r----- 1 mysql mysql 154 May 25 15:03 mysql-bin.000001-rw-r----- 1 mysql mysql 19 May 25 15:03 mysql-bin.indexsrwxrwxrwx 1 mysql mysql 0 May 25 10:15 mysql.sock-rw------- 1 mysql mysql 3 May 25 10:15 mysql.sock.lock. . . 5.自动清理Binlog日志 如果堆积的binlog非常多，不要轻易设置改参数，可以使用purge命令 部分老化binlog 12mysql&gt; purge master logs before &apos;2018-05-25 16:25:00&apos;;//删除指定日期前的日志索引中binlog日志文件mysql&gt; purge master logs to &apos;binlog.000001&apos;;//删除指定日志文件 Binlog日志格式binary log可以通过mysqlbinlog命令来将log的信息打印出来，binlog模式总共可分为以下三种： statement ,row,mixed Statement:基于SQL语句的复制（statement-based replication, SBR） 每一条会修改数据的sql都会记录在binlog中。 优点：不需要记录每一行的变化，减少了binlog日志量，节约了IO, 提高了性能。 缺点：由于记录的只是执行语句，为了这些语句能在slave上正确运行，因此还必须记录每条语句在执行的时候的一些相关信息，以保证所有语句能在slave得到和在master端执行的时候相同的结果。另外mysql的复制，像一些特定函数的功能，slave可与master上要保持一致会有很多相关问题。 Row:基于行的复制（row-based replication, RBR） 5.1.5版本的MySQL才开始支持row level的复制,它不记录sql语句上下文相关信息，仅保存哪条记录被修改。 优点： binlog中可以不记录执行的sql语句的上下文相关的信息，仅需要记录那一条记录被修改成什么了。所以row的日志内容会非常清楚的记录下每一行数据修改的细节。而且不会出现某些特定情况下的存储过程，或function，以及trigger的调用和触发无法被正确复制的问题. 缺点:所有的执行的语句当记录到日志中的时候，都将以每行记录的修改来记录，这样可能会产生大量的日志内容 新版本的MySQL中对row level模式也被做了优化，并不是所有的修改都会以row level来记录，像遇到表结构变更的时候就会以statement模式来记录，如果sql语句确实就是update或者delete等修改数据的语句，那么还是会记录所有行的变更。 Mixed:混合模式复制（mixed-based replication, MBR） 从5.1.8版本开始，MySQL提供了Mixed格式，实际上就是Statement与Row的结合。在Mixed模式下，一般的语句修改使用statment格式保存binlog，如一些函数，statement无法完成主从复制的操作，则采用row格式保存binlog，MySQL会根据执行的每一条具体的sql语句来区分对待记录的日志形式，也就是在Statement和Row之间选择一种。 简而言之 statement：基于 SQL 语句的模式，binlog 数据量小，但是某些语句和函数在复制过程可能导致数据不一致甚至出错； mixed：混合模式，根据语句来选用是 statement 还是 row 模式； row：基于行的模式，记录的是行的完整变化。安全，但 binlog 会比其他两种模式大很多； 查看当前Binlog日志格式 1234567mysql&gt; show variables like &apos;binlog_format&apos;;+---------------+-------+| Variable_name | Value |+---------------+-------+| binlog_format | ROW |+---------------+-------+1 row in set (0.00 sec) 设置Binlog日志格式 123456789101112修改my.cnflog-bin=mysql-bin #binlog_format=STATEMENT #binlog_format=ROW binlog_format=MIXED 或者在运行时设置：mysql&gt; SET SESSION binlog_format = &apos;STATEMENT&apos;; mysql&gt; SET SESSION binlog_format = &apos;ROW&apos;; mysql&gt; SET SESSION binlog_format = &apos;MIXED&apos;; mysql&gt; SET GLOBAL binlog_format = &apos;STATEMENT&apos;; mysql&gt; SET GLOBAL binlog_format = &apos;ROW&apos;; mysql&gt; SET GLOBAL binlog_format = &apos;MIXED&apos;; 查看Binlog日志文件内容1.查看某个具体binlog文件的内容 12345678910111213mysql&gt; show binlog events in &quot;mysql-bin.000001&quot;;+------------------+-----+----------------+-----------+-------------+---------------------------------------+| Log_name | Pos | Event_type | Server_id | End_log_pos | Info |+------------------+-----+----------------+-----------+-------------+---------------------------------------+| mysql-bin.000001 | 4 | Format_desc | 1 | 123 | Server ver: 5.7.21-log, Binlog ver: 4 || mysql-bin.000001 | 123 | Previous_gtids | 1 | 154 | || mysql-bin.000001 | 154 | Anonymous_Gtid | 1 | 219 | SET @@SESSION.GTID_NEXT= &apos;ANONYMOUS&apos; || mysql-bin.000001 | 219 | Query | 1 | 302 | BEGIN || mysql-bin.000001 | 302 | Table_map | 1 | 378 | table_id: 180 (tourism.user_tags) || mysql-bin.000001 | 378 | Write_rows | 1 | 445 | table_id: 180 flags: STMT_END_F || mysql-bin.000001 | 445 | Xid | 1 | 476 | COMMIT /* xid=71618 */ |+------------------+-----+----------------+-----------+-------------+---------------------------------------+7 rows in set (0.00 sec) 2.查看某个具体binlog文件的内容 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960[root@b04f945297ac mysql]# pwd/var/lib/mysql[root@b04f945297ac mysql]# mysqlbinlog mysql-bin.000001 mysqlbinlog: [ERROR] unknown variable &apos;default-character-set=utf8mb4&apos;如果报错，加上--no-defaults参数运行即可[root@b04f945297ac mysql]# mysqlbinlog --no-defaults mysql-bin.000001 /*!50530 SET @@SESSION.PSEUDO_SLAVE_MODE=1*/;/*!50003 SET @OLD_COMPLETION_TYPE=@@COMPLETION_TYPE,COMPLETION_TYPE=0*/;DELIMITER /*!*/;# at 4#180525 16:02:24 server id 1 end_log_pos 123 CRC32 0x62d58cd0 Start: binlog v 4, server v 5.7.21-log created 180525 16:02:24 at startup# Warning: this binlog is either in use or was not closed properly.ROLLBACK/*!*/;BINLOG &apos;EMMHWw8BAAAAdwAAAHsAAAABAAQANS43LjIxLWxvZwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAQwwdbEzgNAAgAEgAEBAQEEgAAXwAEGggAAAAICAgCAAAACgoKKioAEjQAAdCM1WI=&apos;/*!*/;# at 123#180525 16:02:24 server id 1 end_log_pos 154 CRC32 0x57b5fe8d Previous-GTIDs# [empty]# at 154#180525 16:02:48 server id 1 end_log_pos 219 CRC32 0xa3058217 Anonymous_GTID last_committed=0 sequence_number=1 rbr_only=yes/*!50718 SET TRANSACTION ISOLATION LEVEL READ COMMITTED*//*!*/;SET @@SESSION.GTID_NEXT= &apos;ANONYMOUS&apos;/*!*/;# at 219#180525 16:02:48 server id 1 end_log_pos 302 CRC32 0xa849ecb0 Query thread_id=633 exec_time=0 error_code=0SET TIMESTAMP=1527235368/*!*/;SET @@session.pseudo_thread_id=633/*!*/;SET @@session.foreign_key_checks=1, @@session.sql_auto_is_null=0, @@session.unique_checks=1, @@session.autocommit=1/*!*/;SET @@session.sql_mode=1073741824/*!*/;SET @@session.auto_increment_increment=1, @@session.auto_increment_offset=1/*!*/;/*!\\C utf8mb4 *//*!*/;SET @@session.character_set_client=224,@@session.collation_connection=224,@@session.collation_server=8/*!*/;SET @@session.time_zone=&apos;SYSTEM&apos;/*!*/;SET @@session.lc_time_names=0/*!*/;SET @@session.collation_database=DEFAULT/*!*/;BEGIN/*!*/;# at 302#180525 16:02:48 server id 1 end_log_pos 378 CRC32 0x66324940 Table_map: `tourism`.`user_tags` mapped to number 180# at 378#180525 16:02:48 server id 1 end_log_pos 445 CRC32 0x25589cf0 Write_rows: table id 180 flags: STMT_END_FBINLOG &apos;KMMHWxMBAAAATAAAAHoBAAAAALQAAAAAAAEAB3RvdXJpc20ACXVzZXJfdGFncwALA/wPAQEPEREREREKAlAA/AMAAAAAAMAHQEkyZg==KMMHWx4BAAAAQwAAAL0BAAAAALQAAAAAAAEAAgAL///A/AMAAAAAAANjY2MBAAcAczowOiIiO1sIM6hbCDOo8JxYJQ==&apos;/*!*/;# at 445#180525 16:02:48 server id 1 end_log_pos 476 CRC32 0xd1963b7d Xid = 71618COMMIT/*!*/;SET @@SESSION.GTID_NEXT= &apos;AUTOMATIC&apos; /* added by mysqlbinlog */ /*!*/;DELIMITER ;# End of log file/*!50003 SET COMPLETION_TYPE=@OLD_COMPLETION_TYPE*/;/*!50530 SET @@SESSION.PSEUDO_SLAVE_MODE=0*/; 这里Binlog 显示和选择存储的格式相关 执行下面语句，查看对应Binlog记录格式 INSERT INTOstaff(name) VALUES (&#39;zhimma&#39;) row格式对应格式：1234BINLOG &apos;Cb8PWxMBAAAAOgAAAF0BAAAAAGQAAAAAAAEABHRlc3QABXN0YWZmAAYDDw8DAxIF/QL9AgAAkkVdDg==Cb8PWx4BAAAAPwAAAJwBAAAAAGQAAAAAAAEAAgAG/8ADAAAABgB6aGltbWEAAAAAAAAAAAAAgAAA statement格式对应格式：1234use `test`/*!*/;SET TIMESTAMP=1527758668/*!*/;INSERT INTO `staff` (`name`) VALUES (&apos;zhimma&apos;)/*!*/; mixd格式对应格式：1234BINLOG &apos;S74PWw8BAAAAdwAAAHsAAAAAAAQANS43LjIxLWxvZwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABLvg9bEzgNAAgAEgAEBAQEEgAAXwAEGggAAAAICAgCAAAACgoKKioAEjQAAY4lTRU= 提取Binlog文件提取指定的binlog日志123[root@b04f945297ac mysql]# mysqlbinlog --no-defaults /var/lib/mysql/mysql-bin.000001 |grep INSERT SET INSERT_ID=4/*!*/;INSERT INTO `staff` (`name`) VALUES (&apos;zhimma&apos;) 提取指定position位置的binlog日志123[root@b04f945297ac mysql]# mysqlbinlog --no-defaults --start-position=&quot;154&quot; --stop-position=&quot;481&quot; /var/lib/mysql/mysql-bin.000001 | grep INSERTSET INSERT_ID=5/*!*/;INSERT INTO `staff` (`name`) VALUES (&apos;zhimma&apos;) 提取指定position位置的binlog日志并输出到压缩文件12345[root@b04f945297ac binlog]# mysqlbinlog --no-defaults --start-position=&quot;154&quot; --stop-position=&quot;481&quot; /var/lib/mysql/mysql-bin.000001 |gzip &gt; extra_01.sql.gz[root@b04f945297ac binlog]# lsextra_01.sql.gz建议加上过滤[root@b04f945297ac binlog]# mysqlbinlog --no-defaults --start-position=&quot;154&quot; --stop-position=&quot;481&quot; /var/lib/mysql/mysql-bin.000001 | grep INSERT | gzip &gt; extra_01.sql.gz 提取指定position位置的binlog日志导入数据库1[root@b04f945297ac binlog]# mysqlbinlog --no-defaults --start-position=&quot;154&quot; --stop-position=&quot;481&quot; /var/lib/mysql/mysql-bin.000001 | mysql -uroot -p 提取指定时间区间的binlog并输出到日志文件1[root@b04f945297ac binlog]# mysqlbinlog --no-defaults --start-datetime=&quot;2018-05-30 00:00:00&quot; --stop-datetime=&quot;2018-06-30 00:00:00&quot; /var/lib/mysql/mysql-bin.000001 --result-file=20180530_20180630.sql 提取指定位置的多个binlog日志文件1[root@b04f945297ac binlog]# mysqlbinlog --no-defaults --start-datetime=&quot;2018-05-30 00:00:00&quot; --stop-datetime=&quot;2018-06-30 00:00:00&quot; /var/lib/mysql/mysql-bin.000001 /var/lib/mysql/mysql-bin.000002 --result-file=20180530_20180630.sql 提取指定数据库binlog并转换字符集到UTF81[root@b04f945297ac binlog]# mysqlbinlog --no-defaults --database=test --set-charset=utf8 --start-datetime=&quot;2018-05-30 00:00:00&quot; --stop-datetime=&quot;2018-06-30 00:00:00&quot; /var/lib/mysql/mysql-bin.000001 /var/lib/mysql/mysql-bin.000002 &gt; test_20180530_20180630.sql 远程提取使用row格式的binlog日志并输出到本地文件1[root@b04f945297ac binlog]# mysqlbinlog --no-defaults -urobin -p -P3606 -h192.168.1.1 --read-from-remote-server -vv --database=test --set-charset=utf8 --start-datetime=&quot;2018-05-30 00:00:00&quot; --stop-datetime=&quot;2018-06-30 00:00:00&quot; /var/lib/mysql/mysql-bin.000001 &gt; remote_20180530_20180630.sql 有了sql语句，数据就好恢复了 binlog2sql点击查看文档 https://blog.csdn.net/shudaqi2010/article/details/54412895","categories":[],"tags":[]},{"title":"","slug":"Git","date":"2018-09-29T11:08:49.323Z","updated":"2018-09-29T11:08:49.324Z","comments":true,"path":"2018/09/29/Git/","link":"","permalink":"http://yoursite.com/2018/09/29/Git/","excerpt":"","text":"Git集中式vs分布式集中式版本控制系统，版本库是集中存放在中央服务器的，而干活的时候，用的都是自己的电脑，所以要先从中央服务器取得最新的版本，然后开始干活，干完活了，再把自己的活推送给中央服务器。中央服务器就好比是一个图书馆，你要改一本书，必须先从图书馆借出来，然后回到家自己改，改完了，再放回图书馆。 集中式版本控制系统最大的毛病就是必须联网才能工作 分布式版本控制系统根本没有“中央服务器”，每个人的电脑上都是一个完整的版本库，这样，你工作的时候，就不需要联网了，因为版本库就在你自己的电脑上。既然每个人电脑上都有一个完整的版本库，那多个人如何协作呢？比方说你在自己电脑上改了文件A，你的同事也在他的电脑上改了文件A，这时，你们俩之间只需把各自的修改推送给对方，就可以互相看到对方的修改了。 安装后的配置12345678$ git config --global user.name &quot;Your Name&quot;$ git config --global user.email &quot;email@example.com&quot;$ git config --global color.ui true //Git会适当地显示不同的颜色$ git config --global alias.st status$ git config --global alias.co checkout$ git config --global alias.ci commit$ git config --global alias.br branch&amp; git config --global alias.last &apos;log -1&apos; Git是分布式版本控制系统，所以，每个机器都必须自报家门：你的名字和Email地址。git config命令的--global参数，用了这个参数，表示你这台机器上所有的Git仓库都会使用这个配置，当然也可以对某个仓库指定不同的用户名和Email地址。 文件的增删改查仓库管理运行git status命令看看仓库状态git diff查看文件修改记录 文件跟踪git log命令显示从最近到最远的提交日志 如果嫌输出信息太多，看得眼花缭乱的，可以试试加上--pretty=oneline参数Git提供了一个命令git reflog用来记录你的每一次命令 版本管理假如提交历史记录为下面所示1234$ git log --pretty=oneline3628164fb26d48395383f8f31179f24e0882e1e0 latest commitea34578d5496d7dd233c827ed32a8cd576c5ee85 second commitcb926e7ea50ad11b8f9e909c05226233bf755030 first commit 在Git中，用HEAD表示当前版本，也就是最新的提交3628164...882e1e0，上一个版本就是HEAD^，上上一个版本就是HEAD^^，当然往上100个版本写100个^比较容易数不过来，所以写成HEAD~100。Git允许我们在版本的历史之间穿梭，使用命令git reset --hard commit_id 我们要把当前版本“latest commit”回退到上一个版本“second commit”，就可以使用git reset命令：12$ git reset --hard HEAD^HEAD is now at ea34578 second commit 工作区和暂存区工作区（Working Directory）：就是你在电脑里能看到的目录版本库（Repository）：工作区有一个隐藏目录.git，这个不算工作区，而是Git的版本库。 版本库又名仓库，英文名repository，你可以简单理解成一个目录，这个目录里面的所有文件都可以被Git管理起来，每个文件的修改、删除，Git都能跟踪，以便任何时刻都可以追踪历史，或者在将来某个时刻可以“还原”。初始化一个Git仓库，使用git init命令。添加文件到Git仓库，分两步： 第一步，使用命令git add &lt;file&gt;，注意，可反复多次使用，添加多个文件； 第二步，使用命令git commit，完成。 Git的版本库里存了很多东西，其中最重要的就是称为stage（或者叫index）的暂存区，还有Git为我们自动创建的第一个分支master，以及指向master的一个指针叫HEAD。 git add命令实际上就是把要提交的所有修改放到暂存区（Stage），然后，执行git commit就可以一次性把暂存区的所有修改提交到分支。一旦提交后，如果你又没有对工作区做任何修改，那么工作区就是“干净”的 撤销修改当你改乱了工作区某个文件的内容，想直接丢弃工作区的修改时，用命令git checkout -- file当你不但改乱了工作区某个文件的内容，还添加到了暂存区时，想丢弃修改，分两步，第一步用命令git reset HEAD file，就回到了场景1，第二步按场景1操作。已经提交了不合适的修改到版本库时，想要撤销本次提交，使用命令git reset --hard commit_id 删除文件rm删除文件后，Git知道你删除了文件，因此，工作区和版本库就不一致了，git status命令会立刻告诉你哪些文件被删除了现在你有两个选择，一是确实要从版本库中删除该文件，那就用命令git rm删掉，并且git commit，现在，文件就从版本库中被删除了。另一种情况是删错了，因为版本库里还有呢，所以可以很轻松地把误删的文件恢复到最新版本，使用git checkout -- test.txt，git checkout其实是用版本库里的版本替换工作区的版本，无论工作区是修改还是删除，都可以“一键还原”。 命令git rm用于删除一个文件。如果一个文件已经被提交到版本库，那么你永远不用担心误删，但是要小心，你只能恢复文件到最新版本，你会丢失最近一次提交后你修改的内容。 关联远程仓库要关联一个远程库，使用命令git remote add origin git@server-name:path/repo-name.git；关联后，使用命令git push -u origin master第一次推送master分支的所有内容；此后，每次本地提交后，只要有必要，就可以使用命令git push origin master推送最新修改； 分支管理分支就是科幻电影里面的平行宇宙，当你正在电脑前努力学习Git的时候，另一个你正在另一个平行宇宙里努力学习SVN。如果两个平行宇宙互不干扰，那对现在的你也没啥影响。不过，在某个时间点，两个平行宇宙合并了，结果，你既学会了Git又学会了SVN！ 创建合并删除分支每次提交，Git都把它们串成一条时间线，这条时间线就是一个分支。截止到目前，只有一条时间线，在Git里，这个分支叫主分支，即master分支。HEAD严格来说不是指向提交，而是指向master，master才是指向提交的，所以，HEAD指向的就是当前分支。 每次提交，master分支都会向前移动一步，这样，随着你不断提交，master分支的线也越来越长 当我们创建新的分支，例如dev时，Git新建了一个指针叫dev，指向master相同的提交，再把HEAD指向dev，就表示当前分支在dev上 从现在开始，对工作区的修改和提交就是针对dev分支了，比如新提交一次后，dev指针往前移动一步，而master指针不变 假如我们在dev上的工作完成了，就可以把dev合并到master上。Git怎么合并呢？最简单的方法，就是直接把master指向dev的当前提交，就完成了合并： 合并完分支后，甚至可以删除dev分支。删除dev分支就是把dev指针给删掉，删掉后，我们就剩下了一条master分支： 开始实战：我们创建dev分支，然后切换到dev分支：12$ git checkout -b devSwitched to a new branch &apos;dev&apos; git checkout命令加上-b参数表示创建并切换，相当于以下两条命令： 123$ git branch dev$ git checkout devSwitched to branch &apos;dev&apos; 然后，用git branch命令查看当前分支：123$ git branch* dev master git branch命令会列出所有分支，当前分支前面会标一个*号 然后，我们就可以在dev分支上正常提交;如果dev分支的工作完成，我们就可以切换回master分支： 12$ git checkout masterSwitched to branch &apos;master&apos; 切换回master分支后，再查看一个readme.txt文件，刚才添加的内容不见了！因为那个提交是在dev分支上，而master分支此刻的提交点并没有变： 现在，我们把dev分支的工作成果合并到master分支上：12345$ git merge devUpdating d17efd8..fec145aFast-forward readme.txt | 1 + 1 file changed, 1 insertion(+) 合并完成后，就可以放心地删除dev分支了： 12$ git branch -d devDeleted branch dev (was fec145a). 丢弃一个没有被合并过的分支，可以通过git branch -D &lt;name&gt;强行删除。 删除后，查看branch，就只剩下master分支了： 12$ git branch* master 总结： Git鼓励大量使用分支： 查看分支：git branch 创建分支：git branch &lt;name&gt; 切换分支：git checkout &lt;name&gt; 创建+切换分支：git checkout -b &lt;name&gt; 合并某分支到当前分支：git merge &lt;name&gt; 删除分支：git branch -d &lt;name&gt; 分支策略在实际开发中，我们应该按照几个基本原则进行分支管理： 首先，master分支应该是非常稳定的，也就是仅用来发布新版本，平时不能在上面干活； 那在哪干活呢？干活都在dev分支上，也就是说，dev分支是不稳定的，到某个时候，比如1.0版本发布时，再把dev分支合并到master上，在master分支发布1.0版本； 你和你的小伙伴们每个人都在dev分支上干活，每个人都有自己的分支，时不时地往dev分支上合并就可以了。 所以，团队合作的分支看起来就像这样： Bug分支-暂存文件当你接到一个修复一个代号101的bug的任务时，很自然地，你想创建一个分支issue-101来修复它，但是，等等，当前正在dev上进行的工作还没有提交，并不是你不想提交，而是工作只进行到一半，还没法提交，预计完成还需1天时间。但是，必须在两个小时内修复该bug，怎么办？ 幸好，Git还提供了一个stash功能，可以把当前工作现场“储藏”起来，等以后恢复现场后继续工作 123$ git stashSaved working directory and index state WIP on dev: 6224937 add mergeHEAD is now at 6224937 add merge 现在，用git status查看工作区，就是干净的（除非有没有被Git管理的文件），因此可以放心地创建分支来修复bug。等到bug修复完毕，继续在dev分支开发时，工作区是干净的，刚才的工作现场存到哪去了？用git stash list命令看看：12$ git stash liststash@&#123;0&#125;: WIP on dev: 6224937 add merge 一是用git stash apply恢复，但是恢复后，stash内容并不删除，你需要用git stash drop来删除； 另一种方式是用git stash pop，恢复的同时把stash内容也删了 多人协作多人协作的工作模式通常是这样： 首先，可以试图用git push origin branch-name推送自己的修改； 如果推送失败，则因为远程分支比你的本地更新，需要先用git pull试图合并； 如果合并有冲突，则解决冲突，并在本地提交； 没有冲突或者解决掉冲突后，再用git push origin branch-name推送就能成功！ 如果git pull提示“no tracking information”，则说明本地分支和远程分支的链接关系没有创建，用命令git branch --set-upstream branch-name origin/branch-name。 小结： 查看远程库信息，使用git remote -v； 本地新建的分支如果不推送到远程，对其他人就是不可见的； 从本地推送分支，使用git push origin branch-name，如果推送失败，先用git pull抓取远程的新提交； 在本地创建和远程分支对应的分支，使用git checkout -b branch-name origin/branch-name，本地和远程分支的名称最好一致； 建立本地分支和远程分支的关联，使用git branch --set-upstream branch-name origin/branch-name； 从远程抓取分支，使用git pull，如果有冲突，要先处理冲突。 标签管理发布一个版本时，我们通常先在版本库中打一个标签（tag），这样，就唯一确定了打标签时刻的版本。将来无论什么时候，取某个标签的版本，就是把那个打标签的时刻的历史版本取出来。所以，标签也是版本库的一个快照。 tag就是一个让人容易记住的有意义的名字，它跟某个commit绑在一起 创建标签在Git中打标签非常简单，首先，切换到需要打标签的分支上，然后，敲命令git tag &lt;name&gt;就可以打一个新标签1$ git tag v1.0 可以用命令git tag查看所有标签 12$ git tagv1.0 给之前的提交打标签1$ git tag tag_name commit_id 操作标签如果标签打错了，也可以删除：12$ git tag -d v0.1Deleted tag &apos;v0.1&apos; (was e078af9) 因为创建的标签都只存储在本地，不会自动推送到远程。所以，打错的标签可以在本地安全删除。 如果要推送某个标签到远程，使用命令git push origin &lt;tagname&gt;：1234$ git push origin v1.0Total 0 (delta 0), reused 0 (delta 0)To git@github.com:michaelliao/learngit.git * [new tag] v1.0 -&gt; v1.0 或者，一次性推送全部尚未推送到远程的本地标签： 1234567$ git push origin --tagsCounting objects: 1, done.Writing objects: 100% (1/1), 554 bytes, done.Total 1 (delta 0), reused 0 (delta 0)To git@github.com:michaelliao/learngit.git * [new tag] v0.2 -&gt; v0.2 * [new tag] v0.9 -&gt; v0.9 如果标签已经推送到远程，要删除远程标签就麻烦一点，先从本地删除 12$ git tag -d v0.9Deleted tag &apos;v0.9&apos; (was 6224937) 然后，从远程删除。删除命令也是push，但是格式如下： 123$ git push origin :refs/tags/v0.9To git@github.com:michaelliao/learngit.git - [deleted] v0.9 小结： 命令git push origin &lt;tagname&gt;可以推送一个本地标签； 命令git push origin --tags可以推送全部未推送过的本地标签； 命令git tag -d &lt;tagname&gt;可以删除一个本地标签； 命令git push origin :refs/tags/&lt;tagname&gt;可以删除一个远程标签。","categories":[],"tags":[]},{"title":"AJAX解决跨域问题（Access-Control-Allow-Origin）","slug":"AJAX解决跨域问题（Access-Control-Allow-Origin）","date":"2017-06-12T11:37:45.000Z","updated":"2018-09-29T11:08:49.323Z","comments":true,"path":"2017/06/12/AJAX解决跨域问题（Access-Control-Allow-Origin）/","link":"","permalink":"http://yoursite.com/2017/06/12/AJAX解决跨域问题（Access-Control-Allow-Origin）/","excerpt":"之前遇到过跨域的问题,一直觉得很神秘,也没有多关注,就过去了,今天又看到几篇文章说跨域,闲来无事于是将其整理记录下来； 一些概念先来阐述下几个概念: 跨域:是指浏览器对于JavaScript的同源策略限制,只要协议、域名、端口有任何一个不同,都被当作是不同的域,都不能执行或获取其他网站的资源； 姑且这么定义吧,举个简单例子,就是www.client.com网站上的程序不能从www.server.com网站上获取数据,如果强行获取,则会报出下面错误","text":"之前遇到过跨域的问题,一直觉得很神秘,也没有多关注,就过去了,今天又看到几篇文章说跨域,闲来无事于是将其整理记录下来； 一些概念先来阐述下几个概念: 跨域:是指浏览器对于JavaScript的同源策略限制,只要协议、域名、端口有任何一个不同,都被当作是不同的域,都不能执行或获取其他网站的资源； 姑且这么定义吧,举个简单例子,就是www.client.com网站上的程序不能从www.server.com网站上获取数据,如果强行获取,则会报出下面错误 有没有跨域,判断是不是属于跨域,可以参考下面: URL 说明 是否允许通信 http://www.a.com/a.js 调用 http://www.a.com/b.js 同一域名下 允许 http://www.a.com/lab/a.js 调用 http://www.a.com/script/b.js 同一域名下不同文件夹 允许 http://www.a.com:8000/a.js 调用 http://www.a.com/b.js 同一域名,不同端口 不允许 http://www.a.com/a.js 调用 https://www.a.com/b.js 同一域名,不同协议 不允许 http://www.a.com/a.js 调用 http://70.32.92.74/b.js 域名和域名对应ip 不允许 http://www.a.com/a.js 调用 http://script.a.com/b.js 主域相同,子域不同 不允许 http://www.a.com/a.js 调用 http://a.com/b.js 同一域名,不同二级域名（同上） 不允许（cookie这种情况下也不允许访问） http://www.cnblogs.com/a.js 调用 http://www.a.com/b.js 不同域名 不允许 CORS:CORS（Cross-Origin Resource Sharing）跨域资源共享,定义了必须在访问跨域资源时,浏览器与服务器应该如何沟通.CORS背后的基本思想就是使用自定义的HTTP头部让浏览器与服务器进行沟通,从而决定请求或响应是应该成功还是失败. 服务器端对于CORS的支持,主要就是通过设置Access-Control-Allow-Origin来进行的.如果浏览器检测到相应的设置,就可以允许Ajax进行跨域的访问. 解决方法Solution 1:服务端程序解决如果是双方预定沟通好请求允许数据,可以在服务端添加header头来解决 123header( &quot;Access-Control-Allow-Origin:*&quot; );header( &quot;Access-Control-Allow-Methods:POST,GET&quot; ); 看下面的例子: 客户端 www.client.com/cliend.html 123456789101112131415161718192021222324252627&lt;!DOCTYPE html&gt;&lt;html&gt;&lt;head&gt; &lt;meta http-equiv=&quot;content-type&quot; content=&quot;text/html;charset=utf-8&quot;&gt; &lt;title&gt; 跨域测试 &lt;/title&gt; &lt;script src=&quot;//code.jquery.com/jquery-1.11.3.min.js&quot;&gt;&lt;/script&gt;&lt;/head&gt;&lt;body&gt;&lt;button style=&quot;width:100px&quot;&gt;click client&lt;/button&gt;&lt;script type=&quot;text/javascript&quot;&gt; $(&quot;button&quot;).click(function () &#123; $.ajax(&#123; url: &quot;http://www.server.com/server.php&quot;, type: &quot;post&quot;, data: &#123;&apos;text&apos;: &apos;hello world&apos;&#125;, success: function (msg) &#123; $(&quot;button&quot;).html(msg); &#125; &#125;); &#125;);&lt;/script&gt;&lt;/body&gt;&lt;/html&gt; 服务器端 www.server.com/server.php 12345678910111213141516171819202122232425262728//允许所有域名获取数据&lt;?php$text = $_POST[&apos;text&apos;];//允许所有的域名header(&apos;content-type:application:json;charset=utf8&apos;);header(&apos;Access-Control-Allow-Origin:*&apos;); header(&apos;Access-Control-Allow-Methods:POST,GET&apos;); header(&apos;Access-Control-Allow-Headers:x-requested-with,content-type&apos;);echo json_encode($text);?&gt;//允许制定域名获取数据&lt;?php$text = $_POST[&apos;text&apos;];header(&apos;content-type:application:json;charset=utf8&apos;);$origin = isset($_SERVER[&apos;HTTP_ORIGIN&apos;]) ? $_SERVER[&apos;HTTP_ORIGIN&apos;] : &apos;&apos;;//允许指定域名$allow_origin = [ &apos;http://www.client.com&apos;, &apos;http://www.client2.com&apos;];if (in_array($origin, $allow_origin)) &#123; header(&apos;Access-Control-Allow-Origin:&apos; . $origin); header(&apos;Access-Control-Allow-Methods:POST,GET&apos;); header(&apos;Access-Control-Allow-Headers:x-requested-with,content-type&apos;);&#125;echo json_encode($text);?&gt; 这样,理论上就可以解决跨域问题: Solution 2:代理模式解决思路:例如 www.client.com/client.html 需要调用 www.server.com/server.php ,可以写一个接口 www.client.com/server.php ,由这个接口在后端去调用 www.server.com/server.php 并拿到返回值,然后再返回给index.html,这就是一个代理的模式.相当于绕过了浏览器端,自然就不存在跨域问题. Solution 3:使用JSONP使用之前,建议去看下我的另一篇文章Json和JsonP,然后再过来实践； 还是直接上代码: 客户端 www.client.com/client.html 12345678910111213141516171819202122232425262728293031&lt;!DOCTYPE html&gt;&lt;html&gt;&lt;head&gt; &lt;meta http-equiv=&quot;content-type&quot; content=&quot;text/html;charset=utf-8&quot;&gt; &lt;title&gt; 跨域测试 &lt;/title&gt; &lt;script src=&quot;//code.jquery.com/jquery-1.11.3.min.js&quot;&gt;&lt;/script&gt;&lt;/head&gt;&lt;body&gt;&lt;button id=&quot;clickMe&quot; style=&quot;width:100px&quot;&gt;click get jsonP&lt;/button&gt;&lt;script type=&quot;text/javascript&quot;&gt; $(&quot;#clickMe&quot;).click(function () &#123; $.ajax(&#123; url: &quot;http://www.server.com/jsonP.json&quot;, type: &quot;post&quot;, dataType: &quot;jsonP&quot;, data: &#123;&apos;text&apos;: &apos;hello world&apos;&#125;, jsonpCallback: &apos;returnData&apos;, //可自定义 函数名 success: function (msg) &#123; alert(msg.text); &#125;, error: function (XMLHttpRequest, textStatus, errorThrown) &#123; alert(XMLHttpRequest.status); alert(XMLHttpRequest.readyState); alert(textStatus); &#125; &#125;); &#125;);&lt;/script&gt;&lt;/body&gt;&lt;/html&gt; 服务器端 www.server.com/jsonP.json 1returnData(&#123;&quot;text&quot;:&quot;hello jsonP&quot;&#125;); 同样的也可以跨域获取数据 Solution 4:使用html5 API postMessage(转自这里)客户端 www.client.com/client.html 1234567891011121314151617181920&lt;!DOCTYPE html&gt;&lt;html lang=&quot;en&quot;&gt;&lt;head&gt; &lt;meta charset=&quot;UTF-8&quot;&gt; &lt;title&gt;Document&lt;/title&gt;&lt;/head&gt;&lt;body&gt;&lt;iframe style=&quot;display: none&quot; src=&quot;http://www.server.com/server.html&quot; name=&quot;postIframe&quot; onload=&quot;messageLoad()&quot;&gt;&lt;/iframe&gt;&lt;script&gt; function messageLoad() &#123; var url = &quot;http://www.server.com&quot;; window.postIframe.postMessage(&quot;给我tsort的信息&quot;, url); //发送数据 &#125; window.onmessage = function (e) &#123; e = e || event; console.log(e.data); //接收b返回的数据,在控制台有两次输出 &#125;&lt;/script&gt;&lt;/body&gt;&lt;/html&gt; 服务器端 www.server.com/server.html 12345678910111213141516171819202122&lt;!DOCTYPE html&gt;&lt;html lang=&quot;en&quot;&gt;&lt;head&gt; &lt;meta charset=&quot;UTF-8&quot;&gt; &lt;title&gt;Document&lt;/title&gt;&lt;/head&gt;&lt;body&gt;&lt;script&gt; window.onmessage = function(e)&#123; e = e || event; alert(e.data); //立即弹出a发送过来的数据 e.source.postMessage(&quot;好的,请稍等三秒！&quot;,e.origin); //立即回复a var postData = &#123;name:&quot;tsrot&quot;,age:24&#125;; var strData = JSON.stringify(postData); //json对象转化为字符串 setTimeout(function()&#123; e.source.postMessage(strData,e.origin); &#125;,3000); //3秒后向a发送数据 &#125;&lt;/script&gt;&lt;/body&gt;&lt;/html&gt;","categories":[{"name":"JavaScript","slug":"JavaScript","permalink":"http://yoursite.com/categories/JavaScript/"}],"tags":[{"name":"跨域","slug":"跨域","permalink":"http://yoursite.com/tags/跨域/"}]},{"title":"AJAX解决跨域问题（Access-Control-Allow-Origin）","slug":"JSON和JSONP","date":"2017-06-12T11:37:45.000Z","updated":"2018-09-29T11:08:49.324Z","comments":true,"path":"2017/06/12/JSON和JSONP/","link":"","permalink":"http://yoursite.com/2017/06/12/JSON和JSONP/","excerpt":"","text":"有一篇文章介绍了跨域问题的几种解决方法,其中有一种是使用jsonP方式解决,那么今天来详细说说Json和JsonP 前言说到AJAX就会不可避免的面临两个问题,第一个是AJAX以何种格式来交换数据?第二个是跨域的需求如何解决?,目前为止最被推崇或者说首选的方案还是用JSON来传数据,靠JSONP来跨域.而这就是本文将要讲述的内容 JSON和JSONP虽然只有一个字母的差别,但其实他们根本不是一回事儿: JSON是一种数据交换格式 JSONP是一种依靠开发人员的聪明才智创造出的一种非官方跨域数据交互协议. 我们拿最近比较火的谍战片来打个比方,JSON是地下党们用来书写和交换情报的“暗号”,而JSONP则是把用暗号书写的情报传递给自己同志时使用的接头方式.看到没?一个是描述信息的格式,一个是信息传递双方约定的方法. 什么是JSONJSON是一种基于文本的数据交换方式,或者叫做数据描述格式,你是否该选用他首先肯定要关注它所拥有的优点. JSON的优点: 基于纯文本,跨平台传递极其简单; Javascript原生支持,后台语言几乎全部支持; 轻量级数据格式,占用字符数量极少,特别适合互联网传递; 可读性较强,虽然比不上XML那么一目了然,但在合理的依次缩进之后还是很容易识别的; 容易编写和解析,当然前提是你要知道数据结构; JSON的格式或者叫规则JSON能够以非常简单的方式来描述数据结构,XML能做的它都能做,因此在跨平台方面两者完全不分伯仲. JSON只有两种数据类型描述符,大括号{}和方括号[],其余英文冒号:是映射符,英文逗号,是分隔符,英文双引号””是定义符. 大括号{}用来描述一组“不同类型的无序键值对集合”（每个键值对可以理解为OOP的属性描述）,方括号[]用来描述一组“相同类型的有序数据集合”（可对应OOP的数组）. 上述两种集合中若有多个子项,则通过英文逗号,进行分隔. 键值对以英文冒号:进行分隔,并且建议键名都加上英文双引号””,以便于不同语言的解析. JSON内部常用数据类型无非就是字符串、数字、布尔、日期、null 这么几个,字符串必须用双引号引起来,其余的都不用,日期类型比较特殊,这里就不展开讲述了,只是建议如果客户端没有按日期排序功能需求的话,那么把日期时间直接作为字符串传递就好,可以省去很多麻烦. JSON实例:123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172// 描述一个人var person = &#123;&quot;Name&quot;: &quot;Bob&quot;,&quot;Age&quot;: 32,&quot;Company&quot;: &quot;IBM&quot;,&quot;Engineer&quot;: true&#125;// 获取这个人的信息var personAge = person.Age;// 描述几个人var members = [&#123;&quot;Name&quot;: &quot;Bob&quot;,&quot;Age&quot;: 32,&quot;Company&quot;: &quot;IBM&quot;,&quot;Engineer&quot;: true&#125;,&#123;&quot;Name&quot;: &quot;John&quot;,&quot;Age&quot;: 20,&quot;Company&quot;: &quot;Oracle&quot;,&quot;Engineer&quot;: false&#125;,&#123;&quot;Name&quot;: &quot;Henry&quot;,&quot;Age&quot;: 45,&quot;Company&quot;: &quot;Microsoft&quot;,&quot;Engineer&quot;: false&#125;]// 读取其中John的公司名称var johnsCompany = members[1].Company;// 描述一次会议var conference = &#123;&quot;Conference&quot;: &quot;Future Marketing&quot;,&quot;Date&quot;: &quot;2012-6-1&quot;,&quot;Address&quot;: &quot;Beijing&quot;,&quot;Members&quot;:[&#123;&quot;Name&quot;: &quot;Bob&quot;,&quot;Age&quot;: 32,&quot;Company&quot;: &quot;IBM&quot;,&quot;Engineer&quot;: true&#125;,&#123;&quot;Name&quot;: &quot;John&quot;,&quot;Age&quot;: 20,&quot;Company&quot;: &quot;Oracle&quot;,&quot;Engineer&quot;: false&#125;,&#123;&quot;Name&quot;: &quot;Henry&quot;,&quot;Age&quot;: 45,&quot;Company&quot;: &quot;Microsoft&quot;,&quot;Engineer&quot;: false&#125;]&#125;// 读取参会者Henry是否工程师var henryIsAnEngineer = conference.Members[2].Engineer; 什么是JSONPJSONP的产生 一个众所周知的问题,Ajax直接请求普通文件存在跨域无权限访问的问题,甭管你是静态页面、动态网页、web服务、WCF,只要是跨域请求,一律不准; 不过我们又发现,Web页面上调用js文件时则不受是否跨域的影响（不仅如此,我们还发现凡是拥有”src”这个属性的标签都拥有跨域的能力,比如、、）; 于是可以判断,当前阶段如果想通过纯web端（ActiveX控件、服务端代理、属于未来的HTML5之Websocket等方式不算）跨域访问数据就只有一种可能,那就是在远程服务器上设法把数据装进js格式的文件里,供客户端调用和进一步处理; 恰巧我们已经知道有一种叫做JSON的纯字符数据格式可以简洁的描述复杂数据,更妙的是JSON还被js原生支持,所以在客户端几乎可以随心所欲的处理这种格式的数据; 这样子解决方案就呼之欲出了,web客户端通过与调用脚本一模一样的方式,来调用跨域服务器上动态生成的js格式文件（一般以JSON为后缀）,显而易见,服务器之所以要动态生成JSON文件,目的就在于把客户端需要的数据装入进去. 客户端在对JSON文件调用成功之后,也就获得了自己所需的数据,剩下的就是按照自己需求进行处理和展现了,这种获取远程数据的方式看起来非常像AJAX,但其实并不一样. 为了便于客户端使用数据,逐渐形成了一种非正式传输协议,人们把它称作JSONP,该协议的一个要点就是允许用户传递一个callback参数给服务端,然后服务端返回数据时会将这个callback参数作为函数名来包裹住JSON数据,这样客户端就可以随意定制自己的函数来自动处理返回数据了. JSONP的客户端具体实现 我们知道,哪怕跨域js文件中的代码（当然指符合web脚本安全策略的）,web页面也是可以无条件执行的. 远程服务器remoteserver.com根目录下有个remote.js文件代码如下: 1alert(&apos;我是远程文件&apos;); 本地服务器localserver.com下有个jsonp.html页面代码如下: 12345678910&lt;!DOCTYPE html PUBLIC &quot;-//W3C//DTD XHTML 1.0 Transitional//EN&quot; &quot;http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd&quot;&gt;&lt;html xmlns=&quot;http://www.w3.org/1999/xhtml&quot;&gt;&lt;head&gt; &lt;title&gt;&lt;/title&gt; &lt;script type=&quot;text/javascript&quot; src=&quot;http://remoteserver.com/remote.js&quot;&gt;&lt;/script&gt;&lt;/head&gt;&lt;body&gt;&lt;/body&gt;&lt;/html&gt; 结果是弹出一个alert框,则跨域调用成功！ 现在我们在jsonp.html页面定义一个函数,然后在远程remote.js中传入数据进行调用. jsonp.html页面代码如下: 123456789101112131415&lt;!DOCTYPE html PUBLIC &quot;-//W3C//DTD XHTML 1.0 Transitional//EN&quot; &quot;http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd&quot;&gt;&lt;html xmlns=&quot;http://www.w3.org/1999/xhtml&quot;&gt;&lt;head&gt; &lt;title&gt;&lt;/title&gt; &lt;script type=&quot;text/javascript&quot;&gt; var localHandler = function(data)&#123; alert(&apos;我是本地函数,可以被跨域的remote.js文件调用,远程js带来的数据是:&apos; + data.result); &#125;; &lt;/script&gt; &lt;script type=&quot;text/javascript&quot; src=&quot;http://remoteserver.com/remote.js&quot;&gt;&lt;/script&gt;&lt;/head&gt;&lt;body&gt;&lt;/body&gt;&lt;/html&gt; remote.js文件代码如下: 1localHandler(&#123;&quot;result&quot;:&quot;我是远程js带来的数据&quot;&#125;); 运行之后查看结果,页面成功弹出提示窗口,显示本地函数被跨域的远程js调用成功,并且还接收到了远程js带来的数据. 很欣喜,跨域远程获取数据的目的基本实现了,但是又一个问题出现了,我怎么让远程js知道它应该调用的本地函数叫什么名字呢?毕竟是jsonp的服务者都要面对很多服务对象,而这些服务对象各自的本地函数都不相同啊?我们接着往下看 聪明的开发者很容易想到,只要服务端提供的js脚本是动态生成的就行了呗,这样调用者可以传一个参数过去告诉服务端“我想要一段调用XXX函数的js代码,请你返回给我”,于是服务器就可以按照客户端的需求来生成js脚本并响应了. 12345678910111213141516171819202122&lt;!DOCTYPE html PUBLIC &quot;-//W3C//DTD XHTML 1.0 Transitional//EN&quot; &quot;http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd&quot;&gt;&lt;html xmlns=&quot;http://www.w3.org/1999/xhtml&quot;&gt;&lt;head&gt; &lt;title&gt;&lt;/title&gt; &lt;script type=&quot;text/javascript&quot;&gt; // 得到航班信息查询结果后的回调函数 var flightHandler = function(data)&#123; alert(&apos;你查询的航班结果是:票价 &apos; + data.price + &apos; 元,&apos; + &apos;余票 &apos; + data.tickets + &apos; 张.&apos;); &#125;; // 提供jsonp服务的url地址（不管是什么类型的地址,最终生成的返回值都是一段javascript代码） var url = &quot;http://flightQuery.com/jsonp/flightResult.aspx?code=CA1998&amp;callback=flightHandler&quot;; // 创建script标签,设置其属性 var script = document.createElement(&apos;script&apos;); script.setAttribute(&apos;src&apos;, url); // 把script标签加入head,此时调用开始 document.getElementsByTagName(&apos;head&apos;)[0].appendChild(script); &lt;/script&gt;&lt;/head&gt;&lt;body&gt;&lt;/body&gt;&lt;/html&gt; 这次的代码变化比较大,不再直接把远程js文件写死,而是编码实现动态查询,而这也正是jsonp客户端实现的核心部分,本例中的重点也就在于如何完成jsonp调用的全过程. 我们看到调用的url中传递了一个code参数,告诉服务器我要查的是CA1998次航班的信息,而callback参数则告诉服务器,我的本地回调函数叫做flightHandler,所以请把查询结果传入这个函数中进行调用. OK,服务器很聪明,这个叫做flightResult.aspx的页面生成了一段这样的代码提供给jsonp.html（服务端的实现这里就不演示了,与你选用的语言无关,说到底就是拼接字符串）: 12345flightHandler(&#123;&quot;code&quot;: &quot;CA1998&quot;,&quot;price&quot;: 1780,&quot;tickets&quot;: 5&#125;); 我们看到,传递给flightHandler函数的是一个json,它描述了航班的基本信息.运行一下页面,成功弹出提示窗口,jsonp的执行全过程顺利完成！ 到这里为止的话,相信你已经能够理解jsonp的客户端实现原理了吧?剩下的就是如何把代码封装一下,以便于与用户界面交互,从而实现多次和重复调用. 想知道jQuery如何实现jsonp调用?请看下文（我们依然沿用上面那个航班信息查询的例子,假定返回jsonp结果不变）: 123456789101112131415161718192021222324252627&lt;!DOCTYPE html PUBLIC &quot;-//W3C//DTD XHTML 1.0 Transitional//EN&quot; &quot;http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd&quot;&gt;&lt;html xmlns=&quot;http://www.w3.org/1999/xhtml&quot; &gt;&lt;head&gt; &lt;title&gt;Untitled Page&lt;/title&gt; &lt;script type=&quot;text/javascript&quot; src=jquery.min.js&quot;&gt;&lt;/script&gt; &lt;script type=&quot;text/javascript&quot;&gt; jQuery(document).ready(function()&#123; $.ajax(&#123; type: &quot;get&quot;, async: false, url: &quot;http://flightQuery.com/jsonp/flightResult.aspx?code=CA1998&quot;, dataType: &quot;jsonp&quot;, jsonp: &quot;callback&quot;,//传递给请求处理程序或页面的,用以获得jsonp回调函数名的参数名(一般默认为:callback) jsonpCallback:&quot;flightHandler&quot;,//自定义的jsonp回调函数名称,默认为jQuery自动生成的随机函数名,也可以写&quot;?&quot;,jQuery会自动为你处理数据 success: function(json)&#123; alert(&apos;您查询到航班信息:票价: &apos; + json.price + &apos; 元,余票: &apos; + json.tickets + &apos; 张.&apos;); &#125;, error: function()&#123; alert(&apos;fail&apos;); &#125; &#125;); &#125;); &lt;/script&gt;&lt;/head&gt;&lt;body&gt;&lt;/body&gt;&lt;/html&gt; 是不是有点奇怪? 为什么我这次没有写flightHandler这个函数呢? 而且竟然也运行成功了！哈哈,这就是jQuery的功劳了,jquery在处理jsonp类型的ajax时（还是忍不住吐槽,虽然jquery也把jsonp归入了ajax,但其实它们真的不是一回事儿）,自动帮你生成回调函数并把数据取出来供success属性方法来调用,是不是很爽呀? 作者补充 ajax和jsonp这两种技术在调用方式上“看起来”很像,目的也一样,都是请求一个url,然后把服务器返回的数据进行处理,因此jquery和ext等框架都把jsonp作为ajax的一种形式进行了封装; 但ajax和jsonp其实本质上是不同的东西.ajax的核心是通过XmlHttpRequest获取非本页内容,而jsonp的核心则是动态添加标签来调用服务器提供的js脚本. 所以说,其实ajax与jsonp的区别不在于是否跨域,ajax通过服务端代理一样可以实现跨域,jsonp本身也不排斥同域的数据的获取. 还有就是,jsonp是一种方式或者说非强制性协议,如同ajax一样,它也不一定非要用json格式来传递数据,如果你愿意,字符串都行,只不过这样不利于用jsonp提供公开服务. 总而言之,jsonp不是ajax的一个特例,哪怕jquery等巨头把jsonp封装进了ajax,也不能改变着一点 最后本文属于原创,我只是个搬运工,在此记录下,已备不时之需;","categories":[{"name":"JavaScript","slug":"JavaScript","permalink":"http://yoursite.com/categories/JavaScript/"}],"tags":[{"name":"跨域","slug":"跨域","permalink":"http://yoursite.com/tags/跨域/"}]},{"title":"Laravel开发前期准备","slug":"Laravel开发-工具类","date":"2017-06-10T16:09:16.000Z","updated":"2018-12-05T06:03:29.798Z","comments":true,"path":"2017/06/11/Laravel开发-工具类/","link":"","permalink":"http://yoursite.com/2017/06/11/Laravel开发-工具类/","excerpt":"环境 ： windows10 本地开发环境 ：SalamanderWnmp Phpstrom版本：Phpstrom 2017.1 Laravel版本：Laravel5.4","text":"环境 ： windows10 本地开发环境 ：SalamanderWnmp Phpstrom版本：Phpstrom 2017.1 Laravel版本：Laravel5.4 编辑器插件Laravel Plugin ctrl+alt+s打开PHPStrom设置页面，按如下操作 安装完成后，启用插件，如下图所示 然后再去写代码的时候就会提供controllers,views, routes, configuration, translations等的代码提示功能。 Laravel IDE Helper 有时候你会发现Route::之类的没有代码提示或者自动补全，这时候我们需要安装 Laravel IDE Helper 项目地址：GitHub 使用composer命令安装:require barryvdh/laravel-ide-helper```123456安装之后你需要把Laravel IDE Helper以服务的形式注册到应用中。修改**app/config/app.php**,添加```Barryvdh\\LaravelIdeHelper\\IdeHelperServiceProvider::class```, 到**providers**元素下。执行下面的命令 php artisan clear-compiled php artisan ide-helper:generate php artisan optimize ` [参考资料]：https://confluence.jetbrains.com/display/PhpStorm/Laravel+Development+using+PhpStorm","categories":[{"name":"Laravel","slug":"Laravel","permalink":"http://yoursite.com/categories/Laravel/"}],"tags":[{"name":"Laravel","slug":"Laravel","permalink":"http://yoursite.com/tags/Laravel/"}]},{"title":"数据库之主键、外键、索引","slug":"数据库之主键、外键、索引","date":"2017-06-09T14:21:11.000Z","updated":"2018-09-29T11:08:49.332Z","comments":true,"path":"2017/06/09/数据库之主键、外键、索引/","link":"","permalink":"http://yoursite.com/2017/06/09/数据库之主键、外键、索引/","excerpt":"主键 主键用来标志唯一的某一行,主键也是数据表中唯一索引,比如用户表中有id,name,但是id是唯一的,你要找出一个用户,就只能根据id去找,才能找出唯一一个,另外主键必须非空且唯一,一个表最多只能有一个主键,主键是可选的,但是为每个表指定主键通常会更好.MySQL中使用PRIMARY KEY来指定主键,","text":"主键 主键用来标志唯一的某一行,主键也是数据表中唯一索引,比如用户表中有id,name,但是id是唯一的,你要找出一个用户,就只能根据id去找,才能找出唯一一个,另外主键必须非空且唯一,一个表最多只能有一个主键,主键是可选的,但是为每个表指定主键通常会更好.MySQL中使用PRIMARY KEY来指定主键, 创建表时指定主键demo1 1234CREATE TABLE user ( id INT PRIMARY KEY auto_increment, username VARCHAR (255)); demo2 12345CREATE TABLE user ( id INT auto_increment, username VARCHAR (255), PRIMARY KEY (id)); 为已存在的表创建主键例如已存在表user(id,username),现在将字段id指定为主键并且自增 12ALTER TABLE USER ADD PRIMARY KEY (id), MODIFY id INT AUTO_INCREMENT; 删除主键12ALTER TABLE USER DROP PRIMARY KEY, MODIFY id INT; 外键 外键是用来指定参照完整性约束,举个例子： 假如某个电脑生产商,它的数据库中保存着整机和配件的产品信息.用来保存整机产品信息的表叫做 Pc;用来保存配件供货信息的表叫做Parts. 在Pc表中有一个字段,用来描述这款电脑所使用的CPU型号; 在Parts 表中相应有一个字段,描述的正是CPU的型号,我们可以把它想成是全部CPU的型号列表. 很显然,这个厂家生产的电脑,其使用的CPU一定是供货信息表(parts)中存在的型号.这时,两个表中就存在一种约束关系(constraint)——Pc表中的CPU型号受到Parts 表中型号的约束.被指定为外键的列必须要有索引,外键参考列必须为令一个表的主键; 创建表时指定外键例如user(id,username)和表article(id,uid,title),其中article.uid时外键指向user.id主键 123456CREATE TABLE article ( id INT auto_increment, uid INT, PRIMARY KEY (id), CONSTRAINT fk_user_article_uid FOREIGN KEY (uid) REFERENCES USER (id)); 注意：如果外键列没有索引,则MySQL会自动为其添加一个和外键同名的索引 修改表时添加外键约束1ALTER TABLE article ADD CONSTRAINT fk_user_article_uid FOREIGN KEY (uid) REFERENCES USER (id); 删除外键1ALTER TABLE article DROP FOREIGN KEY fk_user_article_uid; 注意：删除外键时,该外键对应的所索引并不会被删除 索引 普通索引这是最基本的索引类型,而且它没有唯一性之类的限制.普通索引可以通过以下几种方式创建： 建表时创建索引12CREATE INDEX &lt;索引的名字&gt; ON tablename (列的列表);CREATE INDEX name ON user (username); 修改表时添加索引12ALTER TABLE tablename ADD INDEX [索引的名字] (列的列表);ALTER TABLE USER ADD INDEX username (username); 唯一性索引这种索引和前面的”普通索引”基本相同,但有一个区别：索引列的所有值都只能出现一次,即必须唯一.唯一性索引可以用以下几种方式创建: 建表时创建索引12CREATE UNIQUE INDEX &lt;索引的名字&gt; ON tablename (列的列表);CREATE UNIQUE INDEX name ON user (username); 修改表时添加索引12ALTER TABLE tablename ADD UNIQUE INDEX [索引的名字] (列的列表);ALTER TABLE USER ADD UNIQUE INDEX username (username); 主键索引上文介绍过,此处略 全文索引MySQL从3.23.23版开始支持全文索引和全文检索.在MySQL中,全文索引的索引类型为FULLTEXT.全文索引可以在VARCHAR或者TEXT类型的列上创建.它可以通过CREATE TABLE命令创建,也可以通过ALTER TABLE或CREATE INDEX命令创建.对于大规模的数据集,通过ALTER TABLE（或者CREATE INDEX）命令创建全文索引要比把记录插入带有全文索引的空表更快 索引的其他说明 单列索引与多列索引索引可以是单列索引,也可以是多列索引. 添加索引1create INDEX 索引名称 ON tablename (row1,row2,row3); 修改索引1ALTER TABLE tablename ADD INDEX 索引名称 (row1,row2,row3); 最左前缀多列索引还有另外一个优点,它通过称为最左前缀（Leftmost Prefixing）的概念体现出来,我们举个列子： 现在我们有一个name、age、phone列上的多列索引,我们称这个索引为indexs.当搜索条件是以下各种列的组合时,MySQL将使用indexs索引： 1234name,age,phonename,agename 从另一方面理解,它相当于我们创建了(name、age、phone)、(name,age)以及(name)这些列组合上的索引.下面这些查询都能够使用这个indexs索引： 1234SELECT * FROM user WHERE user=&apos;Mike&apos; AND age=&apos;18&apos; AND phone=&apos;117&apos;; SELECT * FROM user WHERE user=&apos;Mike&apos; AND age=&apos;19&apos;; SELECT * FROM user WHERE user=&apos;Mike&apos; AND age=&apos;20&apos;; 如何选择索引列在性能优化过程中,选择在哪些列上创建索引是最重要的步骤之一.可以考虑使用索引的主要有两种类型的列：在WHERE子句中出现的列,在join子句中出现的列.请看下面这个查询： 1234567SELECT age ## 不使用索引 FROM user WHERE name =&apos;Mike&apos; ## 考虑使用索引 AND age=&apos;18&apos; ## 考虑使用索引SELECT article.title, ##不使用索引 user.name ##不使用索引 FROM user LEFT JOIN article ON user.id=article.uid ##考虑使用索引 WHERE user.phone=&apos;229&apos; ##考虑使用索引 AND nickname=&apos;mma&apos; ##考虑使用索引","categories":[{"name":"MySQL学习笔记","slug":"MySQL学习笔记","permalink":"http://yoursite.com/categories/MySQL学习笔记/"}],"tags":[{"name":"MySQL","slug":"MySQL","permalink":"http://yoursite.com/tags/MySQL/"}]},{"title":"设计模式-控制反转及其依赖注入(番外篇)","slug":"设计模式-控制反转及其依赖注入（番外篇）","date":"2017-05-07T09:36:10.000Z","updated":"2018-09-29T11:08:49.333Z","comments":true,"path":"2017/05/07/设计模式-控制反转及其依赖注入（番外篇）/","link":"","permalink":"http://yoursite.com/2017/05/07/设计模式-控制反转及其依赖注入（番外篇）/","excerpt":"上面有2篇文章介绍了PHP依赖注入和控制反转的概念和实例,为了加深理解才有这篇文章。 首先,我们假设,我们要开发一个组件命名为SomeComponent.这个组件中现在要注入一个数据库连接。在这个例子中,数据库连接在component中被创建,这种方法不可取,这样做的话,我们将不能改变数据库连接参数及数据库类型等一些参数。","text":"上面有2篇文章介绍了PHP依赖注入和控制反转的概念和实例,为了加深理解才有这篇文章。 首先,我们假设,我们要开发一个组件命名为SomeComponent.这个组件中现在要注入一个数据库连接。在这个例子中,数据库连接在component中被创建,这种方法不可取,这样做的话,我们将不能改变数据库连接参数及数据库类型等一些参数。 1234567891011121314151617181920212223242526&lt;?php class SomeComponent&#123; /** * The instantiation of the connection is hardcoded inside * the component so is difficult to replace it externally * or change its behavior */ public function someDbTask() &#123; $connection = new Connection(array( &quot;host&quot; =&gt; &quot;localhost&quot;, &quot;username&quot; =&gt; &quot;root&quot;, &quot;password&quot; =&gt; &quot;secret&quot;, &quot;dbname&quot; =&gt; &quot;invo&quot; )); // ... &#125; &#125; $some = new SomeComponent();$some-&gt;someDbTask(); 为了解决上面所说的问题,我们需要在使用前创建一个外部连接,并注入到容器中。就目前而言,这看起来是一个很好的解决方案： 1234567891011121314151617181920212223242526272829303132333435363738&lt;?php class SomeComponent&#123; protected $_connection; /** * Sets the connection externally */ public function setConnection($connection) &#123; $this-&gt;_connection = $connection; &#125; public function someDbTask() &#123; $connection = $this-&gt;_connection; // ... &#125; &#125; $some = new SomeComponent(); //Create the connection$connection = new Connection(array( &quot;host&quot; =&gt; &quot;localhost&quot;, &quot;username&quot; =&gt; &quot;root&quot;, &quot;password&quot; =&gt; &quot;secret&quot;, &quot;dbname&quot; =&gt; &quot;invo&quot;)); //Inject the connection in the component$some-&gt;setConnection($connection); $some-&gt;someDbTask(); 现在我们来考虑一个问题,我们在应用程序中的不同地方使用此组件,将多次创建数据库连接。使用一种类似全局注册表的方式,从这获得一个数据库连接实例,而不是使用一次就创建一次。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647&lt;?php class Registry&#123; /** * Returns the connection */ public static function getConnection() &#123; return new Connection(array( &quot;host&quot; =&gt; &quot;localhost&quot;, &quot;username&quot; =&gt; &quot;root&quot;, &quot;password&quot; =&gt; &quot;secret&quot;, &quot;dbname&quot; =&gt; &quot;invo&quot; )); &#125; &#125; class SomeComponent&#123; protected $_connection; /** * Sets the connection externally */ public function setConnection($connection)&#123; $this-&gt;_connection = $connection; &#125; public function someDbTask() &#123; $connection = $this-&gt;_connection; // ... &#125; &#125; $some = new SomeComponent(); //Pass the connection defined in the registry$some-&gt;setConnection(Registry::getConnection()); $some-&gt;someDbTask(); 现在,让我们来想像一下,我们必须在组件中实现两个方法,首先需要创建一个新的数据库连接,第二个总是获得一个共享连接：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384&lt;?php class Registry&#123; protected static $_connection; /** * Creates a connection */ protected static function _createConnection() &#123; return new Connection(array( &quot;host&quot; =&gt; &quot;localhost&quot;, &quot;username&quot; =&gt; &quot;root&quot;, &quot;password&quot; =&gt; &quot;secret&quot;, &quot;dbname&quot; =&gt; &quot;invo&quot; )); &#125; /** * 单例模式 * Creates a connection only once and returns it */ public static function getSharedConnection() &#123; if (self::$_connection===null)&#123; $connection = self::_createConnection(); self::$_connection = $connection; &#125; return self::$_connection; &#125; /** * Always returns a new connection */ public static function getNewConnection() &#123; return self::_createConnection(); &#125; &#125; class SomeComponent&#123; protected $_connection; /** * Sets the connection externally */ public function setConnection($connection)&#123; $this-&gt;_connection = $connection; &#125; /** * This method always needs the shared connection */ public function someDbTask() &#123; $connection = $this-&gt;_connection; // ... &#125; /** * This method always needs a new connection */ public function someOtherDbTask($connection) &#123; &#125; &#125; $some = new SomeComponent(); //This injects the shared connection$some-&gt;setConnection(Registry::getSharedConnection()); $some-&gt;someDbTask(); //Here, we always pass a new connection as parameter$some-&gt;someOtherDbTask(Registry::getConnection()); 到此为止,我们已经看到了如何使用依赖注入解决我们的问题。不是在代码内部创建依赖关系,而是让其作为一个参数传递,这使得我们的程序更容易维护,降低程序代码的耦合度,实现一种松耦合。但是从长远来看,这种形式的依赖注入也有一些缺点。 例如,如果组件中有较多的依赖关系,我们需要创建多个setter方法传递,或创建构造函数进行传递。另外,每次使用组件时,都需要创建依赖组件,使代码维护不太易,我们编写的代码可能像这样： 12345678910111213141516171819&lt;?php //Create the dependencies or retrieve them from the registry$connection = new Connection();$session = new Session();$fileSystem = new FileSystem();$filter = new Filter();$selector = new Selector(); //Pass them as constructor parameters$some = new SomeComponent($connection, $session, $fileSystem, $filter, $selector); // ... or using setters $some-&gt;setConnection($connection);$some-&gt;setSession($session);$some-&gt;setFileSystem($fileSystem);$some-&gt;setFilter($filter);$some-&gt;setSelector($selector); 我想,我们不得不在应用程序的许多地方创建这个对象。如果你不需要依赖的组件后,我们又要去代码注入部分移除构造函数中的参数或者是setter方法。为了解决这个问题,我们再次返回去使用一个全局注册表来创建组件。但是,在创建对象之前,它增加了一个新的抽象层： 1234567891011121314151617181920212223&lt;?php class SomeComponent&#123; // ... /** * Define a factory method to create SomeComponent instances injecting its dependencies */ public static function factory() &#123; $connection = new Connection(); $session = new Session(); $fileSystem = new FileSystem(); $filter = new Filter(); $selector = new Selector(); return new self($connection, $session, $fileSystem, $filter, $selector); &#125; &#125; 这一刻,我们好像回到了问题的开始,我们正在创建组件内部的依赖,我们每次都在修改以及找寻一种解决问题的办法,但这都不是很好的做法。 一种实用和优雅的来解决这些问题,是使用容器的依赖注入,像我们在前面看到的,容器作为全局注册表,使用容器的依赖注入做为一种桥梁来解决依赖可以使我们的代码耦合度更低,很好的降低了组件的复杂性： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061&lt;?php class SomeComponent&#123; protected $_di; public function __construct($di) &#123; $this-&gt;_di = $di; &#125; public function someDbTask() &#123; // Get the connection service // Always returns a new connection $connection = $this-&gt;_di-&gt;get(&apos;db&apos;); &#125; public function someOtherDbTask() &#123; // Get a shared connection service, // this will return the same connection everytime $connection = $this-&gt;_di-&gt;getShared(&apos;db&apos;); //This method also requires a input filtering service $filter = $this-&gt;_db-&gt;get(&apos;filter&apos;); &#125; &#125; $di = new Phalcon\\DI(); //Register a &quot;db&quot; service in the container$di-&gt;set(&apos;db&apos;, function()&#123; return new Connection(array( &quot;host&quot; =&gt; &quot;localhost&quot;, &quot;username&quot; =&gt; &quot;root&quot;, &quot;password&quot; =&gt; &quot;secret&quot;, &quot;dbname&quot; =&gt; &quot;invo&quot; ));&#125;); //Register a &quot;filter&quot; service in the container$di-&gt;set(&apos;filter&apos;, function()&#123; return new Filter();&#125;); //Register a &quot;session&quot; service in the container$di-&gt;set(&apos;session&apos;, function()&#123; return new Session();&#125;); //Pass the service container as unique parameter$some = new SomeComponent($di); $some-&gt;someTask(); 现在,该组件只有访问某种service的时候才需要它,如果它不需要,它甚至不初始化,以节约资源。该组件是高度解耦。他们的行为,或者说他们的任何其他方面都不会影响到组件本身。我们的实现办法 Phalcon\\DI 是一个实现了服务的依赖注入功能的组件,它本身也是一个容器。由于Phalcon高度解耦,Phalcon\\DI 是框架用来集成其他组件的必不可少的部分,开发人员也可以使用这个组件依赖注入和管理应用程序中不同类文件的实例。 基本上,这个组件实现了 Inversion of Control 模式。基于此,对象不再以构造函数接收参数或者使用setter的方式来实现注入,而是直接请求服务的依赖注入。这就大大降低了整体程序的复杂性,因为只有一个方法用以获得所需要的一个组件的依赖关系。 此外,这种模式增强了代码的可测试性,从而使它不容易出错。在容器中注册服务框架本身或开发人员都可以注册服务。当一个组件A要求调用组件B(或它的类的一个实例),可以从容器中请求调用组件B,而不是创建组件B的一个实例。 这种工作方式为我们提供了许多优点： 我们可以更换一个组件,从他们本身或者第三方轻松创建。 在组件发布之前,我们可以充分的控制对象的初始化,并对对象进行各种设置。 我们可以使用统一的方式从组件得到一个结构化的全局实例 服务可以通过以下几种方式注入到容器： 1234567891011121314151617181920&lt;?php //Create the Dependency Injector Container$di = new Phalcon\\DI(); //By its class name$di-&gt;set(&quot;request&quot;, &apos;Phalcon\\Http\\Request&apos;); //Using an anonymous function, the instance will lazy loaded$di-&gt;set(&quot;request&quot;, function()&#123; return new Phalcon\\Http\\Request();&#125;); //Registering directly an instance$di-&gt;set(&quot;request&quot;, new Phalcon\\Http\\Request()); //Using an array definition$di-&gt;set(&quot;request&quot;, array( &quot;className&quot; =&gt; &apos;Phalcon\\Http\\Request&apos;)); 在上面的例子中,当向框架请求访问一个请求数据时,它将首先确定容器中是否存在这个”reqeust”名称的服务。容器会反回一个请求数据的实例,开发人员最终得到他们想要的组件。 在上面示例中的每一种方法都有优缺点,具体使用哪一种,由开发过程中的特定场景来决定的。用一个字符串来设定一个服务非常简单,但缺少灵活性。设置服务时,使用数组则提供了更多的灵活性,而且可以使用较复杂的代码。lambda函数是两者之间一个很好的平衡,但也可能导致更多的维护管理成本。 Phalcon\\DI 提供服务的延迟加载。除非开发人员在注入服务的时候直接实例化一个对象,然后存存储到容器中。在容器中,通过数组,字符串等方式存储的服务都将被延迟加载,即只有在请求对象的时候才被初始化 123456789101112131415161718192021222324&lt;?php //Register a service &quot;db&quot; with a class name and its parameters$di-&gt;set(&quot;db&quot;, array( &quot;className&quot; =&gt; &quot;Phalcon\\Db\\Adapter\\Pdo\\Mysql&quot;, &quot;parameters&quot; =&gt; array( &quot;parameter&quot; =&gt; array( &quot;host&quot; =&gt; &quot;localhost&quot;, &quot;username&quot; =&gt; &quot;root&quot;, &quot;password&quot; =&gt; &quot;secret&quot;, &quot;dbname&quot; =&gt; &quot;blog&quot; ) ))); //Using an anonymous function$di-&gt;set(&quot;db&quot;, function()&#123; return new Phalcon\\Db\\Adapter\\Pdo\\Mysql(array( &quot;host&quot; =&gt; &quot;localhost&quot;, &quot;username&quot; =&gt; &quot;root&quot;, &quot;password&quot; =&gt; &quot;secret&quot;, &quot;dbname&quot; =&gt; &quot;blog&quot; ));&#125;); 以上这两种服务的注册方式产生相同的结果。然后,通过数组定义的,在后面需要的时候,你可以修改服务参数： 1234567&lt;?php $di-&gt;setParameter(&quot;db&quot;, 0, array( &quot;host&quot; =&gt; &quot;localhost&quot;, &quot;username&quot; =&gt; &quot;root&quot;, &quot;password&quot; =&gt; &quot;secret&quot;)); 从容器中获得服务的最简单方式就是使用”get”方法,它将从容器中返回一个新的实例： 12&lt;?php $request = $di-&gt;get(&quot;request&quot;); 或者通过下面这种魔术方法的形式调用： 123&lt;?php $request = $di-&gt;getRequest(); Phalcon\\DI //同时允许服务重用,为了得到一个已经实例化过的服务,可以使用 getShared() 方法的形式来获得服务。 具体的 Phalcon\\Http\\Request 请求示例： 12&lt;?php $request = $di-&gt;getShared(&quot;request&quot;); 参数还可以在请求的时候通过将一个数组参数传递给构造函数的方式： 12&lt;?php $component = $di-&gt;get(&quot;MyComponent&quot;, array(&quot;some-parameter&quot;, &quot;other&quot;)) 复制完毕,本文引自这里","categories":[{"name":"PHP","slug":"PHP","permalink":"http://yoursite.com/categories/PHP/"}],"tags":[{"name":"设计模式","slug":"设计模式","permalink":"http://yoursite.com/tags/设计模式/"}]},{"title":"设计模式-控制反转及其依赖注入(2)","slug":"设计模式-控制反转及其依赖注入（2）","date":"2017-05-07T05:50:16.000Z","updated":"2018-09-29T11:08:49.333Z","comments":true,"path":"2017/05/07/设计模式-控制反转及其依赖注入（2）/","link":"","permalink":"http://yoursite.com/2017/05/07/设计模式-控制反转及其依赖注入（2）/","excerpt":"上节我们介绍了控制反转及依赖注入的实现 最后在调用测试时： 12345678//用宝剑的英雄$class = new Hero(new Gun(&apos;倚天&apos;));$class-&gt;myWeapon();//我的倚天打起来唰唰唰~//用枪的英雄$class = new Hero(new Sword(&apos;沙漠之鹰&apos;));$class-&gt;myWeapon();//我的沙漠之鹰打起来砰砰砰~ 前言 我们看到,注入时需要实例化好所依赖的对象,再传到Hero类中,虽然通过依赖注入解决了解耦问题,但是在实际使用中,比较麻烦,因为每次都需要手动实例化依赖,再传递,这对于复杂大量的依赖关系,手动解决明显力不从心。因此,项目中需要一个自动化的依赖注入管理机制,这就是IoC容器; IoC容器：一个封装了依赖注入DI的框架,实现了动态创建注入依赖对象,管理依赖关系,管理对象声明周期等功能 核心实现,一般分为绑定(注册)对象生成器和创建对象注入依赖这两个核心步骤","text":"上节我们介绍了控制反转及依赖注入的实现 最后在调用测试时： 12345678//用宝剑的英雄$class = new Hero(new Gun(&apos;倚天&apos;));$class-&gt;myWeapon();//我的倚天打起来唰唰唰~//用枪的英雄$class = new Hero(new Sword(&apos;沙漠之鹰&apos;));$class-&gt;myWeapon();//我的沙漠之鹰打起来砰砰砰~ 前言 我们看到,注入时需要实例化好所依赖的对象,再传到Hero类中,虽然通过依赖注入解决了解耦问题,但是在实际使用中,比较麻烦,因为每次都需要手动实例化依赖,再传递,这对于复杂大量的依赖关系,手动解决明显力不从心。因此,项目中需要一个自动化的依赖注入管理机制,这就是IoC容器; IoC容器：一个封装了依赖注入DI的框架,实现了动态创建注入依赖对象,管理依赖关系,管理对象声明周期等功能 核心实现,一般分为绑定(注册)对象生成器和创建对象注入依赖这两个核心步骤 IoC容器 绑定(注册)对象生成器绑定：指的是将类于生成类对象的代码记录,对应,绑定起来。这样,在需要该类对象时,直接执行类对应的生成代码,就可以得到所需的对象; 1234567891011121314151617181920/** * 绑定类的生成器 * * @param $className 类名或者映射名,类的标志 * @param $generator 对应实例化或者可生成此类对象的代码 * * @throws \\Exception * * @author mma5694@gmail.com * @date 2017年5月7日00:42:02 */ public static function bind($className, $generator) &#123; //检测参数是否为合法的可调用结构 if (is_callable($generator)) &#123; self::$generatorList[$className] = $generator; &#125; else &#123; throw new \\Exception(&apos;对象生成器不是可调用的结构！&apos;); &#125; &#125; 注意bind方法,就是上面说的绑定(注册)对象生成器的实现,一般bind方法需要两个参数： 第一个就是类的标志,通常就是带有命名空间的类名称,也可以是自定义的类对应标志 第二个参数是一个匿名函数,也就是生成器,执行new的代码,这个参数可以是匿名函数、函数、类方法或者其他可执行的结构都是可以的 这样其实就是要用户提供类和该类对象的生成代码,将其对应,需要该类对象时再执行,但是注册时,并不调用生成类的代码,而仅仅时先存储起来(真精妙呀)。下面的例子就是将生成器代码存储到$generatorList数组中; 容器绑定对象生成器示例： 123456789101112131415use ClassFile\\Hero;use IImplements\\Sword;use IImplements\\Gun;//这里我第一个参数用的不带命名空间的类名IoContainer::bind(&apos;Gun&apos;, function ($title = &apos;&apos;) &#123; return new Gun($title);&#125;);IoContainer::bind(&apos;Sword&apos;, function ($title = &apos;&apos;) &#123; return new Sword($title);&#125;);IoContainer::bind(&apos;Hero&apos;, function ($module, $params = []) &#123; return new Hero(IoContainer::make($module, $params));&#125;); 调用bind()方法,提供类名和实例化类对象的匿名函数,我们的容器就会将类与生成器记录下来,等着需要时实例化生成所需对象 创建对象注入依赖方式1先看看完善后的IoContainer类 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748class IoContainer&#123; //定义存放类的容器？ protected static $generatorList = []; /** * 绑定类的生成器 * * @param $className 类名或者映射名,类的标志 * @param $generator 对应实例化或者可生成此类对象的代码 * * @throws \\Exception * * @author mma5694@gmail.com * @date 2017年5月7日00:42:02 */ public static function bind($className, $generator) &#123; //检测参数是否为合法的可调用结构 if (is_callable($generator)) &#123; self::$generatorList[$className] = $generator; &#125; else &#123; throw new \\Exception(&apos;对象生成器不是可调用的结构！&apos;); &#125; &#125; /** * 生成类的对象 * * @param $className * @param array $param * * @return mixed * @throws \\Exception * * @author mma5694@gmail.com * @date 2017年5月7日00:46:00 */ public static function make($className, $param = []) &#123; if (!isset(self::$generatorList[$className])) &#123; throw new \\Exception(&apos;类还没有绑定注册！&apos;); &#125; return call_user_func_array(self::$generatorList[$className], $param); &#125;&#125; 上面代码中的make方法就是用来生成对象的方法,该方法要获取所需的类,然后调用绑定时的生成器函数,来获取对象 通过make生成类对象： 1234$hero1 = IoContainer::make(&apos;Hero&apos;,[&apos;Sword&apos;,[&apos;屠龙刀&apos;]]);$hero1-&gt;myWeapon(); //我的屠龙刀打起来唰唰唰~$hero2 = IoContainer::make(&apos;Hero&apos;,[&apos;Gun&apos;,[&apos;AK-47&apos;]]);$hero2-&gt;myWeapon(); //我的AK-47打起来砰砰砰~ 方式2我们将所有的映射一一对应写入一个配置文件中,在容器类的构造方法中,引入配置文件中的所有对应关系,自动完成绑定(注册)对象生成器 1234567config.php return [ &apos;Sword&apos;=&gt;function($title=&apos;&apos;)&#123;return new \\IImplements\\Sword($title);&#125;, &apos;Gun&apos;=&gt;function($title=&apos;&apos;)&#123;return new \\IImplements\\Gun($title);&#125;, &apos;Hero&apos;=&gt;function($module,$params = [])&#123;return new \\ClassFile\\Hero(IoContainer\\IoContainer::make($module,$params));&#125;,]; 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061class IoContainer&#123; //定义存放类的容器？ protected static $generatorList = []; //配置文件注册 public function __construct() &#123; $config = dirname(dirname(__FILE__)) . &quot;/Config/config.php&quot;; $config = include $config; foreach ($config as $key =&gt; $value) &#123; if (is_callable($value)) &#123; self::$generatorList[$key] = $value; &#125; else &#123; throw new \\Exception(&apos;对象生成器不是可调用的结构！&apos;); &#125; &#125; &#125; /** * 绑定类的生成器 * * @param $className 类名或者映射名,类的标志 * @param $generator 对应实例化或者可生成此类对象的代码 * * @throws \\Exception * * @author mma5694@gmail.com * @date 2017年5月7日00:42:02 */ public static function bind($className, $generator) &#123; //检测参数是否为合法的可调用结构 if (is_callable($generator)) &#123; self::$generatorList[$className] = $generator; &#125; else &#123; throw new \\Exception(&apos;对象生成器不是可调用的结构！&apos;); &#125; &#125; /** * 生成类的对象 * * @param $className * @param array $param * * @return mixed * @throws \\Exception * * @author mma5694@gmail.com * @date 2017年5月7日00:46:00 */ public static function make($className, $param = []) &#123; if (!isset(self::$generatorList[$className])) &#123; throw new \\Exception(&apos;类还没有绑定注册！&apos;); &#125; return call_user_func_array(self::$generatorList[$className], $param); &#125;&#125; 这样就当调用容器类时,会自动绑定(注册)生成器 12345$container = new IoContainer();$hero1 = IoContainer::make(&apos;Hero&apos;,[&apos;Sword&apos;,[&apos;屠龙刀&apos;]]);$hero1-&gt;myWeapon(); //我的屠龙刀打起来唰唰唰~$hero2 = IoContainer::make(&apos;Hero&apos;,[&apos;Gun&apos;,[&apos;AK-47&apos;]]);$hero2-&gt;myWeapon(); //我的AK-47打起来砰砰砰~ 这样也是可以的; 上面的例子就完成了IoC容器的两个基本步骤：绑定和创建 结语 理解了什么是IoC容器, 本文的目的就达到了. 实际使用中(例如laravel)IoC容器的方法会有很多, 例如绑定构造器, 绑定对象实例, 绑定单例, 绑定接口实现等. 具体的使用就要到具体的框架或者产品中应用了 本文示例代码在这里,引用参考文章地址在这里","categories":[{"name":"PHP","slug":"PHP","permalink":"http://yoursite.com/categories/PHP/"}],"tags":[{"name":"设计模式","slug":"设计模式","permalink":"http://yoursite.com/tags/设计模式/"}]},{"title":"设计模式-控制反转及其依赖注入(1)","slug":"设计模式-控制反转及其依赖注入（1）","date":"2017-05-07T03:46:17.000Z","updated":"2018-09-29T11:08:49.333Z","comments":true,"path":"2017/05/07/设计模式-控制反转及其依赖注入（1）/","link":"","permalink":"http://yoursite.com/2017/05/07/设计模式-控制反转及其依赖注入（1）/","excerpt":"摘要 IoC:Inversion of Control 控制反转 DI：Dependency Injection 依赖注入 IoC与DI","text":"摘要 IoC:Inversion of Control 控制反转 DI：Dependency Injection 依赖注入 IoC与DI 先记住这句话：IoC是设计模式,而DI是IoC控制反转设计模式的典型实现 IoC控制反转是一种设计模式,用来解决对象间的过度依赖问题。 解决思路是：设法不在依赖对象中去获取(new)被依赖对象,最典型的的实现方式就是DI依赖注入了。 将对象所依赖的其他对象,在类外部生成好之后,传递到类内部的,而不是在类的内部实例化。这种解决依赖的方法就是DI依赖注入。 例如：对象Hero依赖对象Sword,我们可以选择如下定义方式： 123456789101112131415161718// 英雄依赖宝剑的定义实现class Sword&#123; private $title; public function __construct($title) &#123; $this-&gt;title = $title; &#125;&#125;class Hero&#123; private $weapon; public function __construct() &#123; // Hero依赖Sword $this-&gt;weapon = new Sword(&apos;倚天剑&apos;); &#125;&#125; 上面的代码中,Hero类对象就依赖Sword对象,但是在此例子中,Hero类对象对于Sword类对象的依赖就比较严重,一旦这个Hero使用的不再是Sword,而是Gun了,Hero的内部方法就要重写,在复杂的程序中,是不可取得,需要降低Hero对武器(无论是Sword或者Gun亦或者是其他武器)的直接依赖 解决思路就是设法不在依赖对象中去获取需要依赖的对象,这种思路就是IoC控制反转。 把原来本应在类(对象)内部完成的依赖,设法在类(对象)外部完成,这个由内到外的转化过程就是反转 所以：IoC反转最典型的实现方式就是依赖注入DI,如下代码所示 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172/** * 武器接口 * Interface Weapon */interface Weapon&#123; public function __construct($title); /** * 进攻 */ public function attack();&#125; /** * 宝剑类 */class Sword implements Weapon&#123; protected $title; public function __construct($title) &#123; $this-&gt;title = $title; &#125; public function attack() &#123; return &quot;我的&#123;$this-&gt;title&#125;打起来唰唰唰~&quot;; &#125; /** * 枪类 */class Gun implements Weapon&#123; protected $title; public function __construct($title) &#123; $this-&gt;title = $title; &#125; public function attack() &#123; return &quot;我的&#123;$this-&gt;title&#125;打起来砰砰砰~&quot;; &#125;&#125; class Hero&#123; private $weapon; /** * * 构造方法的参数是一个对象,通过类型约束限制必须为实现Weapon武器接口的对象 * 在构造方法中,直接将参数传递进来的武器对象赋值到当前对象的属性上 * 这样,英雄Hero依赖的对象不是在Hero类的内部实例化,而是在外部实例化好,传递到Hero内部的 * * 这就是《依赖注入》,通俗来讲,就是所依赖的对象在外部生成好之后,传递到类内内部的,而不是在 * 类内部实例化,这种解决依赖的方法就是DI依赖注入 * * * * Hero constructor。 * * @param Weapon $weapon */ public function __construct(Weapon $weapon) &#123; $this-&gt;weapon = $weapon; &#125; public function myWeapon() &#123; echo $this-&gt;weapon-&gt;attack(); &#125; 调用测试： 12345678//用宝剑的英雄$class = new Hero(new Gun(&apos;倚天&apos;));$class-&gt;myWeapon();//我的倚天打起来唰唰唰~//用枪的英雄$class = new Hero(new Sword(&apos;沙漠之鹰&apos;));$class-&gt;myWeapon();//我的沙漠之鹰打起来砰砰砰~ 这样,无论Hero需要宝剑还是枪,都可以通过外部注入的方式,将武器传递给Hero对象 通过构造方法传递参数,是依赖注入最常用的形式,除此之外,还有属性赋值的方法,也可以完成依赖注入,例如： 1234567// class Hero&#123; public $weapon;&#125;$hero = new Hero;$hero-&gt;weapon = new Sword(&apos;倚天&apos;); 以上就是平时所说的依赖注入,有没有理解呢？ 结语 解决了什么是依赖注入的问题, 本篇的目的就达到了,(示例代码在这里,本文参考引用这里)但还远远不够 , 注意上面的使用Hero的代码, 我们是手动将实例化好的武器对象作为参数传递给Hero的构造方法的。 此时的问题就是, 当出现大量的, 随机的需要注入的依赖如何处理? 一个个的实例化传递, 是否够自动化? 要解决这个问题, 就出现了IoC容器。 IoC容器也称为服务容器。 主要就是解决依赖和注入的问题。 实现机制是通过预先将创建对象的代码绑定或注册到IoC容器中, 然后利用该IoC容器创建对象, 在创建对象的过程中, 通过分析对象所需要的依赖(一般利用反射机制), 将注册好的创建对象的代码注入到对象的构造方法中去, 从而完成自动解决这个依赖注入的问题。 非常智能。 下篇我会接着记录","categories":[{"name":"PHP","slug":"PHP","permalink":"http://yoursite.com/categories/PHP/"}],"tags":[{"name":"设计模式","slug":"设计模式","permalink":"http://yoursite.com/tags/设计模式/"}]},{"title":"PHP中匿名函数","slug":"PHP中匿名函数","date":"2017-05-07T01:41:11.000Z","updated":"2018-09-29T11:08:49.328Z","comments":true,"path":"2017/05/07/PHP中匿名函数/","link":"","permalink":"http://yoursite.com/2017/05/07/PHP中匿名函数/","excerpt":"匿名函数,说白了就是”没有名字的函数” 123$foo = function()&#123; //this is a closure;&#125; 上面声明的就是匿名函数,没有什么特别的,和一般函数结构神似,唯独少了个函数名。并且这个函数可以作为一个值被赋予一个变量或者对象属性。这种特性是的拥有匿名函数的编程语言在设计一些应用时,更为灵活。 匿名函数和普通函数最大的区别是在于： 匿名函数可以作为一个具体的”值”赋予给变量或者对象属性 匿名函数可以被定义在不同地方,使得它可以有效利用他所在的局域内的变量（或者说上下文环境）","text":"匿名函数,说白了就是”没有名字的函数” 123$foo = function()&#123; //this is a closure;&#125; 上面声明的就是匿名函数,没有什么特别的,和一般函数结构神似,唯独少了个函数名。并且这个函数可以作为一个值被赋予一个变量或者对象属性。这种特性是的拥有匿名函数的编程语言在设计一些应用时,更为灵活。 匿名函数和普通函数最大的区别是在于： 匿名函数可以作为一个具体的”值”赋予给变量或者对象属性 匿名函数可以被定义在不同地方,使得它可以有效利用他所在的局域内的变量（或者说上下文环境） 1234567891011class foo&#123; public function exec(Closure $callback) &#123; echo $callback();//hi ,nick &#125;&#125;$name = &quot;nick&quot;;(new foo())-&gt;exec(function() use ($name)&#123; return &quot;hi ,&quot;.$name;&#125;); 可以看到,匿名函数使用使用了上下文中的变量$name。而实际上,这个匿名函数实在另一个地方被执行（foo类里面）。这样使得我们不必将变量$name的值通过参数传递到foo类的exec方法中,而且可以减少在exec方法中不必要的处理逻辑,使得类跟家专注于自己的职责； 匿名函数定义时不会被执行,除非被调用,上文中的例子就是这样,利用这种特性,我们可以利用它来实现一个控制反转（IoC）容器。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869/** * 一个简单的IoC容器 */class Container&#123; protected static $bindings; public static function bind($abstract, Closure $concrete) &#123; static::$bindings[$abstract] = $concrete; &#125; public static function make($abstract) &#123; return call_user_func(static::$bindings[$abstract]); &#125;&#125; /** * 示例用的 talk 类 */class talk&#123; public function greet($target) &#123; echo &apos;hi, &apos; . $target-&gt;getName(); &#125;&#125; /** * 示例用的 A 类 */class A&#123; public function getName() &#123; return &apos;Nick&apos;; &#125;&#125; /** * 示例用的 B 类 */class B&#123; public function getName() &#123; return &apos;Amy&apos;; &#125;&#125; // 以下代码是主要示例代码 // 创建一个talk类的实例$talk = new talk; // 将A类绑定至容器,命名为fooContainer::bind(&apos;foo&apos;, function() &#123; return new A;&#125;); // 将B类绑定至容器,命名为barContainer::bind(&apos;bar&apos;, function() &#123; return new B;&#125;); // 通过容器取出实例$talk-&gt;greet(Container::make(&apos;foo&apos;)); // hi, Nick$talk-&gt;greet(Container::make(&apos;bar&apos;)); // hi, Amy 上述例子中,只有通过make方法获取实例的时候,实例才被创建,使得我们可以实现容器。","categories":[{"name":"PHP","slug":"PHP","permalink":"http://yoursite.com/categories/PHP/"}],"tags":[{"name":"闭包/匿名函数","slug":"闭包-匿名函数","permalink":"http://yoursite.com/tags/闭包-匿名函数/"}]},{"title":"PhpStrom中安装CodeSniffer","slug":"PhpStrom中安装CodeSniffer","date":"2017-04-18T15:10:48.000Z","updated":"2018-09-29T11:08:49.328Z","comments":true,"path":"2017/04/18/PhpStrom中安装CodeSniffer/","link":"","permalink":"http://yoursite.com/2017/04/18/PhpStrom中安装CodeSniffer/","excerpt":"环境 ： windows10 本地开发环境 ：phpStudy Phpstrom版本：Phpstrom 2017.1","text":"环境 ： windows10 本地开发环境 ：phpStudy Phpstrom版本：Phpstrom 2017.1 Phpstrom Phpstorm是JetBrains 公司开发的跨平台的PHP IDE。在用Phpstorm编辑PHP，HTML和JavaScript的代码时，Phpstorm提供实施代码分析，错误提示和自动格式化等功能。支持的PHP版本包括5.3, 5.4, 5.5, 5.6 和 7.0。一款便携又强大的IDE，很多功能能够帮助你更好的进行开发。 PHP CodeSniffer PHP CodeSniffer是PEAR中的一个用PHP5写的一个PHP的代码风格检测器，它根据预先设定好的PHP编码风格和规则，去检查应用中的代码风格情况是否有违反一组预先设置好的编码标准，内置了ZEND，PEAR的编码风格规则，当然也支持自己定制。PHP CodeSniffer 是确保代码简洁一致的必不可少的开发工具，甚至还可以帮助程序员减少一些语义错误。 安装 PHP扩展安装 下载PEAR文件 切换到PHP软件目录，运行php go-pear.phar 按照提示指令输入，完成安装 装PHP Code Snifferpear install PHP_CodeSniffer 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263E:\\phpStudy\\php\\php-5.6.27-nts&gt;php go-pear.pharAre you installing a system-wide PEAR or a local copy?(system|local) [system] :Below is a suggested file layout for your new PEAR installation. Tochange individual locations, type the number in front of thedirectory. Type &apos;all&apos; to change all of them or simply press Enter toaccept these locations. 1. Installation base ($prefix) : E:\\phpStudy\\php\\php-5.6.27-nts 2. Temporary directory for processing : E:\\phpStudy\\php\\php-5.6.27-nts\\tmp 3. Temporary directory for downloads : E:\\phpStudy\\php\\php-5.6.27-nts\\tmp 4. Binaries directory : E:\\phpStudy\\php\\php-5.6.27-nts 5. PHP code directory ($php_dir) : E:\\phpStudy\\php\\php-5.6.27-nts\\pear 6. Documentation directory : E:\\phpStudy\\php\\php-5.6.27-nts\\docs 7. Data directory : E:\\phpStudy\\php\\php-5.6.27-nts\\data 8. User-modifiable configuration files directory : E:\\phpStudy\\php\\php-5.6.27-nts\\cfg 9. Public Web Files directory : E:\\phpStudy\\php\\php-5.6.27-nts\\www10. System manual pages directory : E:\\phpStudy\\php\\php-5.6.27-nts\\man11. Tests directory : E:\\phpStudy\\php\\php-5.6.27-nts\\tests12. Name of configuration file : C:\\Windows\\pear.ini13. Path to CLI php.exe : E:\\phpStudy\\php\\php-5.6.27-nts1-13, &apos;all&apos; or Enter to continue:Beginning install...Configuration written to C:\\Windows\\pear.ini...Initialized registry...Preparing to install...installing phar://E:/phpStudy/php/php-5.6.27-nts/go-pear.phar/PEAR/go-pear-tarballs/Archive_Tar-1.4.2.tar...installing phar://E:/phpStudy/php/php-5.6.27-nts/go-pear.phar/PEAR/go-pear-tarballs/Console_Getopt-1.4.1.tar...installing phar://E:/phpStudy/php/php-5.6.27-nts/go-pear.phar/PEAR/go-pear-tarballs/PEAR-1.10.3.tar...installing phar://E:/phpStudy/php/php-5.6.27-nts/go-pear.phar/PEAR/go-pear-tarballs/Structures_Graph-1.1.1.tar...installing phar://E:/phpStudy/php/php-5.6.27-nts/go-pear.phar/PEAR/go-pear-tarballs/XML_Util-1.4.2.tar...install ok: channel://pear.php.net/Archive_Tar-1.4.2install ok: channel://pear.php.net/Console_Getopt-1.4.1install ok: channel://pear.php.net/Structures_Graph-1.1.1install ok: channel://pear.php.net/XML_Util-1.4.2install ok: channel://pear.php.net/PEAR-1.10.3PEAR: Optional feature webinstaller available (PEAR&apos;s web-based installer)PEAR: Optional feature gtkinstaller available (PEAR&apos;s PHP-GTK-based installer)PEAR: Optional feature gtk2installer available (PEAR&apos;s PHP-GTK2-based installer)PEAR: To install optional features use &quot;pear install pear/PEAR#featurename&quot;** WARNING! Old version found at E:\\phpStudy\\php\\php-5.6.27-nts, please remove it or be sure to use the new e:\\phpstudy\\php\\php-5.6.27-nts\\pear.bat commandThe &apos;pear&apos; command is now at your service at e:\\phpstudy\\php\\php-5.6.27-nts\\pear.bat* WINDOWS ENVIRONMENT VARIABLES *For convenience, a REG file is available under E:\\phpStudy\\php\\php-5.6.27-ntsPEAR_ENV.reg .This file creates ENV variables for the current user.Double-click this file to add it to the current user registry.E:\\phpStudy\\php\\php-5.6.27-nts&gt;pear install PHP_CodeSnifferWARNING: channel &quot;pear.php.net&quot; has updated its protocols, use &quot;pear channel-update pear.php.net&quot; to updatedownloading PHP_CodeSniffer-2.8.1.tgz ...Starting to download PHP_CodeSniffer-2.8.1.tgz (522,712 bytes).........................................................................................................done: 522,712 bytesinstall ok: channel://pear.php.net/PHP_CodeSniffer-2.8.1 Phpstrom配置 下载对应的标准到Standard（E:\\phpStudy\\php\\php-5.6.27-nts\\pear\\PHP\\CodeSniffer\\Standards）目录下面 这里我省略了这一步 打开Phpstrom设置,依次打开Setting-&gt;Languages and Frameworks-&gt;PHP-&gt;Code Sniffer，按照下图操作 Standard配置，按照下图操作 最好保存即可预览效果","categories":[{"name":"PHP","slug":"PHP","permalink":"http://yoursite.com/categories/PHP/"}],"tags":[{"name":"PHP_CodeSniffer","slug":"PHP-CodeSniffer","permalink":"http://yoursite.com/tags/PHP-CodeSniffer/"}]},{"title":"Git生成多个ssh key","slug":"Git生成多个ssh-key","date":"2017-04-09T06:58:25.000Z","updated":"2018-09-29T11:08:49.324Z","comments":true,"path":"2017/04/09/Git生成多个ssh-key/","link":"","permalink":"http://yoursite.com/2017/04/09/Git生成多个ssh-key/","excerpt":"当使用了多个不同的git版本控制系统，分别有不同账号时，如一个在github上面有项目，一个在coding或者开源中国上面的有项目时，如果2者的邮箱不同时，就会涉及一个问题，生成的ssh key 会相互覆盖，必然有一个无法使用； 下面记录下解决方法：","text":"当使用了多个不同的git版本控制系统，分别有不同账号时，如一个在github上面有项目，一个在coding或者开源中国上面的有项目时，如果2者的邮箱不同时，就会涉及一个问题，生成的ssh key 会相互覆盖，必然有一个无法使用； 下面记录下解决方法： 生成ssh-key 12//创建github的ssh keyssh-keygen -t rsa -C &quot;your_email@example.com&quot; -f /c/user/username/.ssh/github_rsa 123456789101112131415161718192021222324252627example：//我的秘钥保存路径C:\\Users\\MMA\\.ssh\\test,邮箱使用your_email@example.comssh-keygen -t rsa -C &quot;your_email@example.com&quot; -f /c/Users/MMA/.ssh/test/github_rsa //运行之后弹出$ ssh-keygen -t rsa -C &quot;your_email@example.com&quot; -f /c/User/MMA/.ssh/test/test/github_rsaGenerating public/private rsa key pair.Enter passphrase (empty for no passphrase):回车默认即可，出现下面提示，则创建成功Your identification has been saved in /c/Users/MMA/.ssh/test/github_rsa.Your public key has been saved in /c/Users/MMA/.ssh/test/github_rsa.pub.The key fingerprint is:SHA256:AjEAqCT5VeTZsdHpklyMIVQQWbBVtAufE/P/GzkEw9I your_email@example.comThe key&apos;s randomart image is:+---[RSA 2048]----+|oo..o+OBBBo. ||+. .+.*.+=.o ||+. .. +.+++. E ||. . . +o.*. o || . S.= . . || . . .. .|| .+ || .o|| .o|+----[SHA256]-----+ 查看本地目录，GitHub ssh key生成成功 123456789101112131415161718192021222324//创建coding的ssh keyssh-keygen -t rsa -C &quot;my_email@example.com&quot; -f /c/Users/MMA/.ssh/test/coding_rsa和创建github的相似$ ssh-keygen -t rsa -C &quot;my_email@example.com&quot; -f /c/Users/MMA/.ssh/test/coding_rsaGenerating public/private rsa key pair.Enter passphrase (empty for no passphrase):Enter same passphrase again:Your identification has been saved in /c/Users/MMA/.ssh/test/coding_rsa.Your public key has been saved in /c/Users/MMA/.ssh/test/coding_rsa.pub.The key fingerprint is:SHA256:aqcMT/i9ZgXB6aCHus1zdf5JQlrLBYfUnnIBNJ37WIQ my_email@example.comThe key&apos;s randomart image is:+---[RSA 2048]----+| . o=+ o || . +. oE . || o o .o..= || o . o .o= . || . . S.oo.+ || . . ..=oo. . || +o +.o++ . || . +B.+o .o . || o=oo. .o |+----[SHA256]-----+ 添加私钥到SSH agent中 12ssh-add /c/Users/MMA/.ssh/test/coding_rsassh-add/c/Users/MMA/.ssh/test/github_rsa 如果执行ssh-add时提示&quot;Could not open a connection to your authentication agent&quot;，可以现执行命令：ssh-agent bash 重新添加即可 123456789101112MMA@MMA-PC MINGW64 ~/Desktop$ ssh-add /c/Users/MMA/.ssh/test/github_rsaIdentity added: /c/Users/MMA/.ssh/test/github_rsa (/c/Users/MMA/.ssh/test/github_rsa)MMA@MMA-PC MINGW64 ~/Desktop$ ssh-add /c/Users/MMA/.ssh/test/coding_rsaIdentity added: /c/Users/MMA/.ssh/test/coding_rsa (/c/Users/MMA/.ssh/test/coding_rsa)MMA@MMA-PC MINGW64 ~/Desktop$ ssh-add -l2048 SHA256:aqcMT/i9ZgXB6aCHus1zdf5JQlrLBYfUnnIBNJ37WIQ /c/Users/MMA/.ssh/test/coding_rsa (RSA)2048 SHA256:AjEAqCT5VeTZsdHpklyMIVQQWbBVtAufE/P/GzkEw9I /c/Users/MMA/.ssh/test/github_rsa (RSA) // 可以通过 ssh-add -l 来确私钥列表 ssh-add -l // 可以通过 ssh-add -D 来清空私钥列表 ssh-add -D 修改config文件 在/c/Users/MMA/.ssh/test 目录下新建一个config文件 12345678# coding Host git.coding.net PreferredAuthentications publickey IdentityFile /c/Users/MMA/.ssh/test/coding_rsa# github Host github.com PreferredAuthentications publickey IdentityFile /c/Users/MMA/.ssh/test/github_rsa 添加公钥到git平台 [coding教程]https://coding.net/help/doc/git/ssh-key.html) [github教程]https://help.github.com/articles/adding-a-new-ssh-key-to-your-github-account)","categories":[{"name":"Git","slug":"Git","permalink":"http://yoursite.com/categories/Git/"}],"tags":[{"name":"Git","slug":"Git","permalink":"http://yoursite.com/tags/Git/"}]},{"title":"CentOS中PHP7的安装","slug":"CentOS中PHP7的安装","date":"2017-04-08T14:47:10.000Z","updated":"2018-09-29T11:08:49.323Z","comments":true,"path":"2017/04/08/CentOS中PHP7的安装/","link":"","permalink":"http://yoursite.com/2017/04/08/CentOS中PHP7的安装/","excerpt":"本文安装参考这里，并且全程墙外网; 查看Linux版本cat /etc/centos-release CentOS Linux release 7.3.1611 (Core)","text":"本文安装参考这里，并且全程墙外网; 查看Linux版本cat /etc/centos-release CentOS Linux release 7.3.1611 (Core) 删除之前的 PHP 版本yum remove php* php-common //如果存在其他版本删除原来的版本 rpm 安装 Php7 相应的 yum源rpm -Uvh https://dl.fedoraproject.org/pub/epel/epel-release-latest-7.noarch.rpm rpm -Uvh https://mirror.webtatic.com/yum/el7/webtatic-release.rpm yum安装PHP7yum install php70w-fpm php70w-opcache 查看PHP版本php -v / php-fpm -v 附录 Package Provides Package Provides php70w mod_php, php70w-zts php70w-bcmath php70w-cli php-cgi, php-pcntl, php-readline php70w-common php-api, php-bz2, php-calendar, php-ctype, php-curl, php-date, php-exif, php-fileinfo,php-filter,php-ftp,php-gettext,php-gmp, php-hash, php-iconv, php-json, php-libxml, php-openssl,php-pcre,php-spl,php-tokenizer, php-zend-abi, php-zip, php-zlib php70w-dba php70w-devel php70w-embedded php-embedded-devel php70w-enchant php70w-fpm php70w-gd php70w-imap php70w-interbase php_database, php-firebird php70w-intl php70w-ldap php70w-mbstring php70w-mcrypt php70w-mysql php-mysqli, php_database php70w-mysqlnd php-mysqli, php_database php70w-odbc php-pdo_odbc, php_database php70w-opcache php70w-pecl-zendopcache php70w-pdo php70w-pdo_sqlite, php70w-sqlite3 php70w-pdo_dblib php70w-mssql php70w-pear php70w-pecl-apcu php70w-pecl-imagick php70w-pecl-redis php70w-pecl-xdebug php70w-pgsql php-pdo_pgsql, php_database php70w-phpdbg php70w-process php-posix, php-sysvmsg, php-sysvsem, php-sysvshm php70w-pspell php70w-recode php70w-snmp php70w-soap php70w-tidy php70w-xml php-dom, php-domxml, php-wddx, php-xsl php70w-xmlrpc","categories":[{"name":"Linux","slug":"Linux","permalink":"http://yoursite.com/categories/Linux/"}],"tags":[{"name":"PHP7","slug":"PHP7","permalink":"http://yoursite.com/tags/PHP7/"}]},{"title":"Centos7中，PHP7下，扩展的安装","slug":"Centos7中，PHP7下，扩展的安装","date":"2017-04-08T14:30:14.000Z","updated":"2018-09-29T11:08:49.323Z","comments":true,"path":"2017/04/08/Centos7中，PHP7下，扩展的安装/","link":"","permalink":"http://yoursite.com/2017/04/08/Centos7中，PHP7下，扩展的安装/","excerpt":"CentOS 下，PHP有多种方式来安装拓展， 主要有 包管理式的 yum 安装、pecl 安装， 以及源码编译安装。包管理式的安装卸载尤为方便，而源码编译式的安装则方便参数调优。一般搭建本机开发环境推荐包管理式的安装，节约时间。而线上部署环境则推荐编译安装， 方便调优。 环境和准备 环境 ： windows10 PHP版本：7.0.13 Nginx: 1.10.3 Centos: docker 创建的CentOS容器[CentOS Linux release 7.3.1611 (Core) ] 全程墙外网方式1： yum 安装扩展（mongodb）","text":"CentOS 下，PHP有多种方式来安装拓展， 主要有 包管理式的 yum 安装、pecl 安装， 以及源码编译安装。包管理式的安装卸载尤为方便，而源码编译式的安装则方便参数调优。一般搭建本机开发环境推荐包管理式的安装，节约时间。而线上部署环境则推荐编译安装， 方便调优。 环境和准备 环境 ： windows10 PHP版本：7.0.13 Nginx: 1.10.3 Centos: docker 创建的CentOS容器[CentOS Linux release 7.3.1611 (Core) ] 全程墙外网方式1： yum 安装扩展（mongodb） yum方式安装能自动安装扩展的.so动态库，并配置好php.ini yum search mongodb|grep php //搜索到拓展名为 php70w-pecl-mongodb 等待自动安装完成后，查看phpinfo 到此 yum 安装扩展方法介绍完毕 pecl 安装（redis） pecl 安装需要准备2个文件：phpize ，php-config 查找phpize的位置12[root@9e2c60482bdc conf.d]# whereis phpizephpize: /usr/bin/phpize 查找php-config的位置12[root@9e2c60482bdc conf.d]# whereis php-configphp-config:[root@9e2c60482bdc conf.d]# 发现没有php-config，先测试运行下phpize 123php-config:[root@9e2c60482bdc conf.d]# phpizeCan t find PHP headers in /usr/include/phpThe php-devel package is required for use of this command. 直接报错，接下来安装php-devel解决上面报错yum install php70w-devel 再次运行phpize,没有报找不到的错误，出现了下面的报错： 123[root@9e2c60482bdc bin]# phpizeCannot find config.m4. Make sure that you run /usr/bin/phpize in the top level source directory of the module 先不管他，进行下一步的操作 更新 pear（非必须）我们需要先从pear官网下载 go-pear 工具,这个工具将帮我们同时安装 pecl包管理器(管理php的C拓展) pear包管理器(管理php类库)； wget http://pear.php.net/go-pear.phar 下载完成后安装工具，运行下面命令：php go-pear.phar， 然后默认回车即可，暂时没搞懂这些参数的意思，估计是配置路经相关吧，先回车再说； 安装扩展（1）搜索扩展包：pecl search redis 123456789101112131415161718192021222324252627[root@9e2c60482bdc test]# pecl search redisWarning: Invalid argument supplied for foreach() in Command.php on line 249Warning: Invalid argument supplied for foreach() in /usr/share/pear/PEAR/Command.php on line 249Warning: Invalid argument supplied for foreach() in Command.php on line 249Warning: Invalid argument supplied for foreach() in /usr/share/pear/PEAR/Command.php on line 249Warning: Invalid argument supplied for foreach() in Command.php on line 249Warning: Invalid argument supplied for foreach() in /usr/share/pear/PEAR/Command.php on line 249Warning: Invalid argument supplied for foreach() in Command.php on line 249Warning: Invalid argument supplied for foreach() in /usr/share/pear/PEAR/Command.php on line 249Warning: Invalid argument supplied for foreach() in Command.php on line 249...Warning: Invalid argument supplied for foreach() in PEAR/Command.php on line 249Warning: Invalid argument supplied for foreach() in /usr/share/pear/PEAR/Command.php on line 249XML Extension not found 刷刷的报错了，查询错误后贴出解决方法： 解决方法 1vi /usr/bin/pecl //文件最后一行去掉 -n 参数 再次搜索， 123456[root@9e2c60482bdc test]# pecl search redisRetrieving data...0%Matched packages, channel pecl.php.net:=======================================Package Stable/(Latest) Localredis 3.1.2 (stable) PHP extension for interfacing with Redis 安装扩展包pecl install mongodb 123456789101112131415161718192021[root@9e2c60482bdc test]# pecl install redisdownloading redis-3.1.2.tgz ...Starting to download redis-3.1.2.tgz (199,041 bytes).................done: 199,041 bytes20 source files, buildingrunning: phpizeConfiguring for:PHP Api Version: 20151012Zend Module Api No: 20151012Zend Extension Api No: 320151012building in /tmp/pear/install/pear-build-rootLPns3m/redis-3.1.2running: /tmp/pear/install/redis/configure --with-php-config=/usr/bin/php-configchecking for grep that handles long lines and -e... /usr/bin/grepchecking for egrep... /usr/bin/grep -Echecking for a sed that does not truncate output... /usr/bin/sedchecking for cc... nochecking for gcc... noconfigure: error: in /tmp/pear/install/pear-build-rootLPns3m/redis-3.1.2:configure: error: no acceptable C compiler found in $PATHSee &apos;config.log&apos; for more detailsERROR: &apos;/tmp/pear/install/redis/configure --with-php-config=/usr/bin/php-config&apos; failed 刷刷的报错了，查询错误后贴出解决方法:yun install gcc gcc+ 安装扩展（2）执行：pecl install monodb 等待自动安装完成后，显示如下 12345Build process completed successfullyInstalling &apos;/usr/lib64/php/modules/redis.so&apos;install ok: channel://pecl.php.net/redis-3.1.2configuration option &quot;php_ini&quot; is not set to php.ini locationYou should add &quot;extension=redis.so&quot; to php.ini 然后在php配置文件中稍作修改，将extension=redis.so添加到php.ini中,重启PHP,查看phpinfo 到此 pecl 安装扩展方法介绍完毕 源码编译安装（Seaslog） Seaslog文档 安装git先安装git，克隆Seaslog源码 123456[root@9e2c60482bdc test]# git clone https://github.com/Neeke/SeasLog.gitCloning into &apos;SeasLog&apos;...remote: Counting objects: 1094, done.remote: Total 1094 (delta 0), reused 0 (delta 0), pack-reused 1094Receiving objects: 100% (1094/1094), 1.04 MiB | 24.00 KiB/s, done.Resolving deltas: 100% (628/628), done. 安装Seaslog进入Seaslog目录，执行 123$ /path/to/phpize //更换自己对应的目录$ ./configure --with-php-config=/path/to/php-config$ make &amp;&amp; make install 完成之后，修改php配置文件，将extension = seaslog.so添加到php.ini中,重启PHP,查看phpinfo 总结至此Linux中,给PHP安装扩展的3种方式记录完毕,特此总结 参考1 参考2 peal官网","categories":[{"name":"Linux","slug":"Linux","permalink":"http://yoursite.com/categories/Linux/"}],"tags":[{"name":"PHP7","slug":"PHP7","permalink":"http://yoursite.com/tags/PHP7/"}]},{"title":"CentOS7☞lnmp环境搭建","slug":"CentOS7☞lnmp环境搭建","date":"2017-02-27T10:00:51.000Z","updated":"2018-09-29T11:08:49.323Z","comments":true,"path":"2017/02/27/CentOS7☞lnmp环境搭建/","link":"","permalink":"http://yoursite.com/2017/02/27/CentOS7☞lnmp环境搭建/","excerpt":"本文转自这里 简介 LNMP是Linux、Nginx、MySQL(MariaDB)和PHP的缩写，这个组合是最常见的WEB服务器的运行环境之一。 本文将带领大家在CentOS 7操作系统上搭建一套LNMP环境。 本教程适用于CentOS 7.x版本。","text":"本文转自这里 简介 LNMP是Linux、Nginx、MySQL(MariaDB)和PHP的缩写，这个组合是最常见的WEB服务器的运行环境之一。 本文将带领大家在CentOS 7操作系统上搭建一套LNMP环境。 本教程适用于CentOS 7.x版本。 安装Nginx yum install nginx 如果报没有可用的软件包nginx错误，解决方法这这里 按照提示，输入yes后开始安装。安装完毕后，Nginx的配置文件在/etc/nginx目录下。使用以下命令启动Nginx：systemctl start nginx 检查系统中firewalld防火墙服务是否开启，如果已开启，我们需要修改防火墙配置，开启Nginx外网端口访问。systemctl status firewalld 如果显示active (running)，则需要调整防火墙规则的配置。 修改/etc/firewalld/zones/public.xml文件，在zone一节中增加：1234&lt;zone&gt; ... &lt;service name=&quot;nginx&quot;/&gt;&lt;zone&gt; 保存后重新加载firewalld服务：systemctl reload firewalld 可以通过浏览器访问 http://&lt;外网IP地址&gt; 来确定Nginx是否已经启动。 最后将Nginx设置为开机启动：systemctl enable nginx.service 测试环境的话，为了方便也可以先禁用掉防火墙 安装MySQL(MariaDB)https://my.oschina.net/Laily/blog/713023 MariaDB是MySQL的一个分支，主要由开源社区进行维护和升级，而MySQL被Oracle收购以后，发展较慢。在CentOS 7的软件仓库中，将MySQL更替为了MariaDB。 我们可以使用yum直接安装MariaDB：yum install mariadb-server 安装完成之后，执行以下命令重启MariaDB服务： systemctl start mariadb MariaDB默认root密码为空，我们需要设置一下，执行脚本：/usr/bin/mysql_secure_installation 首先提示输入当前的root密码：Enter current password for root (enter for none): 初始root密码为空，我们直接敲回车进行下一步Set root password? [Y/n] 设置root密码，默认选项为Yes，我们直接回车，提示输入密码，在这里设置您的MariaDB的root账户密码Remove anonymous users? [Y/n] 是否移除匿名用户，默认选项为Yes，建议按默认设置，回车继续Disallow root login remotely? [Y/n] 是否禁止root用户远程登录？如果您只在本机内访问MariaDB，建议按默认设置，回车继续Remove test database and access to it? [Y/n] 是否删除测试用的数据库和权限？ 建议按照默认设置，回车继续Reload privilege tables now? [Y/n] 是否重新加载权限表？因为我们上面更新了root的密码，这里需要重新加载，回车。 完成后你会看到Success!的提示，MariaDB的安全设置已经完成。我们可以使用以下命令登录MariaDB：mysql -uroot -p 按提示输入root密码，就会进入MariaDB的交互界面，说明已经安装成功。 最后我们将MariaDB设置为开机启动systemctl enable mariadb 安装PHP https://www.yaosansi.com/post/install-php-yum-on-centos/我们可以直接使用yum安装PHP：yum install php-fpm php-mysql 安装完成后我们将php-fpm启动：systemctl start php-fpm 将php-fpm设置为开机启动: systemctl enable php-fpm php安装完成之后，需要设置一下php session的目录：12sudo mkdir /var/lib/php/session/sudo chown -R apache:apache /var/lib/php/session/ 这时php-fpm已经安装完毕，但是现在需要配置一下Nginx，在/etc/nginx/conf.d目录中新建一个名为php.conf的文件，其内容为：123456789101112server &#123; listen 80; # pass the PHP scripts to FastCGI server listening on 127.0.0.1:9000 # location ~ \\.php$ &#123; root /usr/share/php; fastcgi_pass 127.0.0.1:9000; fastcgi_index index.php; fastcgi_param SCRIPT_FILENAME $document_root$fastcgi_script_name; include fastcgi_params; &#125;&#125; 然后执行以下命令使我们的配置生效：systemctl reload nginx 以上我们配置了Nginx的8000端口用来测试，如果您在美团云控制台创建机器时选择了绑定防火墙，需要检查该防火墙是否允许80端口，如果不允许的话，可以在防火墙设置中新增防火墙，并关联到该主机。 我们在/usr/share/php目录下新建一个名为phpinfo.php的文件用来展示phpinfo信息，文件内容为： &lt;?php echo phpinfo(); ?&gt; 我们从浏览器打开 http://&lt;外网IP地址&gt;:80/phpinfo.php，您就能看到phpinfo信息了，说明我们php环境已经部署成功; 升级PHP版本 yum 默认安装的版本是5.4，现在升级PHP版本至5.6 执行下面命令：123rpm -Uvh https://mirror.webtatic.com/yum/el7/epel-release.rpmrpm -Uvh https://mirror.webtatic.com/yum/el7/webtatic-release.rpm 执行下面的命令删除phpyum remove php-common然后像安装那样问你是否继续的，输入yes即可 安装php5.6 yum install -y php56w php56w-opcache php56w-xml php56w-fpm php56w-mcrypt php56w-gd php56w-devel php56w-mysql php56w-intl php56w-mbstring 查看php版本php-fpm --version 重启服务123systemctl restart nginxsystemctl restart mariadbsystemctl restart php-fpm","categories":[{"name":"Linux","slug":"Linux","permalink":"http://yoursite.com/categories/Linux/"}],"tags":[{"name":"lnmp","slug":"lnmp","permalink":"http://yoursite.com/tags/lnmp/"}]},{"title":"没有可用软件包nginx","slug":"没有可用软件包nginx","date":"2017-02-27T08:58:28.000Z","updated":"2018-09-29T11:08:49.332Z","comments":true,"path":"2017/02/27/没有可用软件包nginx/","link":"","permalink":"http://yoursite.com/2017/02/27/没有可用软件包nginx/","excerpt":"","text":"今天安装Nginx时候使用：yum install nginx，报出了没有可用软件包 nginx，我的环境是CentOS7,在网上查询后，贴出解决方法 ngixn官方解决方法 先创建yum的一个repository文件：/etc/yum.repos.d/nginx.repo； 将下面配置粘贴保存进去 12345[nginx]name=nginx repobaseurl=http://nginx.org/packages/centos/$releasever/$basearch/gpgcheck=0enabled=1 执行命令 1234(1)安装Nginxyum install nginx(2)启动nginxservice nginx start / systemctl start nginx.service","categories":[{"name":"遇到的问题","slug":"遇到的问题","permalink":"http://yoursite.com/categories/遇到的问题/"}],"tags":[{"name":"遇到的问题","slug":"遇到的问题","permalink":"http://yoursite.com/tags/遇到的问题/"}]},{"title":"MySQL中按照姓名或者中文首字母区间查询排序","slug":"mysql中按照姓名或者中文首字母区间查询排序","date":"2017-02-23T04:05:06.000Z","updated":"2018-09-29T11:08:49.329Z","comments":true,"path":"2017/02/23/mysql中按照姓名或者中文首字母区间查询排序/","link":"","permalink":"http://yoursite.com/2017/02/23/mysql中按照姓名或者中文首字母区间查询排序/","excerpt":"英文26个字母中除了i,u,v三个字母不能成为汉语拼音的首字母外,其它的字母都可以。先上一个表格,说明下各个字母字母的拼音编码的开始值和结束值","text":"英文26个字母中除了i,u,v三个字母不能成为汉语拼音的首字母外,其它的字母都可以。先上一个表格,说明下各个字母字母的拼音编码的开始值和结束值 字母 起值 止值 A 45217 45252 B 45253 45760 C 45761 46317 D 46318 46825 E 46826 47009 F 47010 47296 G 47297 47613 H 47614 48118 J 48119 49061 K 49062 49323 L 49324 49895 M 49896 50370 N 50371 50613 O 50614 50621 P 50622 50905 Q 50906 51386 R 51387 51445 S 51446 52217 T 52218 52697 W 52698 52979 X 52980 53688 Y 53689 54480 Z 54481 55289 用途：假如需要查询数据库中 以A-G字母开头的省,并且按照字母顺序排序：数据库中数据 需要的结果 类似这种结构或者这种数据排序,我们直接可以执行下面的sql语句查询 select * from wr_province where CONV(HEX(left(CONVERT(province_name USING gbk),1)),16,10) between 45217 and 47613 ORDER BY convert(province_name USING gbk) asc; 下面有一个我在自己项目中使用的例子,用的是循环查询,大家可以看看结果 1234567891011121314151617$sort = array( &apos;A-G&apos; =&gt; array(&apos;45217&apos;, &apos;47613&apos;), &apos;H-K&apos; =&gt; array(&apos;47614&apos;, &apos;49323&apos;), &apos;L-S&apos; =&gt; array(&apos;49324&apos;, &apos;52217&apos;), &apos;T-Z&apos; =&gt; array(&apos;52218&apos;, &apos;55289&apos;));$model = D(&apos;Province&apos;);$array = array();foreach ($sort as $key =&gt; $value)&#123; $sql = &quot;select * from wr_province where CONV(HEX(left(CONVERT(province_name USING gbk),1)),16,10) between &#123;$value[0]&#125; and &#123;$value[1]&#125; ORDER BY convert(province_name USING gbk) asc&quot;; $data = $model-&gt;query($sql); foreach ($data as $value)&#123; $array[$key][] = array(&apos;code&apos;=&gt;$value[&apos;province_id&apos;],&apos;address&apos;=&gt;$value[&apos;province_name&apos;]); &#125;&#125;debug(json_encode($array));//结果： 满足需求;","categories":[{"name":"MySQL","slug":"MySQL","permalink":"http://yoursite.com/categories/MySQL/"}],"tags":[{"name":"MySQL查询","slug":"MySQL查询","permalink":"http://yoursite.com/tags/MySQL查询/"}]},{"title":"sea.js中加载layer，缺少css文件解决","slug":"sea.js中加载layer，缺少css文件解决","date":"2017-02-08T07:37:45.000Z","updated":"2018-09-29T11:08:49.330Z","comments":true,"path":"2017/02/08/sea.js中加载layer，缺少css文件解决/","link":"","permalink":"http://yoursite.com/2017/02/08/sea.js中加载layer，缺少css文件解决/","excerpt":"今天做项目时遇到了一个问题，看下图页面错乱，询问前端工程师后，定位问题应该是缺少layer.css导致的，这就很奇怪了，之前的项目使用layer的时候，也只是单单的引入jquery和layer.min.js为什么现在这个新项目就不行了呢？ 答案就是：新项目使用sea.js进行js文件加载，可能内部的路径问题导致layer.js无法加载到自己的css文件，在网上查找一番之后，给出如下解决办法：","text":"今天做项目时遇到了一个问题，看下图页面错乱，询问前端工程师后，定位问题应该是缺少layer.css导致的，这就很奇怪了，之前的项目使用layer的时候，也只是单单的引入jquery和layer.min.js为什么现在这个新项目就不行了呢？ 答案就是：新项目使用sea.js进行js文件加载，可能内部的路径问题导致layer.js无法加载到自己的css文件，在网上查找一番之后，给出如下解决办法：123456789manage.js 使用的js文件define(function (require) &#123; var layer = require(&apos;layer&apos;); var paths = JSON.parse(PATH_INFO); layer.config(&#123; path: paths.remote_asset+&apos;/Common/Manage/plugins/layer/&apos; //layer.js所在的目录，可以是绝对目录，也可以是相对目录 &#125;);&#125;) 手动配置layer的路径，可以是绝对路径也可以是相对路径，只要能找得到layer的文件夹 1234567891011config.js sea.js配置文件alias: &#123; jquery: &apos;remote_asset/Manage/js/jquery.min.js&apos;, bootstrap: &apos;remote_asset/Manage/plugins/bootstrap-3.3.5/js/bootstrap.min.js&apos;, layer: &apos;remote_asset/Manage/plugins/layer/layer.min.js&apos;, validate: &apos;remote_asset/Manage/plugins/jquery-validation-1.13.1/jquery.validate.min.js&apos;, &#125;, preload: [ &apos;jquery&apos; ], 就这样，重新配置layer,让它自己能找到css文件并且加载，看看修改后的效果吧：","categories":[{"name":"遇到的问题","slug":"遇到的问题","permalink":"http://yoursite.com/categories/遇到的问题/"}],"tags":[{"name":"遇到的问题","slug":"遇到的问题","permalink":"http://yoursite.com/tags/遇到的问题/"}]},{"title":"sudo: sorry, you must have a tty to run sudo","slug":"sudo-sorry-you-must-have-a-tty-to-run-sudo","date":"2017-02-07T06:47:05.000Z","updated":"2018-09-29T11:08:49.330Z","comments":true,"path":"2017/02/07/sudo-sorry-you-must-have-a-tty-to-run-sudo/","link":"","permalink":"http://yoursite.com/2017/02/07/sudo-sorry-you-must-have-a-tty-to-run-sudo/","excerpt":"","text":"今天使用一个非root管理员操作服务器时，使用sudo命令报出了 sudo: sorry, you must have a tty to run sudo 错误，查找资料后记录如下解决方法： 使用不同账户，执行执行脚本时候sudo经常会碰到 sudo: sorry, you must have a tty to run sudo这个情况 其实修改一下sudo的配置就好了 vi /etc/sudoers (最好用visudo命令)注释掉 Default requiretty 一行#Default requiretty 意思就是sudo默认需要tty终端。注释掉就可以在后台执行了。","categories":[{"name":"遇到的问题","slug":"遇到的问题","permalink":"http://yoursite.com/categories/遇到的问题/"}],"tags":[{"name":"遇到的问题","slug":"遇到的问题","permalink":"http://yoursite.com/tags/遇到的问题/"}]},{"title":"常用的Git","slug":"常用的git","date":"2017-02-06T12:17:56.000Z","updated":"2018-09-29T11:08:49.331Z","comments":true,"path":"2017/02/06/常用的git/","link":"","permalink":"http://yoursite.com/2017/02/06/常用的git/","excerpt":"Git的概念Git是一款免费、开源的分布式版本控制系统，用于敏捷高效地处理任何或小或大的项目。Git是一个开源的分布式版本控制系统，可以有效、高速的处理从很小到非常大的项目版本管理。","text":"Git的概念Git是一款免费、开源的分布式版本控制系统，用于敏捷高效地处理任何或小或大的项目。Git是一个开源的分布式版本控制系统，可以有效、高速的处理从很小到非常大的项目版本管理。 工作原理 Workspace（工作区）： 执行git add *命令就把改动提交到了暂存区，执行git pull命令将远程仓库的数据拉到当前分支并合并，执行git checkout [branch-name]切换分支 Index（暂存区）： 执行git commit -m ‘说明’ 命令就把改动提交到了仓库区（当前分支） Repository（仓库区或本地仓库）： 执行git push origin master提交到远程仓库，执行git clone 地址将克隆远程仓库到本地 Remote（远程仓库）： 就是类似github，coding等网站所提供的仓库 Git术语仓库（Repository）：一个仓库包括了所有的版本信息、所有的分支和标记信息。在Git中仓库的每份拷贝都是完整的。仓库让你可以从中取得你的工作副本 分支（Branches）：一个分支意味着一个独立的、拥有自己历史信息的代码线（code line）。你可以从已有的代码中生成一个新的分支，这个分支与剩余的分支完全独立。默认的分支往往是叫master。用户可以选择一个分支，选择一个分支执行命令git checkout branch 标记（Tags）：一个标记指的是某个分支某个特定时间点的状态。通过标记，可以很方便的切换到标记时的状态，例如2016年11月17号在testing分支上的代码状态 提交（Commit）：提交代码后，仓库会创建一个新的版本。这个版本可以在后续被重新获得。每次提交都包括作者和提交者，作者和提交者可以是不同的人 修订（Revision）：用来表示代码的一个版本状态。Git通过用SHA1 hash算法表示的id来标识不同的版本。每一个 SHA1 id都是160位长，16进制标识的字符串.。最新的版本可以通过HEAD来获取。之前的版本可以通过”HEAD~1”来获取，以此类推 开始使用创建仓库12345678# 在当前目录新建一个Git代码库$ git init # 新建一个目录，将其初始化为Git代码库$ git init [project-name] # 下载一个项目和它的整个代码历史（各个分支提交记录等）$ git clone [url] git init后会出现.git文件夹，里面有配置文件，如果没有git bash里面输入ls -lah就可以看到了 配置Git的设置文件为.gitconfig，它可以在用户主目录下（全局配置），也可以在项目目录下（项目配置）123456789# 显示当前的Git配置$ git config --list # 编辑Git配置文件，只是配置用户信息的话直接看下面两行命令即可$ git config -e [--global] # 设置提交代码时的用户信息$ git config [--global] user.name &quot;[name]&quot;$ git config [--global] user.email &quot;[email address]&quot; 增加删除文件123456789101112131415161718192021# 添加指定文件到暂存区$ git add [file1] [file2] ... # 添加指定目录到暂存区，包括子目录$ git add [dir] # 添加当前目录的所有文件到暂存区$ git add . # 添加每个变化前，都会要求确认# 对于同一个文件的多处变化，可以实现分次提交$ git add -p # 删除工作区文件，并且将这次删除放入暂存区$ git rm [file1] [file2] ... # 停止追踪指定文件，但该文件会保留在工作区$ git rm --cached [file] # 改名文件，并且将这个改名放入暂存区$ git mv [file-original] [file-renamed] 提交文件123456789101112131415161718# 提交暂存区到仓库区$ git commit -m [message] # 提交暂存区的指定文件到仓库区$ git commit [file1] [file2] ... -m [message] # 提交工作区自上次commit之后的变化，直接到仓库区$ git commit -a # 提交时显示所有diff信息$ git commit -v # 使用一次新的commit，替代上一次提交# 如果代码没有任何新变化，则用来改写上一次commit的提交信息$ git commit --amend -m [message] # 重做上一次commit，并包括指定文件的新变化$ git commit --amend [file1] [file2] ... 推送远程服务器1234567891011121314151617181920212223# 下载远程仓库的所有变动$ git fetch [remote] # 显示所有远程仓库$ git remote -v # 显示某个远程仓库的信息$ git remote show [remote] # 增加一个新的远程仓库，并命名$ git remote add [shortname] [url] # 取回远程仓库的变化，并与本地分支合并$ git pull [remote] [branch] # 上传本地指定分支到远程仓库$ git push [remote] [branch] # 强行推送当前分支到远程仓库，即使有冲突$ git push [remote] --force # 推送所有分支到远程仓库$ git push [remote] --all 撤销12345678910111213141516171819202122232425262728293031# 恢复暂存区的指定文件到工作区$ git checkout [file] # 恢复某个commit的指定文件到暂存区和工作区$ git checkout [commit] [file] # 恢复暂存区的所有文件到工作区$ git checkout . # 重置暂存区的指定文件，与上一次commit保持一致，但工作区不变$ git reset [file] # 重置暂存区与工作区，与上一次commit保持一致$ git reset --hard # 重置当前分支的指针为指定commit，同时重置暂存区，但工作区不变$ git reset [commit] # 重置当前分支的HEAD为指定commit，同时重置暂存区和工作区，与指定commit一致$ git reset --hard [commit] # 重置当前HEAD为指定commit，但保持暂存区和工作区不变$ git reset --keep [commit] # 新建一个commit，用来撤销指定commit# 后者的所有变化都将被前者抵消，并且应用到当前分支$ git revert [commit] # 暂时将未提交的变化移除，稍后再移入$ git stash$ git stash pop 分支123456789101112131415161718192021222324252627282930313233343536373839404142# 列出所有本地分支$ git branch # 列出所有远程分支$ git branch -r # 列出所有本地分支和远程分支$ git branch -a # 新建一个分支，但依然停留在当前分支$ git branch [branch-name] # 新建一个分支，并切换到该分支$ git checkout -b [branch] # 新建一个分支，指向指定commit$ git branch [branch] [commit] # 新建一个分支，与指定的远程分支建立追踪关系$ git branch --track [branch] [remote-branch] # 切换到指定分支，并更新工作区$ git checkout [branch-name] # 切换到上一个分支$ git checkout - # 建立追踪关系，在现有分支与指定的远程分支之间$ git branch --set-upstream [branch] [remote-branch] # 合并指定分支到当前分支$ git merge [branch] # 选择一个commit，合并进当前分支$ git cherry-pick [commit] # 删除分支$ git branch -d [branch-name] # 删除远程分支$ git push origin --delete [branch-name]$ git branch -dr [remote/branch] 标签1234567891011121314151617181920212223242526# 列出所有tag$ git tag # 新建一个tag在当前commit$ git tag [tag] # 新建一个tag在指定commit$ git tag [tag] [commit] # 删除本地tag$ git tag -d [tag] # 删除远程tag$ git push origin :refs/tags/[tagName] # 查看tag信息$ git show [tag] # 提交指定tag$ git push [remote] [tag] # 提交所有tag$ git push [remote] --tags # 新建一个分支，指向某个tag$ git checkout -b [branch] [tag] 查看信息12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061# 显示有变更的文件$ git status # 显示当前分支的版本历史$ git log # 显示commit历史，以及每次commit发生变更的文件$ git log --stat # 搜索提交历史，根据关键词$ git log -S [keyword] # 显示某个commit之后的所有变动，每个commit占据一行$ git log [tag] HEAD --pretty=format:%s # 显示某个commit之后的所有变动，其&quot;提交说明&quot;必须符合搜索条件$ git log [tag] HEAD --grep feature # 显示某个文件的版本历史，包括文件改名$ git log --follow [file]$ git whatchanged [file] # 显示指定文件相关的每一次diff$ git log -p [file] # 显示过去5次提交$ git log -5 --pretty --oneline # 显示所有提交过的用户，按提交次数排序$ git shortlog -sn # 显示指定文件是什么人在什么时间修改过$ git blame [file]$ git blame [file] # 显示暂存区和工作区的差异$ git diff # 显示暂存区和上一个commit的差异$ git diff --cached [file] # 显示工作区与当前分支最新commit之间的差异$ git diff HEAD # 显示两次提交之间的差异$ git diff [first-branch]...[second-branch] # 显示今天你写了多少行代码$ git diff --shortstat &quot;@&#123;0 day ago&#125;&quot; # 显示某次提交的元数据和内容变化$ git show [commit] # 显示某次提交发生变化的文件$ git show --name-only [commit] # 显示某次提交时，某个文件的内容$ git show [commit]:[filename] # 显示当前分支的最近几次提交$ git reflog 附录 点击下载 git for windows客户端 安装教程","categories":[{"name":"Git","slug":"Git","permalink":"http://yoursite.com/categories/Git/"}],"tags":[{"name":"Git","slug":"Git","permalink":"http://yoursite.com/tags/Git/"}]},{"title":"PHP中匿名函数和闭包初探","slug":"PHP中匿名函数和闭包初探","date":"2017-02-04T12:17:56.000Z","updated":"2018-09-29T11:08:49.328Z","comments":true,"path":"2017/02/04/PHP中匿名函数和闭包初探/","link":"","permalink":"http://yoursite.com/2017/02/04/PHP中匿名函数和闭包初探/","excerpt":"「闭包」和「匿名」的区别首先，虽然闭包和匿名在PHP中对应的都是一个东西，但是闭包和匿名并不等价。 匿名是指这个函数可以想变量一样操作，例如可以赋值给一个变量或者作为参数传递，作为函数的返回值等。 闭包则是指这个函数可以从上下文中捕获变量（不是通过传参获取），例如PHP使用use这个子句来完成这个操作； 实际上，闭包和匿名函数是伪装成函数的对象。他们是Closure类的实例。闭包和字符串、整数一样，是一等值类型","text":"「闭包」和「匿名」的区别首先，虽然闭包和匿名在PHP中对应的都是一个东西，但是闭包和匿名并不等价。 匿名是指这个函数可以想变量一样操作，例如可以赋值给一个变量或者作为参数传递，作为函数的返回值等。 闭包则是指这个函数可以从上下文中捕获变量（不是通过传参获取），例如PHP使用use这个子句来完成这个操作； 实际上，闭包和匿名函数是伪装成函数的对象。他们是Closure类的实例。闭包和字符串、整数一样，是一等值类型 使用举例 提到闭包就不得不想起匿名函数，也叫闭包函数（closures），貌似PHP闭包实现主要就是靠它.所以，在PHP中闭包（Closure）就是匿名函数; 声明一个匿名函数12$func = function()&#123;&#125;; 可以看到，匿名函数因为没有名字，如果要使用它，需要将其返回给一个变量。匿名函数也像普通函数一样可以声明参数，调用方法也相同：1234567$message = function($name)&#123; echo &apos;hello &apos;.$name;&#125;;$message(&apos;world&apos;);//输出hello world 通常会把闭包当做函数的回调来使用 我们之所以能调用$message变量，是因为这个变量的值是一个闭包，而且闭包对象实现了invoke()魔术方法。只要变量名后有(),PHP就会查找并调用invoke()方法。 array_map(), preg_replace_callback()方法都会用到回调函数，这是使用闭包的最佳时机！ 12345$numbersPlusOne = array_map(function ($number) &#123; return $number + 1;&#125;, [1, 2, 3]);print_r($numbersPlusOne);//输出[2, 3, 4] use关键字1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950&lt;?php// 一个基本的购物车，包括一些已经添加的商品和每种商品的数量。// 其中有一个方法用来计算购物车中所有商品的总价格。该方法使用了一个closure作为回调函数。class Cart&#123; const PRICE_BUTTER = 1.00; const PRICE_MILK = 3.00; const PRICE_EGGS = 6.95; protected $products = array(); public function add($product, $quantity) &#123; $this-&gt;products[$product] = $quantity; &#125; public function getQuantity($product) &#123; return isset($this-&gt;products[$product]) ? $this-&gt;products[$product] : FALSE; &#125; public function getTotal($tax) &#123; $total = 0.00; $callback = function ($quantity, $product) use ($tax, &amp;$total) &#123; $pricePerItem = constant(__CLASS__ . &quot;::PRICE_&quot; . strtoupper($product)); $total += ($pricePerItem * $quantity) * ($tax + 1.0); &#125;; array_walk($this-&gt;products, $callback); return round($total, 2);; &#125;&#125;$my_cart = new Cart;// 往购物车里添加条目$my_cart-&gt;add(&apos;butter&apos;, 1);$my_cart-&gt;add(&apos;milk&apos;, 3);$my_cart-&gt;add(&apos;eggs&apos;, 6);// 打出出总价格，其中有 5% 的销售税.print $my_cart-&gt;getTotal(0.05) . &quot;\\n&quot;;// The result is 54.29?&gt; 匿名函数不会自动从父作用域中继承变量，注意从父作用域继承变量和使用全局变量是不同的。 如果父作用域本身就是全局的 情况下就不存在从父作用域继承变量了，如果不是全局的话，想要使用父作用域中的变量，必须在声明匿名函数时候使用use换键字 来定义继承父作用域的变量。","categories":[{"name":"PHP","slug":"PHP","permalink":"http://yoursite.com/categories/PHP/"}],"tags":[{"name":"闭包/匿名函数","slug":"闭包-匿名函数","permalink":"http://yoursite.com/tags/闭包-匿名函数/"}]},{"title":"window10下docker的应用-创建本地环境的lnmp环境","slug":"window10下docker的应用-创建本地环境的lnmp环境","date":"2016-12-30T07:41:38.000Z","updated":"2018-09-29T11:08:49.330Z","comments":true,"path":"2016/12/30/window10下docker的应用-创建本地环境的lnmp环境/","link":"","permalink":"http://yoursite.com/2016/12/30/window10下docker的应用-创建本地环境的lnmp环境/","excerpt":"docker相关1.下载docker for windows2.安装docker的步骤就不多说了，下一步下一步就行,安装之前记得先将windows自带的hyper-v开启&nbsp;","text":"docker相关1.下载docker for windows2.安装docker的步骤就不多说了，下一步下一步就行,安装之前记得先将windows自带的hyper-v开启&nbsp; 3.配置docker 设置共享磁盘 配置镜像仓库地址为阿里云（非必须） 1.在阿里云镜像仓库中申请自己的加速器&nbsp;&nbsp; 2.在docker中配置仓库地址，右键右下角docker中的设置功能进行设置&nbsp;&nbsp; 上面配置成功后，接下来进行docker的常用操作 4.打开windows的cmd或者git bash; 输入docker，出现下列信息表示安装成功5.docker命令 attach Attach to a running container # 当前 shell 下 attach 连接指定运行容器 build Build an image from a Dockerfile # 通过 Dockerfile 定制镜像 commit Create a new image from a container’s changes # 提交当前容器为新的镜像 cp Copy files/folders from the containers filesystem to the host path# 从容器中拷贝指定文件或者目录到宿主机中 create Create a new container # 创建一个新的容器，同 run，但不启动容器 diff Inspect changes on a container’s filesystem # 查看 docker 容器变化 events Get real time events from the server # 从 docker 服务获取容器实时事件 exec Run a command in an existing container # 在已存在的容器上运行命令 export Stream the contents of a container as a tar archive # 导出容器的内容流作为一个 tar 归档文件[对应 import ] history Show the history of an image # 展示一个镜像形成历史 images List images # 列出系统当前镜像 import Create a new filesystem image from the contents of a tarball # 从tar包中的内容创建一个新的文件系统映像[对应 export] info Display system-wide information # 显示系统相关信息 inspect Return low-level information on a container # 查看容器详细信息 kill Kill a running container # kill 指定 docker 容器 load Load an image from a tar archive # 从一个 tar 包中加载一个镜像[对应 save] login Register or Login to the docker registry server # 注册或者登陆一个 docker 源服务器 logout Log out from a Docker registry server # 从当前 Docker registry 退出 logs Fetch the logs of a container # 输出当前容器日志信息 port Lookup the public-facing port which is NAT-ed to PRIVATE_PORT# 查看映射端口对应的容器内部源端口 pause Pause all processes within a container # 暂停容器 ps List containers # 列出容器列表 pull Pull an image or a repository from the docker registry server# 从docker镜像源服务器拉取指定镜像或者库镜像 push Push an image or a repository to the docker registry server# 推送指定镜像或者库镜像至docker源服务器 rename Rename an existing container restart Restart a running container # 重启运行的容器 rm Remove one or more containers # 移除一个或者多个容器 rmi Remove one or more images # 移除一个或多个镜像[无容器使用该镜像才可删除，否则需删除相关容器才可继续或 -f 强制删除] run Run a command in a new container# 创建一个新的容器并运行一个命令 save Save an image to a tar archive # 保存一个镜像为一个 tar 包[对应 load] search Search for an image on the Docker Hub # 在 docker hub 中搜索镜像 start Start a stopped containers # 启动容器 stats Display a stream of a containers’ resource usage statistics stop Stop a running containers # 停止容器 tag Tag an image into a repository # 给源中镜像打标签 top Lookup the running processes of a container # 查看容器中运行的进程信息 unpause Unpause a paused container # 取消暂停容器 version Show the docker version information # 查看 docker 版本号 wait Block until a container stops, then print its exit code # 截取容器停止时的退出状态值&nbsp; 6.到此windows for docker 安装了解完成，下面进行容器的运行 查找镜像docker search centos&nbsp; pull一个镜像docker pull centos&nbsp;&nbsp; 将这个镜像启动成为一个容器,并映射端口、挂在本地的目录、后台启动、赋予最高权限docker run -it -d --privileged=true --name www -p 33060:3306 -p 220:22 -p 8080:80 -v e:\\WWW\\:/home/www centos /usr/sbin/init 解释一下主要参数的意义： -d&nbsp;&nbsp;&nbsp;&nbsp;以daemon方式运行 –privileged=true&nbsp;&nbsp;&nbsp;&nbsp;增加权限的选项（本人未测试） –name &nbsp;&nbsp;&nbsp;&nbsp;给运行的容器起别名（个人理解） -p 33060:3306 -p 220:22 -p 8080:80 &nbsp;&nbsp;&nbsp;&nbsp;进行端口映射 -v e:\\WWW\\:/home/www &nbsp;&nbsp;&nbsp;&nbsp;挂载宿主机的www目录到容器内部的www目录 运行后查看容器运行列表&nbsp; 进入容器并查看&nbsp;主要是查看挂在的目录是否存在&nbsp;)和本地目录一致，挂在成功！7 安装ifconfigyum install net-tools –y8 安装压缩解压缩yum install -y unzip zip9 安装firewall-cmdyum install firewalld systemd –y10 修改密码passwd11 安装ssh服务，使用工具与容器内进行通讯和管理 1 . 安装ssh服务 yum install openssh* 2 . 配置sshvi /etc/ssh/sshd_config 这里我没有设置，因为是初学，使用的默认配置,如果需要设置，请参考下面的说明 设置這些设定是一些比较基本的首先先把port改掉port 52041再来是限定登入者AllowUsers 使用者账号1 使用者账号2 …..这一行在设置中是沒有的~请自行加入再来把这两行的注释掉PermitEmptyPasswords noPasswordAuthentication yes再来限制root账号登录 3 .重启 systemctl restart sshd.service 4 .设置为开机启动sudo systemctl enable sshd.service 5 .开放防火墙端口firewall-cmd --permanent --zone=public --add-port=22/tcp 6 . 重启防火墙firewall-cmd --reload最后输入netstat -ant 看看PORT有沒有加入监控中 CentOS 7 的最小安装未把 netstat 安装进去，所以如果执行失败请输入sudo yum install net-toolsyum install firewalld systemd -y测试环境下也可以彻底关闭防火墙 关闭防火墙CentOS 7.0默认使用的是firewall作为防火墙 firewall： systemctl start firewalld.service#启动firewall systemctl stop firewalld.service#停止firewall systemctl disable firewalld.service#禁止firewall开机启动 12.测试ssh连接记住我们的端口映射好220=&gt;22 8080=&gt;80 33060=&gt;3306直接上图 查看本机ip&nbsp; 使用220端口连接容器&nbsp; 连接成功查看&nbsp; 13.将容器保存为镜像先退出容器，拿到需要保存为镜像的容器iddocker commit -m=&#39;ssh_network_vim&#39; --author=&#39;mma&#39; f3823b442695 ssh_network_vim -m 创建的镜像的提交信息 –author指定镜像作者，接着是容器ID、目标镜像仓库、镜像名&nbsp; ok，docker在windows上面的安装设置就到这里，下面进行lnmp环境的搭建 下面进行lnmp 环境的搭建 安装lnmp 请移步此教程：CentOS7☞lnmp环境搭建 正式使用 之前我安装过一次，并且配置完成提交到阿里云的仓库中了，这次的演示，我直接从阿里云下载之前我使用的镜像1.下载镜像 镜像信息&nbsp; 下载镜像docker pull registry.cn-hangzhou.aliyuncs.com/mma/centos7-lnmp:v1.0.0&nbsp;&nbsp;2.运行一个容器，并进入进入容器docker run -it -d --privileged=true --name www -p 33060:3306 -p 220:22 -p 8080:80 -v e:\\WWW\\:/home/www 84901c8f883b/usr/sbin/init&nbsp;3.启动lnmp4.windows访问容器中的项目 ok,这篇总结就到这里，总结下，写这篇总结收获很多，第一次使用hexo，第一次在windows环境模拟linux环境（纯属zhuangb用），阿里云方面，第一次使用markdown。。。 说实在的，还是很有感触，也是个开始，继续加油下去吧！mafuntoo","categories":[{"name":"docker","slug":"docker","permalink":"http://yoursite.com/categories/docker/"}],"tags":[{"name":"docker","slug":"docker","permalink":"http://yoursite.com/tags/docker/"}]}]}